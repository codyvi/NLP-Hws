{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea8_P2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-aUh2JjqynL"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "Uhfc2Mh1q5U_",
        "outputId": "7288378d-d4ed-40a4-f0ab-11ea7745b6df"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8ead62de-94c9-48fd-b663-23f84dfeef74\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8ead62de-94c9-48fd-b663-23f84dfeef74\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving loan.csv to loan.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loan.csv': b'Dependents,Education,Self_Employed,ApplicantIncome,CoapplicantIncome,LoanAmount,Loan_Amount_Term,Credit_History,Property_Area,Loan_Status\\r\\n0,Graduate,No,5849,0,,360,1,Urban,Y\\r\\n1,Graduate,No,4583,1508,128,360,1,Rural,N\\r\\n0,Graduate,Yes,3000,0,66,360,1,Urban,Y\\r\\n0,Not Graduate,No,2583,2358,120,360,1,Urban,Y\\r\\n0,Graduate,No,6000,0,141,360,1,Urban,Y\\r\\n2,Graduate,Yes,5417,4196,267,360,1,Urban,Y\\r\\n0,Not Graduate,No,2333,1516,95,360,1,Urban,Y\\r\\n3,Graduate,No,3036,2504,158,360,0,Semiurban,N\\r\\n2,Graduate,No,4006,1526,168,360,1,Urban,Y\\r\\n1,Graduate,No,12841,10968,349,360,1,Semiurban,N\\r\\n2,Graduate,No,3200,700,70,360,1,Urban,Y\\r\\n2,Graduate,,2500,1840,109,360,1,Urban,Y\\r\\n2,Graduate,No,3073,8106,200,360,1,Urban,Y\\r\\n0,Graduate,No,1853,2840,114,360,1,Rural,N\\r\\n2,Graduate,No,1299,1086,17,120,1,Urban,Y\\r\\n0,Graduate,No,4950,0,125,360,1,Urban,Y\\r\\n1,Not Graduate,No,3596,0,100,240,,Urban,Y\\r\\n0,Graduate,No,3510,0,76,360,0,Urban,N\\r\\n0,Not Graduate,No,4887,0,133,360,1,Rural,N\\r\\n0,Graduate,,2600,3500,115,,1,Urban,Y\\r\\n0,Not Graduate,No,7660,0,104,360,0,Urban,N\\r\\n1,Graduate,No,5955,5625,315,360,1,Urban,Y\\r\\n0,Not Graduate,No,2600,1911,116,360,0,Semiurban,N\\r\\n2,Not Graduate,No,3365,1917,112,360,0,Rural,N\\r\\n1,Graduate,,3717,2925,151,360,,Semiurban,N\\r\\n0,Graduate,Yes,9560,0,191,360,1,Semiurban,Y\\r\\n0,Graduate,No,2799,2253,122,360,1,Semiurban,Y\\r\\n2,Not Graduate,No,4226,1040,110,360,1,Urban,Y\\r\\n0,Not Graduate,No,1442,0,35,360,1,Urban,N\\r\\n2,Graduate,,3750,2083,120,360,1,Semiurban,Y\\r\\n1,Graduate,,4166,3369,201,360,,Urban,N\\r\\n0,Graduate,No,3167,0,74,360,1,Urban,N\\r\\n1,Graduate,Yes,4692,0,106,360,1,Rural,N\\r\\n0,Graduate,No,3500,1667,114,360,1,Semiurban,Y\\r\\n3,Graduate,No,12500,3000,320,360,1,Rural,N\\r\\n0,Graduate,No,2275,2067,,360,1,Urban,Y\\r\\n0,Graduate,No,1828,1330,100,,0,Urban,N\\r\\n0,Graduate,No,3667,1459,144,360,1,Semiurban,Y\\r\\n0,Graduate,No,4166,7210,184,360,1,Urban,Y\\r\\n0,Not Graduate,No,3748,1668,110,360,1,Semiurban,Y\\r\\n0,Graduate,No,3600,0,80,360,1,Urban,N\\r\\n0,Graduate,No,1800,1213,47,360,1,Urban,Y\\r\\n0,Graduate,No,2400,0,75,360,,Urban,Y\\r\\n0,Graduate,No,3941,2336,134,360,1,Semiurban,Y\\r\\n0,Not Graduate,Yes,4695,0,96,,1,Urban,Y\\r\\n0,Graduate,No,3410,0,88,,1,Urban,Y\\r\\n1,Graduate,No,5649,0,44,360,1,Urban,Y\\r\\n0,Graduate,No,5821,0,144,360,1,Urban,Y\\r\\n0,Graduate,No,2645,3440,120,360,0,Urban,N\\r\\n0,Graduate,No,4000,2275,144,360,1,Semiurban,Y\\r\\n0,Not Graduate,No,1928,1644,100,360,1,Semiurban,Y\\r\\n0,Graduate,No,3086,0,120,360,1,Semiurban,Y\\r\\n0,Graduate,No,4230,0,112,360,1,Semiurban,N\\r\\n2,Graduate,No,4616,0,134,360,1,Urban,N\\r\\n1,Graduate,Yes,11500,0,286,360,0,Urban,N\\r\\n2,Graduate,No,2708,1167,97,360,1,Semiurban,Y\\r\\n0,Graduate,No,2132,1591,96,360,1,Semiurban,Y\\r\\n0,Graduate,No,3366,2200,135,360,1,Rural,N\\r\\n1,Graduate,No,8080,2250,180,360,1,Urban,Y\\r\\n2,Not Graduate,No,3357,2859,144,360,1,Urban,Y\\r\\n0,Graduate,No,2500,3796,120,360,1,Urban,Y\\r\\n3,Graduate,No,3029,0,99,360,1,Urban,Y\\r\\n0,Not Graduate,Yes,2609,3449,165,180,0,Rural,N\\r\\n1,Graduate,No,4945,0,,360,0,Rural,N\\r\\n0,Graduate,No,4166,0,116,360,0,Semiurban,N\\r\\n0,Graduate,No,5726,4595,258,360,1,Semiurban,N\\r\\n0,Not Graduate,No,3200,2254,126,180,0,Urban,N\\r\\n1,Graduate,No,10750,0,312,360,1,Urban,Y\\r\\n3,Not Graduate,Yes,7100,0,125,60,1,Urban,Y\\r\\n0,Graduate,No,4300,0,136,360,0,Semiurban,N\\r\\n0,Graduate,No,3208,3066,172,360,1,Urban,Y\\r\\n2,Not Graduate,Yes,1875,1875,97,360,1,Semiurban,Y\\r\\n0,Graduate,No,3500,0,81,300,1,Semiurban,Y\\r\\n3,Not Graduate,No,4755,0,95,,0,Semiurban,N\\r\\n3,Graduate,Yes,5266,1774,187,360,1,Semiurban,Y\\r\\n0,Graduate,No,3750,0,113,480,1,Urban,N\\r\\n0,Graduate,No,3750,4750,176,360,1,Urban,N\\r\\n1,Graduate,Yes,1000,3022,110,360,1,Urban,N\\r\\n3,Graduate,No,3167,4000,180,300,0,Semiurban,N\\r\\n3,Not Graduate,Yes,3333,2166,130,360,,Semiurban,Y\\r\\n0,Graduate,No,3846,0,111,360,1,Semiurban,Y\\r\\n1,Graduate,Yes,2395,0,,360,1,Semiurban,Y\\r\\n2,Graduate,No,1378,1881,167,360,1,Urban,N\\r\\n0,Graduate,No,6000,2250,265,360,,Semiurban,N\\r\\n1,Graduate,No,3988,0,50,240,1,Urban,Y\\r\\n0,Graduate,No,2366,2531,136,360,1,Semiurban,Y\\r\\n2,Not Graduate,No,3333,2000,99,360,,Semiurban,Y\\r\\n0,Graduate,No,2500,2118,104,360,1,Semiurban,Y\\r\\n0,Graduate,No,8566,0,210,360,1,Urban,Y\\r\\n0,Graduate,No,5695,4167,175,360,1,Semiurban,Y\\r\\n0,Graduate,No,2958,2900,131,360,1,Semiurban,Y\\r\\n2,Graduate,No,6250,5654,188,180,1,Semiurban,Y\\r\\n2,Not Graduate,No,3273,1820,81,360,1,Urban,Y\\r\\n0,Graduate,No,4133,0,122,360,1,Semiurban,Y\\r\\n0,Not Graduate,No,3620,0,25,120,1,Semiurban,Y\\r\\n0,Graduate,,6782,0,,360,,Urban,N\\r\\n0,Graduate,No,2484,2302,137,360,1,Semiurban,Y\\r\\n0,Graduate,No,1977,997,50,360,1,Semiurban,Y\\r\\n0,Not Graduate,No,4188,0,115,180,1,Semiurban,Y\\r\\n0,Graduate,No,1759,3541,131,360,1,Semiurban,Y\\r\\n2,Not Graduate,No,4288,3263,133,180,1,Urban,Y\\r\\n0,Graduate,No,4843,3806,151,360,1,Semiurban,Y\\r\\n,Graduate,No,13650,0,,360,1,Urban,Y\\r\\n0,Graduate,No,4652,3583,,360,1,Semiurban,Y\\r\\n,Graduate,No,3816,754,160,360,1,Urban,Y\\r\\n1,Graduate,No,3052,1030,100,360,1,Urban,Y\\r\\n2,Graduate,No,11417,1126,225,360,1,Urban,Y\\r\\n0,Not Graduate,,7333,0,120,360,1,Rural,N\\r\\n2,Graduate,No,3800,3600,216,360,0,Urban,N\\r\\n3,Not Graduate,No,2071,754,94,480,1,Semiurban,Y\\r\\n0,Graduate,No,5316,0,136,360,1,Urban,Y\\r\\n0,Graduate,,2929,2333,139,360,1,Semiurban,Y\\r\\n0,Not Graduate,No,3572,4114,152,,0,Rural,N\\r\\n1,Graduate,Yes,7451,0,,360,1,Semiurban,Y\\r\\n0,Graduate,,5050,0,118,360,1,Semiurban,Y\\r\\n1,Graduate,No,14583,0,185,180,1,Rural,Y\\r\\n0,Graduate,No,3167,2283,154,360,1,Semiurban,Y\\r\\n1,Graduate,No,2214,1398,85,360,,Urban,Y\\r\\n0,Graduate,No,5568,2142,175,360,1,Rural,N\\r\\n0,Graduate,No,10408,0,259,360,1,Urban,Y\\r\\n,Graduate,No,5667,2667,180,360,1,Rural,Y\\r\\n0,Graduate,No,4166,0,44,360,1,Semiurban,Y\\r\\n0,Graduate,No,2137,8980,137,360,0,Semiurban,Y\\r\\n2,Graduate,No,2957,0,81,360,1,Semiurban,Y\\r\\n0,Not Graduate,No,4300,2014,194,360,1,Rural,Y\\r\\n0,Graduate,No,3692,0,93,360,,Rural,Y\\r\\n3,Graduate,No,23803,0,370,360,1,Rural,Y\\r\\n0,Graduate,No,3865,1640,,360,1,Rural,Y\\r\\n1,Graduate,Yes,10513,3850,160,180,0,Urban,N\\r\\n0,Graduate,No,6080,2569,182,360,,Rural,N\\r\\n0,Graduate,Yes,20166,0,650,480,,Urban,Y\\r\\n0,Graduate,No,2014,1929,74,360,1,Urban,Y\\r\\n0,Graduate,No,2718,0,70,360,1,Semiurban,Y\\r\\n0,Graduate,Yes,3459,0,25,120,1,Semiurban,Y\\r\\n0,Graduate,No,4895,0,102,360,1,Semiurban,Y\\r\\n3,Graduate,No,4000,7750,290,360,1,Semiurban,N\\r\\n0,Graduate,No,4583,0,84,360,1,Rural,N\\r\\n2,Graduate,Yes,3316,3500,88,360,1,Urban,Y\\r\\n0,Graduate,No,14999,0,242,360,0,Semiurban,N\\r\\n2,Not Graduate,No,4200,1430,129,360,1,Rural,N\\r\\n2,Graduate,No,5042,2083,185,360,1,Rural,N\\r\\n0,Graduate,No,5417,0,168,360,1,Urban,Y\\r\\n0,Graduate,Yes,6950,0,175,180,1,Semiurban,Y\\r\\n0,Graduate,No,2698,2034,122,360,1,Semiurban,Y\\r\\n2,Graduate,No,11757,0,187,180,1,Urban,Y\\r\\n0,Graduate,No,2330,4486,100,360,1,Semiurban,Y\\r\\n2,Graduate,No,14866,0,70,360,1,Urban,Y\\r\\n1,Graduate,No,1538,1425,30,360,1,Urban,Y\\r\\n0,Graduate,No,10000,1666,225,360,1,Rural,N\\r\\n0,Graduate,No,4860,830,125,360,1,Semiurban,Y\\r\\n0,Graduate,No,6277,0,118,360,0,Rural,N\\r\\n0,Graduate,Yes,2577,3750,152,360,1,Rural,Y\\r\\n0,Graduate,No,9166,0,244,360,1,Urban,N\\r\\n2,Not Graduate,No,2281,0,113,360,1,Rural,N\\r\\n0,Graduate,No,3254,0,50,360,1,Urban,Y\\r\\n3,Graduate,No,39999,0,600,180,0,Semiurban,Y\\r\\n1,Graduate,No,6000,0,160,360,,Rural,Y\\r\\n1,Graduate,No,9538,0,187,360,1,Urban,Y\\r\\n0,Graduate,,2980,2083,120,360,1,Rural,Y\\r\\n0,Graduate,No,4583,5625,255,360,1,Semiurban,Y\\r\\n0,Not Graduate,No,1863,1041,98,360,1,Semiurban,Y\\r\\n0,Graduate,No,7933,0,275,360,1,Urban,N\\r\\n1,Graduate,No,3089,1280,121,360,0,Semiurban,N\\r\\n2,Graduate,No,4167,1447,158,360,1,Rural,Y\\r\\n0,Graduate,No,9323,0,75,180,1,Urban,Y\\r\\n0,Graduate,No,3707,3166,182,,1,Rural,Y\\r\\n0,Graduate,No,4583,0,112,360,1,Rural,N\\r\\n0,Graduate,No,2439,3333,129,360,1,Rural,Y\\r\\n0,Graduate,No,2237,0,63,480,0,Semiurban,N\\r\\n2,Graduate,No,8000,0,200,360,1,Semiurban,Y\\r\\n0,Not Graduate,,1820,1769,95,360,1,Rural,Y\\r\\n3,Graduate,No,51763,0,700,300,1,Urban,Y\\r\\n3,Not Graduate,No,3522,0,81,180,1,Rural,N\\r\\n0,Graduate,No,5708,5625,187,360,1,Semiurban,Y\\r\\n0,Not Graduate,Yes,4344,736,87,360,1,Semiurban,N\\r\\n0,Graduate,No,3497,1964,116,360,1,Rural,Y\\r\\n2,Graduate,No,2045,1619,101,360,1,Rural,Y\\r\\n3,Graduate,No,5516,11300,495,360,0,Semiurban,N\\r\\n1,Graduate,No,3750,0,116,360,1,Semiurban,Y\\r\\n0,Not Graduate,No,2333,1451,102,480,0,Urban,N\\r\\n1,Graduate,No,6400,7250,180,360,0,Urban,N\\r\\n0,Graduate,No,1916,5063,67,360,,Rural,N\\r\\n0,Graduate,No,4600,0,73,180,1,Semiurban,Y\\r\\n1,Graduate,No,33846,0,260,360,1,Semiurban,N\\r\\n0,Graduate,No,3625,0,108,360,1,Semiurban,Y\\r\\n0,Graduate,Yes,39147,4750,120,360,1,Semiurban,Y\\r\\n1,Graduate,Yes,2178,0,66,300,0,Rural,N\\r\\n0,Graduate,No,2383,2138,58,360,,Rural,Y\\r\\n0,Graduate,Yes,674,5296,168,360,1,Rural,Y\\r\\n0,Graduate,No,9328,0,188,180,1,Rural,Y\\r\\n0,Not Graduate,No,4885,0,48,360,1,Rural,Y\\r\\n0,Graduate,No,12000,0,164,360,1,Semiurban,N\\r\\n0,Not Graduate,No,6033,0,160,360,1,Urban,N\\r\\n0,Graduate,No,3858,0,76,360,1,Semiurban,Y\\r\\n0,Graduate,No,4191,0,120,360,1,Rural,Y\\r\\n1,Graduate,No,3125,2583,170,360,1,Semiurban,N\\r\\n0,Graduate,No,8333,3750,187,360,1,Rural,Y\\r\\n0,Not Graduate,No,1907,2365,120,,1,Urban,Y\\r\\n0,Graduate,No,3416,2816,113,360,,Semiurban,Y\\r\\n0,Graduate,Yes,11000,0,83,360,1,Urban,N\\r\\n1,Not Graduate,No,2600,2500,90,360,1,Semiurban,Y\\r\\n2,Graduate,No,4923,0,166,360,0,Semiurban,Y\\r\\n3,Not Graduate,No,3992,0,,180,1,Urban,N\\r\\n1,Not Graduate,No,3500,1083,135,360,1,Urban,Y\\r\\n2,Not Graduate,No,3917,0,124,360,1,Semiurban,Y\\r\\n0,Not Graduate,No,4408,0,120,360,1,Semiurban,Y\\r\\n0,Graduate,No,3244,0,80,360,1,Urban,Y\\r\\n0,Not Graduate,No,3975,2531,55,360,1,Rural,Y\\r\\n0,Graduate,No,2479,0,59,360,1,Urban,Y\\r\\n0,Graduate,No,3418,0,127,360,1,Semiurban,N\\r\\n0,Graduate,No,10000,0,214,360,1,Semiurban,N\\r\\n3,Graduate,No,3430,1250,128,360,0,Semiurban,N\\r\\n1,Graduate,Yes,7787,0,240,360,1,Urban,Y\\r\\n3,Not Graduate,Yes,5703,0,130,360,1,Rural,Y\\r\\n0,Graduate,No,3173,3021,137,360,1,Urban,Y\\r\\n3,Not Graduate,No,3850,983,100,360,1,Semiurban,Y\\r\\n0,Graduate,No,150,1800,135,360,1,Rural,N\\r\\n0,Graduate,No,3727,1775,131,360,1,Semiurban,Y\\r\\n2,Graduate,,5000,0,72,360,0,Semiurban,N\\r\\n2,Graduate,No,4283,2383,127,360,,Semiurban,Y\\r\\n0,Graduate,No,2221,0,60,360,0,Urban,N\\r\\n2,Graduate,No,4009,1717,116,360,1,Semiurban,Y\\r\\n0,Graduate,No,2971,2791,144,360,1,Semiurban,Y\\r\\n0,Graduate,No,7578,1010,175,,1,Semiurban,Y\\r\\n0,Graduate,No,6250,0,128,360,1,Semiurban,Y\\r\\n0,Graduate,No,3250,0,170,360,1,Rural,N\\r\\n,Not Graduate,Yes,4735,0,138,360,1,Urban,N\\r\\n2,Graduate,No,6250,1695,210,360,1,Semiurban,Y\\r\\n,Graduate,No,4758,0,158,480,1,Semiurban,Y\\r\\n0,Graduate,Yes,6400,0,200,360,1,Rural,Y\\r\\n1,Graduate,No,2491,2054,104,360,1,Semiurban,Y\\r\\n0,Graduate,,3716,0,42,180,1,Rural,Y\\r\\n0,Not Graduate,No,3189,2598,120,,1,Rural,Y\\r\\n0,Graduate,No,8333,0,280,360,1,Semiurban,Y\\r\\n1,Graduate,No,3155,1779,140,360,1,Semiurban,Y\\r\\n1,Graduate,No,5500,1260,170,360,1,Rural,Y\\r\\n0,Graduate,,5746,0,255,360,,Urban,N\\r\\n0,Graduate,Yes,3463,0,122,360,,Urban,Y\\r\\n1,Graduate,No,3812,0,112,360,1,Rural,Y\\r\\n1,Graduate,No,3315,0,96,360,1,Semiurban,Y\\r\\n2,Graduate,No,5819,5000,120,360,1,Rural,Y\\r\\n1,Not Graduate,No,2510,1983,140,180,1,Urban,N\\r\\n0,Graduate,No,2965,5701,155,60,1,Urban,Y\\r\\n2,Graduate,Yes,6250,1300,108,360,1,Rural,Y\\r\\n0,Not Graduate,No,3406,4417,123,360,1,Semiurban,Y\\r\\n0,Graduate,Yes,6050,4333,120,180,1,Urban,N\\r\\n2,Graduate,No,9703,0,112,360,1,Urban,Y\\r\\n1,Not Graduate,No,6608,0,137,180,1,Urban,Y\\r\\n1,Graduate,No,2882,1843,123,480,1,Semiurban,Y\\r\\n0,Graduate,No,1809,1868,90,360,1,Urban,Y\\r\\n0,Not Graduate,No,1668,3890,201,360,0,Semiurban,N\\r\\n2,Graduate,No,3427,0,138,360,1,Urban,N\\r\\n0,Not Graduate,Yes,2583,2167,104,360,1,Rural,Y\\r\\n1,Not Graduate,No,2661,7101,279,180,1,Semiurban,Y\\r\\n0,Graduate,Yes,16250,0,192,360,0,Urban,N\\r\\n3,Graduate,No,3083,0,255,360,1,Rural,Y\\r\\n0,Not Graduate,No,6045,0,115,360,0,Rural,N\\r\\n3,Graduate,No,5250,0,94,360,1,Urban,N\\r\\n0,Graduate,No,14683,2100,304,360,1,Rural,N\\r\\n3,Not Graduate,No,4931,0,128,360,,Semiurban,N\\r\\n1,Graduate,No,6083,4250,330,360,,Urban,Y\\r\\n0,Graduate,No,2060,2209,134,360,1,Semiurban,Y\\r\\n1,Graduate,No,3481,0,155,36,1,Semiurban,N\\r\\n0,Graduate,No,7200,0,120,360,1,Rural,Y\\r\\n0,Graduate,Yes,5166,0,128,360,1,Semiurban,Y\\r\\n0,Graduate,No,4095,3447,151,360,1,Rural,Y\\r\\n2,Graduate,No,4708,1387,150,360,1,Semiurban,Y\\r\\n3,Graduate,No,4333,1811,160,360,0,Urban,Y\\r\\n0,Graduate,,3418,0,135,360,1,Rural,N\\r\\n1,Graduate,No,2876,1560,90,360,1,Urban,Y\\r\\n0,Graduate,No,3237,0,30,360,1,Urban,Y\\r\\n0,Graduate,No,11146,0,136,360,1,Urban,Y\\r\\n0,Graduate,No,2833,1857,126,360,1,Rural,Y\\r\\n0,Graduate,No,2620,2223,150,360,1,Semiurban,Y\\r\\n2,Graduate,No,3900,0,90,360,1,Semiurban,Y\\r\\n1,Graduate,No,2750,1842,115,360,1,Semiurban,Y\\r\\n0,Graduate,No,3993,3274,207,360,1,Semiurban,Y\\r\\n0,Graduate,No,3103,1300,80,360,1,Urban,Y\\r\\n0,Graduate,No,14583,0,436,360,1,Semiurban,Y\\r\\n0,Not Graduate,No,4100,0,124,360,,Rural,Y\\r\\n1,Not Graduate,Yes,4053,2426,158,360,0,Urban,N\\r\\n0,Graduate,No,3927,800,112,360,1,Semiurban,Y\\r\\n2,Graduate,No,2301,985.7999878,78,180,1,Urban,Y\\r\\n0,Graduate,No,1811,1666,54,360,1,Urban,Y\\r\\n0,Graduate,No,20667,0,,360,1,Rural,N\\r\\n0,Graduate,No,3158,3053,89,360,1,Rural,Y\\r\\n0,Graduate,Yes,2600,1717,99,300,1,Semiurban,N\\r\\n0,Graduate,No,3704,2000,120,360,1,Rural,Y\\r\\n0,Graduate,No,4124,0,115,360,1,Semiurban,Y\\r\\n0,Graduate,No,9508,0,187,360,1,Rural,Y\\r\\n0,Graduate,No,3075,2416,139,360,1,Rural,Y\\r\\n2,Graduate,No,4400,0,127,360,0,Semiurban,N\\r\\n2,Graduate,No,3153,1560,134,360,1,Urban,Y\\r\\n,Graduate,No,5417,0,143,480,0,Urban,N\\r\\n0,Graduate,No,2383,3334,172,360,1,Semiurban,Y\\r\\n3,Graduate,,4416,1250,110,360,1,Urban,Y\\r\\n1,Graduate,No,6875,0,200,360,1,Semiurban,Y\\r\\n1,Graduate,No,4666,0,135,360,1,Urban,Y\\r\\n0,Graduate,No,5000,2541,151,480,1,Rural,N\\r\\n1,Graduate,No,2014,2925,113,360,1,Urban,N\\r\\n0,Not Graduate,No,1800,2934,93,360,0,Urban,N\\r\\n,Not Graduate,No,2875,1750,105,360,1,Semiurban,Y\\r\\n0,Graduate,No,5000,0,132,360,1,Rural,Y\\r\\n1,Graduate,No,1625,1803,96,360,1,Urban,Y\\r\\n0,Graduate,No,4000,2500,140,360,1,Rural,Y\\r\\n0,Not Graduate,No,2000,0,,360,1,Urban,N\\r\\n0,Graduate,No,3762,1666,135,360,1,Rural,Y\\r\\n0,Graduate,No,2400,1863,104,360,0,Urban,N\\r\\n0,Graduate,No,20233,0,480,360,1,Rural,N\\r\\n2,Not Graduate,No,7667,0,185,360,,Rural,Y\\r\\n0,Graduate,No,2917,0,84,360,1,Semiurban,Y\\r\\n0,Not Graduate,No,2927,2405,111,360,1,Semiurban,Y\\r\\n0,Graduate,No,2507,0,56,360,1,Rural,Y\\r\\n2,Graduate,Yes,5746,0,144,84,,Rural,Y\\r\\n0,Graduate,No,2473,1843,159,360,1,Rural,N\\r\\n1,Not Graduate,No,3399,1640,111,180,1,Urban,Y\\r\\n2,Graduate,No,3717,0,120,360,1,Semiurban,Y\\r\\n0,Graduate,No,2058,2134,88,360,,Urban,Y\\r\\n1,Graduate,No,3541,0,112,360,,Semiurban,Y\\r\\n1,Graduate,Yes,10000,0,155,360,1,Rural,N\\r\\n0,Graduate,No,2400,2167,115,360,1,Semiurban,Y\\r\\n3,Graduate,No,4342,189,124,360,1,Semiurban,Y\\r\\n2,Not Graduate,No,3601,1590,,360,1,Rural,Y\\r\\n0,Graduate,No,3166,2985,132,360,,Rural,Y\\r\\n3,Graduate,No,15000,0,300,360,1,Rural,Y\\r\\n1,Graduate,Yes,8666,4983,376,360,0,Rural,N\\r\\n0,Graduate,No,4917,0,130,360,0,Rural,Y\\r\\n0,Graduate,Yes,5818,2160,184,360,1,Semiurban,Y\\r\\n0,Graduate,No,4333,2451,110,360,1,Urban,N\\r\\n0,Graduate,No,2500,0,67,360,1,Urban,Y\\r\\n1,Graduate,No,4384,1793,117,360,1,Urban,Y\\r\\n0,Graduate,No,2935,0,98,360,1,Semiurban,Y\\r\\n,Graduate,No,2833,0,71,360,1,Urban,Y\\r\\n0,Graduate,,63337,0,490,180,1,Urban,Y\\r\\n1,Graduate,Yes,9833,1833,182,180,1,Urban,Y\\r\\n,Graduate,Yes,5503,4490,70,,1,Semiurban,Y\\r\\n1,Graduate,,5250,688,160,360,1,Rural,Y\\r\\n2,Graduate,Yes,2500,4600,176,360,1,Rural,Y\\r\\n3,Not Graduate,No,1830,0,,360,0,Urban,N\\r\\n0,Graduate,No,4160,0,71,360,1,Semiurban,Y\\r\\n3,Not Graduate,No,2647,1587,173,360,1,Rural,N\\r\\n0,Graduate,No,2378,0,46,360,1,Rural,N\\r\\n1,Not Graduate,No,4554,1229,158,360,1,Urban,Y\\r\\n3,Not Graduate,No,3173,0,74,360,1,Semiurban,Y\\r\\n2,Graduate,,2583,2330,125,360,1,Rural,Y\\r\\n0,Graduate,No,2499,2458,160,360,1,Semiurban,Y\\r\\n,Not Graduate,No,3523,3230,152,360,0,Rural,N\\r\\n2,Not Graduate,No,3083,2168,126,360,1,Urban,Y\\r\\n0,Graduate,No,6333,4583,259,360,,Semiurban,Y\\r\\n0,Graduate,No,2625,6250,187,360,1,Rural,Y\\r\\n0,Graduate,No,9083,0,228,360,1,Semiurban,Y\\r\\n0,Graduate,No,8750,4167,308,360,1,Rural,N\\r\\n3,Graduate,No,2666,2083,95,360,1,Rural,Y\\r\\n0,Graduate,Yes,5500,0,105,360,0,Rural,N\\r\\n0,Graduate,No,2423,505,130,360,1,Semiurban,Y\\r\\n,Graduate,No,3813,0,116,180,1,Urban,Y\\r\\n2,Graduate,No,8333,3167,165,360,1,Rural,Y\\r\\n1,Graduate,No,3875,0,67,360,1,Urban,N\\r\\n0,Not Graduate,No,3000,1666,100,480,0,Urban,N\\r\\n3,Graduate,No,5167,3167,200,360,1,Semiurban,Y\\r\\n1,Graduate,No,4723,0,81,360,1,Semiurban,N\\r\\n2,Graduate,No,5000,3667,236,360,1,Semiurban,Y\\r\\n0,Graduate,No,4750,2333,130,360,1,Urban,Y\\r\\n0,Graduate,No,3013,3033,95,300,,Urban,Y\\r\\n0,Graduate,Yes,6822,0,141,360,1,Rural,Y\\r\\n0,Not Graduate,No,6216,0,133,360,1,Rural,N\\r\\n0,Graduate,No,2500,0,96,480,1,Semiurban,N\\r\\n0,Graduate,No,5124,0,124,,0,Rural,N\\r\\n1,Graduate,No,6325,0,175,360,1,Semiurban,Y\\r\\n0,Graduate,No,19730,5266,570,360,1,Rural,N\\r\\n0,Graduate,Yes,15759,0,55,360,1,Semiurban,Y\\r\\n2,Graduate,No,5185,0,155,360,1,Semiurban,Y\\r\\n2,Graduate,Yes,9323,7873,380,300,1,Rural,Y\\r\\n1,Graduate,No,3062,1987,111,180,0,Urban,N\\r\\n0,Graduate,,2764,1459,110,360,1,Urban,Y\\r\\n0,Graduate,No,4817,923,120,180,1,Urban,Y\\r\\n3,Graduate,No,8750,4996,130,360,1,Rural,Y\\r\\n0,Graduate,No,4310,0,130,360,,Semiurban,Y\\r\\n0,Graduate,No,3069,0,71,480,1,Urban,N\\r\\n2,Graduate,No,5391,0,130,360,1,Urban,Y\\r\\n0,Graduate,,3333,2500,128,360,1,Semiurban,Y\\r\\n0,Graduate,No,5941,4232,296,360,1,Semiurban,Y\\r\\n0,Graduate,No,6000,0,156,360,1,Urban,Y\\r\\n0,Graduate,Yes,7167,0,128,360,1,Urban,Y\\r\\n2,Graduate,No,4566,0,100,360,1,Urban,N\\r\\n1,Graduate,,3667,0,113,180,1,Urban,Y\\r\\n0,Not Graduate,No,2346,1600,132,360,1,Semiurban,Y\\r\\n0,Not Graduate,No,3010,3136,,360,0,Urban,N\\r\\n0,Graduate,No,2333,2417,136,360,1,Urban,Y\\r\\n0,Graduate,No,5488,0,125,360,1,Rural,Y\\r\\n3,Graduate,No,9167,0,185,360,1,Rural,Y\\r\\n3,Graduate,No,9504,0,275,360,1,Rural,Y\\r\\n0,Graduate,No,2583,2115,120,360,,Urban,Y\\r\\n2,Not Graduate,No,1993,1625,113,180,1,Semiurban,Y\\r\\n2,Graduate,No,3100,1400,113,360,1,Urban,Y\\r\\n2,Graduate,No,3276,484,135,360,,Semiurban,Y\\r\\n0,Graduate,No,3180,0,71,360,0,Urban,N\\r\\n0,Graduate,No,3033,1459,95,360,1,Urban,Y\\r\\n0,Not Graduate,No,3902,1666,109,360,1,Rural,Y\\r\\n0,Graduate,No,1500,1800,103,360,0,Semiurban,N\\r\\n2,Not Graduate,No,2889,0,45,180,0,Urban,N\\r\\n0,Not Graduate,No,2755,0,65,300,1,Rural,N\\r\\n0,Graduate,No,2500,20000,103,360,1,Semiurban,Y\\r\\n0,Not Graduate,No,1963,0,53,360,1,Semiurban,Y\\r\\n0,Graduate,Yes,7441,0,194,360,1,Rural,N\\r\\n0,Graduate,No,4547,0,115,360,1,Semiurban,Y\\r\\n0,Not Graduate,No,2167,2400,115,360,1,Urban,Y\\r\\n0,Not Graduate,No,2213,0,66,360,1,Rural,Y\\r\\n1,Graduate,No,8300,0,152,300,0,Semiurban,N\\r\\n3,Graduate,No,81000,0,360,360,0,Rural,N\\r\\n1,Not Graduate,Yes,3867,0,62,360,1,Semiurban,N\\r\\n0,Graduate,,6256,0,160,360,,Urban,Y\\r\\n0,Not Graduate,No,6096,0,218,360,0,Rural,N\\r\\n0,Not Graduate,No,2253,2033,110,360,1,Rural,Y\\r\\n0,Not Graduate,No,2149,3237,178,360,0,Semiurban,N\\r\\n0,Graduate,No,2995,0,60,360,1,Urban,Y\\r\\n1,Graduate,No,2600,0,160,360,1,Urban,N\\r\\n2,Graduate,Yes,1600,20000,239,360,1,Urban,N\\r\\n0,Graduate,No,1025,2773,112,360,1,Rural,Y\\r\\n0,Graduate,No,3246,1417,138,360,1,Semiurban,Y\\r\\n0,Graduate,No,5829,0,138,360,1,Rural,Y\\r\\n0,Not Graduate,No,2720,0,80,,0,Urban,N\\r\\n0,Graduate,No,1820,1719,100,360,1,Urban,Y\\r\\n1,Graduate,No,7250,1667,110,,0,Urban,N\\r\\n0,Graduate,No,14880,0,96,360,1,Semiurban,Y\\r\\n0,Graduate,No,2666,4300,121,360,1,Rural,Y\\r\\n1,Not Graduate,No,4606,0,81,360,1,Rural,N\\r\\n2,Graduate,No,5935,0,133,360,1,Semiurban,Y\\r\\n0,Graduate,No,2920,16.12000084,87,360,1,Rural,Y\\r\\n0,Not Graduate,No,2717,0,60,180,1,Urban,Y\\r\\n1,Graduate,Yes,8624,0,150,360,1,Semiurban,Y\\r\\n0,Graduate,No,6500,0,105,360,0,Rural,N\\r\\n0,Graduate,,12876,0,405,360,1,Semiurban,Y\\r\\n0,Graduate,No,2425,2340,143,360,1,Semiurban,Y\\r\\n0,Graduate,No,3750,0,100,360,1,Urban,Y\\r\\n,Graduate,No,10047,0,,240,1,Semiurban,Y\\r\\n0,Graduate,No,1926,1851,50,360,1,Semiurban,Y\\r\\n0,Graduate,No,2213,1125,,360,1,Urban,Y\\r\\n0,Graduate,Yes,10416,0,187,360,0,Urban,N\\r\\n0,Not Graduate,Yes,7142,0,138,360,1,Rural,Y\\r\\n0,Graduate,No,3660,5064,187,360,1,Semiurban,Y\\r\\n0,Graduate,No,7901,1833,180,360,1,Rural,Y\\r\\n3,Not Graduate,No,4707,1993,148,360,1,Semiurban,Y\\r\\n1,Graduate,No,37719,0,152,360,1,Semiurban,Y\\r\\n0,Graduate,No,7333,8333,175,300,,Rural,Y\\r\\n1,Graduate,Yes,3466,1210,130,360,1,Rural,Y\\r\\n2,Not Graduate,No,4652,0,110,360,1,Rural,Y\\r\\n0,Graduate,,3539,1376,55,360,1,Rural,N\\r\\n2,Graduate,No,3340,1710,150,360,0,Rural,N\\r\\n1,Not Graduate,Yes,2769,1542,190,360,,Semiurban,N\\r\\n2,Not Graduate,No,2309,1255,125,360,0,Rural,N\\r\\n2,Not Graduate,No,1958,1456,60,300,,Urban,Y\\r\\n0,Graduate,No,3948,1733,149,360,0,Rural,N\\r\\n0,Graduate,No,2483,2466,90,180,0,Rural,Y\\r\\n0,Graduate,Yes,7085,0,84,360,1,Semiurban,Y\\r\\n2,Graduate,No,3859,0,96,360,1,Semiurban,Y\\r\\n0,Graduate,No,4301,0,118,360,1,Urban,Y\\r\\n0,Graduate,No,3708,2569,173,360,1,Urban,N\\r\\n2,Graduate,No,4354,0,136,360,1,Rural,Y\\r\\n0,Graduate,No,8334,0,160,360,1,Semiurban,N\\r\\n0,Graduate,Yes,2083,4083,160,360,,Semiurban,Y\\r\\n3,Graduate,No,7740,0,128,180,1,Urban,Y\\r\\n0,Graduate,No,3015,2188,153,360,1,Rural,Y\\r\\n1,Not Graduate,,5191,0,132,360,1,Semiurban,Y\\r\\n0,Graduate,No,4166,0,98,360,0,Semiurban,N\\r\\n0,Graduate,No,6000,0,140,360,1,Rural,Y\\r\\n3,Not Graduate,No,2947,1664,70,180,0,Urban,N\\r\\n0,Graduate,No,16692,0,110,360,1,Semiurban,Y\\r\\n2,Not Graduate,,210,2917,98,360,1,Semiurban,Y\\r\\n0,Graduate,No,4333,2451,110,360,1,Urban,N\\r\\n1,Graduate,Yes,3450,2079,162,360,1,Semiurban,Y\\r\\n1,Not Graduate,No,2653,1500,113,180,0,Rural,N\\r\\n3,Graduate,No,4691,0,100,360,1,Semiurban,Y\\r\\n0,Graduate,Yes,2500,0,93,360,,Urban,Y\\r\\n2,Graduate,No,5532,4648,162,360,1,Rural,Y\\r\\n2,Graduate,Yes,16525,1014,150,360,1,Rural,Y\\r\\n2,Graduate,No,6700,1750,230,300,1,Semiurban,Y\\r\\n2,Graduate,No,2873,1872,132,360,0,Semiurban,N\\r\\n1,Graduate,Yes,16667,2250,86,360,1,Semiurban,Y\\r\\n2,Graduate,No,2947,1603,,360,1,Urban,N\\r\\n0,Not Graduate,No,4350,0,154,360,1,Rural,Y\\r\\n3,Not Graduate,No,3095,0,113,360,1,Rural,Y\\r\\n0,Graduate,No,2083,3150,128,360,1,Semiurban,Y\\r\\n0,Graduate,No,10833,0,234,360,1,Semiurban,Y\\r\\n2,Graduate,No,8333,0,246,360,1,Semiurban,Y\\r\\n1,Not Graduate,No,1958,2436,131,360,1,Rural,Y\\r\\n2,Graduate,No,3547,0,80,360,0,Rural,N\\r\\n1,Graduate,No,18333,0,500,360,1,Urban,N\\r\\n2,Graduate,Yes,4583,2083,160,360,1,Semiurban,Y\\r\\n0,Graduate,No,2435,0,75,360,1,Urban,N\\r\\n0,Not Graduate,No,2699,2785,96,360,,Semiurban,Y\\r\\n1,Not Graduate,No,5333,1131,186,360,,Urban,Y\\r\\n0,Not Graduate,No,3691,0,110,360,1,Rural,Y\\r\\n0,Not Graduate,Yes,17263,0,225,360,1,Semiurban,Y\\r\\n0,Graduate,No,3597,2157,119,360,0,Rural,N\\r\\n1,Graduate,No,3326,913,105,84,1,Semiurban,Y\\r\\n0,Not Graduate,No,2600,1700,107,360,1,Rural,Y\\r\\n0,Graduate,No,4625,2857,111,12,,Urban,Y\\r\\n1,Graduate,Yes,2895,0,95,360,1,Semiurban,Y\\r\\n0,Graduate,No,6283,4416,209,360,0,Rural,N\\r\\n0,Graduate,No,645,3683,113,480,1,Rural,Y\\r\\n0,Graduate,No,3159,0,100,360,1,Semiurban,Y\\r\\n2,Graduate,No,4865,5624,208,360,1,Semiurban,Y\\r\\n1,Not Graduate,No,4050,5302,138,360,,Rural,N\\r\\n0,Not Graduate,No,3814,1483,124,300,1,Semiurban,Y\\r\\n2,Graduate,No,3510,4416,243,360,1,Rural,Y\\r\\n0,Graduate,No,20833,6667,480,360,,Urban,Y\\r\\n0,Graduate,No,3583,0,96,360,1,Urban,N\\r\\n0,Graduate,Yes,2479,3013,188,360,1,Urban,Y\\r\\n1,Graduate,No,13262,0,40,360,1,Urban,Y\\r\\n0,Not Graduate,No,3598,1287,100,360,1,Rural,N\\r\\n1,Graduate,No,6065,2004,250,360,1,Semiurban,Y\\r\\n2,Graduate,No,3283,2035,148,360,1,Urban,Y\\r\\n0,Graduate,No,2130,6666,70,180,1,Semiurban,N\\r\\n0,Graduate,No,5815,3666,311,360,1,Rural,N\\r\\n3,Graduate,No,3466,3428,150,360,1,Rural,Y\\r\\n2,Graduate,No,2031,1632,113,480,1,Semiurban,Y\\r\\n,Not Graduate,No,3074,1800,123,360,0,Semiurban,N\\r\\n0,Graduate,No,4683,1915,185,360,1,Semiurban,N\\r\\n0,Not Graduate,No,3400,0,95,360,1,Rural,N\\r\\n2,Not Graduate,No,2192,1742,45,360,1,Semiurban,Y\\r\\n0,Graduate,No,2500,0,55,360,1,Semiurban,Y\\r\\n3,Graduate,Yes,5677,1424,100,360,1,Rural,Y\\r\\n2,Graduate,Yes,7948,7166,480,360,1,Rural,Y\\r\\n0,Graduate,No,4680,2087,,360,1,Semiurban,N\\r\\n2,Graduate,Yes,17500,0,400,360,1,Rural,Y\\r\\n0,Graduate,No,3775,0,110,360,1,Semiurban,Y\\r\\n1,Not Graduate,No,5285,1430,161,360,0,Semiurban,Y\\r\\n1,Not Graduate,No,2679,1302,94,360,1,Semiurban,Y\\r\\n0,Not Graduate,No,6783,0,130,360,1,Semiurban,Y\\r\\n0,Graduate,No,1025,5500,216,360,,Rural,Y\\r\\n3,Graduate,No,4281,0,100,360,1,Urban,Y\\r\\n2,Graduate,No,3588,0,110,360,0,Rural,N\\r\\n1,Graduate,No,11250,0,196,360,,Semiurban,N\\r\\n0,Not Graduate,Yes,18165,0,125,360,1,Urban,Y\\r\\n0,Not Graduate,,2550,2042,126,360,1,Rural,Y\\r\\n0,Graduate,No,6133,3906,324,360,1,Urban,Y\\r\\n2,Graduate,No,3617,0,107,360,1,Semiurban,Y\\r\\n0,Not Graduate,No,2917,536,66,360,1,Rural,N\\r\\n3,Graduate,No,6417,0,157,180,1,Rural,Y\\r\\n1,Graduate,No,4608,2845,140,180,1,Semiurban,Y\\r\\n0,Graduate,No,2138,0,99,360,0,Semiurban,N\\r\\n1,Graduate,,3652,0,95,360,1,Semiurban,Y\\r\\n1,Not Graduate,No,2239,2524,128,360,1,Urban,Y\\r\\n0,Not Graduate,No,3017,663,102,360,,Semiurban,Y\\r\\n0,Graduate,No,2768,1950,155,360,1,Rural,Y\\r\\n0,Not Graduate,No,3358,0,80,36,1,Semiurban,N\\r\\n0,Graduate,No,2526,1783,145,360,1,Rural,Y\\r\\n0,Graduate,No,5000,0,103,360,0,Semiurban,N\\r\\n0,Graduate,No,2785,2016,110,360,1,Rural,Y\\r\\n2,Graduate,Yes,6633,0,,360,0,Rural,N\\r\\n1,Not Graduate,No,2492,2375,,360,1,Rural,Y\\r\\n1,Graduate,No,3333,3250,158,360,1,Urban,Y\\r\\n0,Not Graduate,No,2454,2333,181,360,0,Urban,N\\r\\n0,Graduate,No,3593,4266,132,180,0,Rural,N\\r\\n1,Graduate,No,5468,1032,26,360,1,Semiurban,Y\\r\\n0,Graduate,No,2667,1625,84,360,,Urban,Y\\r\\n3,Graduate,Yes,10139,0,260,360,1,Semiurban,Y\\r\\n0,Graduate,No,3887,2669,162,360,1,Semiurban,Y\\r\\n0,Graduate,No,4180,2306,182,360,1,Semiurban,Y\\r\\n2,Not Graduate,No,3675,242,108,360,1,Semiurban,Y\\r\\n1,Graduate,Yes,19484,0,600,360,1,Semiurban,Y\\r\\n0,Graduate,No,5923,2054,211,360,1,Rural,Y\\r\\n0,Not Graduate,Yes,5800,0,132,360,1,Semiurban,Y\\r\\n2,Graduate,No,8799,0,258,360,0,Urban,N\\r\\n0,Not Graduate,No,4467,0,120,360,,Rural,Y\\r\\n0,Graduate,No,3333,0,70,360,1,Urban,Y\\r\\n3,Graduate,No,3400,2500,123,360,0,Rural,N\\r\\n0,Graduate,No,2378,0,9,360,1,Urban,N\\r\\n0,Graduate,No,3166,2064,104,360,0,Urban,N\\r\\n1,Graduate,No,3417,1750,186,360,1,Urban,Y\\r\\n,Graduate,No,5116,1451,165,360,0,Urban,N\\r\\n2,Graduate,No,16666,0,275,360,1,Urban,Y\\r\\n2,Not Graduate,No,6125,1625,187,480,1,Semiurban,N\\r\\n3,Graduate,No,6406,0,150,360,1,Semiurban,N\\r\\n2,Graduate,No,3159,461,108,84,1,Urban,Y\\r\\n0,Graduate,No,3087,2210,136,360,0,Semiurban,N\\r\\n0,Graduate,No,3229,2739,110,360,1,Urban,Y\\r\\n1,Graduate,No,1782,2232,107,360,1,Rural,Y\\r\\n0,Graduate,,3182,2917,161,360,1,Urban,Y\\r\\n2,Graduate,No,6540,0,205,360,1,Semiurban,Y\\r\\n0,Graduate,No,1836,33837,90,360,1,Urban,N\\r\\n0,Graduate,No,3166,0,36,360,1,Semiurban,Y\\r\\n1,Graduate,No,1880,0,61,360,,Rural,N\\r\\n1,Graduate,No,2787,1917,146,360,0,Rural,N\\r\\n1,Graduate,No,4283,3000,172,84,1,Rural,N\\r\\n0,Graduate,No,2297,1522,104,360,1,Urban,Y\\r\\n0,Not Graduate,No,2165,0,70,360,1,Semiurban,Y\\r\\n0,Graduate,No,4750,0,94,360,1,Semiurban,Y\\r\\n2,Graduate,Yes,2726,0,106,360,0,Semiurban,N\\r\\n0,Graduate,No,3000,3416,56,180,1,Semiurban,Y\\r\\n2,Graduate,Yes,6000,0,205,240,1,Semiurban,N\\r\\n3,Graduate,Yes,9357,0,292,360,1,Semiurban,Y\\r\\n0,Graduate,No,3859,3300,142,180,1,Rural,Y\\r\\n0,Graduate,Yes,16120,0,260,360,1,Urban,Y\\r\\n0,Not Graduate,No,3833,0,110,360,1,Rural,Y\\r\\n2,Not Graduate,Yes,6383,1000,187,360,1,Rural,N\\r\\n,Graduate,No,2987,0,88,360,0,Semiurban,N\\r\\n0,Graduate,Yes,9963,0,180,360,1,Rural,Y\\r\\n2,Graduate,No,5780,0,192,360,1,Urban,Y\\r\\n3,Graduate,,416,41667,350,180,,Urban,N\\r\\n0,Not Graduate,,2894,2792,155,360,1,Rural,Y\\r\\n3,Graduate,No,5703,0,128,360,1,Urban,Y\\r\\n0,Graduate,No,3676,4301,172,360,1,Rural,Y\\r\\n1,Graduate,No,12000,0,496,360,1,Semiurban,Y\\r\\n0,Not Graduate,No,2400,3800,,180,1,Urban,N\\r\\n1,Graduate,No,3400,2500,173,360,1,Semiurban,Y\\r\\n2,Not Graduate,No,3987,1411,157,360,1,Rural,Y\\r\\n0,Graduate,No,3232,1950,108,360,1,Rural,Y\\r\\n0,Graduate,No,2900,0,71,360,1,Rural,Y\\r\\n3,Graduate,No,4106,0,40,180,1,Rural,Y\\r\\n1,Graduate,No,8072,240,253,360,1,Urban,Y\\r\\n2,Graduate,No,7583,0,187,360,1,Urban,Y\\r\\n0,Graduate,Yes,4583,0,133,360,0,Semiurban,N\\r\\n'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWaErDVkrCBf"
      },
      "source": [
        "# Problema 2\n",
        "\n",
        "# a) El set de datos loans.csv tiene datos para determinar la elegibilidad de un préstamo, construye una red neuronal para predecir si una persona puede ser acreedor a uno (la variable dependiente a predecir es Loan_status)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fSP263arpO5"
      },
      "source": [
        "El set de datos tiene varias entradas con valores incompletos, para las observaciones que les falta el plazo del monto del préstamo(loan amount term)cambia los NaN por el valor promedio de esa columna. Para  las observaciones que  les  falta  indicar  si es  un trabajador por  cuenta  propia (self_employed), cambia los NaN por la moda de esa columna. Remueve todas las otras entradas con valores incompletos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSdDRWtYq6WP"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38qpbGjyrnkj"
      },
      "source": [
        "df = pd.read_csv('loan.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "6INyaM_Eq1YM",
        "outputId": "d21e3d27-95f3-47af-fe6b-309f7e6a9d6f"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dependents</th>\n",
              "      <th>Education</th>\n",
              "      <th>Self_Employed</th>\n",
              "      <th>ApplicantIncome</th>\n",
              "      <th>CoapplicantIncome</th>\n",
              "      <th>LoanAmount</th>\n",
              "      <th>Loan_Amount_Term</th>\n",
              "      <th>Credit_History</th>\n",
              "      <th>Property_Area</th>\n",
              "      <th>Loan_Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>5849</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>4583</td>\n",
              "      <td>1508.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Rural</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Not Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>2583</td>\n",
              "      <td>2358.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>6000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Dependents     Education  ... Property_Area  Loan_Status\n",
              "0         0.0      Graduate  ...         Urban            Y\n",
              "1         1.0      Graduate  ...         Rural            N\n",
              "2         0.0      Graduate  ...         Urban            Y\n",
              "3         0.0  Not Graduate  ...         Urban            Y\n",
              "4         0.0      Graduate  ...         Urban            Y\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "lSjnYTNvrzLY",
        "outputId": "6110562a-caae-4707-f537-5005e193356b"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dependents</th>\n",
              "      <th>ApplicantIncome</th>\n",
              "      <th>CoapplicantIncome</th>\n",
              "      <th>LoanAmount</th>\n",
              "      <th>Loan_Amount_Term</th>\n",
              "      <th>Credit_History</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>599.000000</td>\n",
              "      <td>614.000000</td>\n",
              "      <td>614.000000</td>\n",
              "      <td>592.000000</td>\n",
              "      <td>600.00000</td>\n",
              "      <td>564.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.762938</td>\n",
              "      <td>5403.459283</td>\n",
              "      <td>1621.245798</td>\n",
              "      <td>146.412162</td>\n",
              "      <td>342.00000</td>\n",
              "      <td>0.842199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.015216</td>\n",
              "      <td>6109.041673</td>\n",
              "      <td>2926.248369</td>\n",
              "      <td>85.587325</td>\n",
              "      <td>65.12041</td>\n",
              "      <td>0.364878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>12.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>2877.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>360.00000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>3812.500000</td>\n",
              "      <td>1188.500000</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>360.00000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>5795.000000</td>\n",
              "      <td>2297.250000</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>360.00000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>81000.000000</td>\n",
              "      <td>41667.000000</td>\n",
              "      <td>700.000000</td>\n",
              "      <td>480.00000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Dependents  ApplicantIncome  ...  Loan_Amount_Term  Credit_History\n",
              "count  599.000000       614.000000  ...         600.00000      564.000000\n",
              "mean     0.762938      5403.459283  ...         342.00000        0.842199\n",
              "std      1.015216      6109.041673  ...          65.12041        0.364878\n",
              "min      0.000000       150.000000  ...          12.00000        0.000000\n",
              "25%      0.000000      2877.500000  ...         360.00000        1.000000\n",
              "50%      0.000000      3812.500000  ...         360.00000        1.000000\n",
              "75%      2.000000      5795.000000  ...         360.00000        1.000000\n",
              "max      3.000000     81000.000000  ...         480.00000        1.000000\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLP00v4Ar0bu",
        "outputId": "99dc496b-0687-48bf-98dc-012bc59eeaec"
      },
      "source": [
        "loanAmountProm = df['Loan_Amount_Term'].mean()\n",
        "loanAmountProm"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "342.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ8RltUEpphW"
      },
      "source": [
        "df['Loan_Amount_Term'] = df['Loan_Amount_Term'].replace(np.nan, loanAmountProm)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV_0LCIbp8_w",
        "outputId": "3a978e3a-4225-4bb4-d0b6-6aeb4c251730"
      },
      "source": [
        "df['Loan_Amount_Term'].isnull().values.any()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsfBOoGopz95"
      },
      "source": [
        "EmployeeMode = df['Self_Employed'].mode()\n",
        "EmployeeMode = EmployeeMode[0]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bynUkRc7sQvF"
      },
      "source": [
        "df['Self_Employed'] = df['Self_Employed'].replace(np.nan,  EmployeeMode)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUldCvYHsZC7",
        "outputId": "da1a6982-39da-4871-8833-4719a64bd36a"
      },
      "source": [
        "df['Self_Employed'].isnull().values.any()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT5Bm92Csn9q"
      },
      "source": [
        "# Removiendo todas las filas que en algun valor tenian NaN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nazMOlx6snXi"
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "ZTQmUe56208C",
        "outputId": "42351508-c60d-4db9-ba5d-e57c621f124f"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dependents</th>\n",
              "      <th>Education</th>\n",
              "      <th>Self_Employed</th>\n",
              "      <th>ApplicantIncome</th>\n",
              "      <th>CoapplicantIncome</th>\n",
              "      <th>LoanAmount</th>\n",
              "      <th>Loan_Amount_Term</th>\n",
              "      <th>Credit_History</th>\n",
              "      <th>Property_Area</th>\n",
              "      <th>Loan_Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>4583</td>\n",
              "      <td>1508.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Rural</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Not Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>2583</td>\n",
              "      <td>2358.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>6000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Yes</td>\n",
              "      <td>5417</td>\n",
              "      <td>4196.0</td>\n",
              "      <td>267.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Dependents     Education  ... Property_Area  Loan_Status\n",
              "1         1.0      Graduate  ...         Rural            N\n",
              "2         0.0      Graduate  ...         Urban            Y\n",
              "3         0.0  Not Graduate  ...         Urban            Y\n",
              "4         0.0      Graduate  ...         Urban            Y\n",
              "5         2.0      Graduate  ...         Urban            Y\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g96hDkJ2sEbY"
      },
      "source": [
        "\n",
        "#b) El  set  de  datos  incluye  varias  entradas  de  tipo categóricas (i.e. property_area). Incluye  un comentario  o  una  celda  de  texto (markdown  cell)  explicando  qué  es  one  hot  encoding e impleméntalo entodos los datos categóricos. Explica cuál hubiera sido el problema de codificar las entradas de property_area de la siguiente forma, Semiurban= 1, Urban = 2, Rural = 3. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUx7Z-jM3-gp"
      },
      "source": [
        "One Hot Encoding es un proceso en el que las variables categóricas son convertidas en una forma en la cual si se provee a algoritmos de ML estos puedan hacer un mejor trabajo prediciendo. El problema con las variables categóricas es que el algoritmo puede pensar que si tiene un numero mayor es mejor, por eso no es buena idea codificar las entradas de la manera que menciona al final"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx9kf_3xsAQK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "86fa8b28-23e0-4026-c484-6b0efa893790"
      },
      "source": [
        "#One Hot Encoding\n",
        "df = pd.get_dummies(df)\n",
        "df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dependents</th>\n",
              "      <th>ApplicantIncome</th>\n",
              "      <th>CoapplicantIncome</th>\n",
              "      <th>LoanAmount</th>\n",
              "      <th>Loan_Amount_Term</th>\n",
              "      <th>Credit_History</th>\n",
              "      <th>Education_Graduate</th>\n",
              "      <th>Education_Not Graduate</th>\n",
              "      <th>Self_Employed_No</th>\n",
              "      <th>Self_Employed_Yes</th>\n",
              "      <th>Property_Area_Rural</th>\n",
              "      <th>Property_Area_Semiurban</th>\n",
              "      <th>Property_Area_Urban</th>\n",
              "      <th>Loan_Status_N</th>\n",
              "      <th>Loan_Status_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4583</td>\n",
              "      <td>1508.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2583</td>\n",
              "      <td>2358.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>6000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.0</td>\n",
              "      <td>5417</td>\n",
              "      <td>4196.0</td>\n",
              "      <td>267.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Dependents  ApplicantIncome  ...  Loan_Status_N  Loan_Status_Y\n",
              "1         1.0             4583  ...              1              0\n",
              "2         0.0             3000  ...              0              1\n",
              "3         0.0             2583  ...              0              1\n",
              "4         0.0             6000  ...              0              1\n",
              "5         2.0             5417  ...              0              1\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu_esRb24kqo"
      },
      "source": [
        "# c)¿Qué   métrica   utilizarías   para   determinar   el   rendimiento   del   modelo,   la precisión o   la exhaustividad? Justifica tu respuesta\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amFUsg2542Z3"
      },
      "source": [
        "La precisión, para poder medir el porcentaje de personas a las que se les da un prestamo de forma correcta.\n",
        "\n",
        "Ref: https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall?hl=es-419"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgGauAwN8jQ5"
      },
      "source": [
        "# d) Divide  el  set  de  datos  con  una  distribución  de  80%  para  el  entrenamiento  y  20%  de  testing. Experimenta  con  diferentes  arquitecturas(varía  la  cantidad  de  capas,  neuronas,  funciones de activación, tasa de aprendizaje, etc) y reporta el mejor rendimiento que obtuviste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0ar4VTI4fZn"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VRUFPccAdSo",
        "outputId": "6901f830-8271-48b0-f9f5-d69d91f54354"
      },
      "source": [
        "loan = df.pop(\"Loan_Status_Y\")\n",
        "loan"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1      0\n",
              "2      1\n",
              "3      1\n",
              "4      1\n",
              "5      1\n",
              "      ..\n",
              "609    1\n",
              "610    1\n",
              "611    1\n",
              "612    1\n",
              "613    0\n",
              "Name: Loan_Status_Y, Length: 530, dtype: uint8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "-bduSLtKGGnt",
        "outputId": "e2d0f615-8533-43d2-f3d2-5dd12beacf59"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dependents</th>\n",
              "      <th>ApplicantIncome</th>\n",
              "      <th>CoapplicantIncome</th>\n",
              "      <th>LoanAmount</th>\n",
              "      <th>Loan_Amount_Term</th>\n",
              "      <th>Credit_History</th>\n",
              "      <th>Education_Graduate</th>\n",
              "      <th>Education_Not Graduate</th>\n",
              "      <th>Self_Employed_No</th>\n",
              "      <th>Self_Employed_Yes</th>\n",
              "      <th>Property_Area_Rural</th>\n",
              "      <th>Property_Area_Semiurban</th>\n",
              "      <th>Property_Area_Urban</th>\n",
              "      <th>Loan_Status_N</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4583</td>\n",
              "      <td>1508.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2583</td>\n",
              "      <td>2358.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>6000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.0</td>\n",
              "      <td>5417</td>\n",
              "      <td>4196.0</td>\n",
              "      <td>267.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Dependents  ApplicantIncome  ...  Property_Area_Urban  Loan_Status_N\n",
              "1         1.0             4583  ...                    0              1\n",
              "2         0.0             3000  ...                    1              0\n",
              "3         0.0             2583  ...                    1              0\n",
              "4         0.0             6000  ...                    1              0\n",
              "5         2.0             5417  ...                    1              0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNbhinODAaj_"
      },
      "source": [
        "train, test, train_y,test_y = train_test_split(df, loan, test_size=0.2)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR3kkSiGAd6q"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cZRxSOoLVHw",
        "outputId": "065334fc-104a-4a2c-b69e-b1810813a5fb"
      },
      "source": [
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "print('Num GPUs Available: ', len(physical_devices))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhMHD5EAL-A7",
        "outputId": "90e30812-e385-4637-c2de-93fe26f3766a"
      },
      "source": [
        "tf.device('/device:GPU:0')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.eager.context._EagerDeviceContext at 0x7f1c4da470a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PuyW2T1KLb5n",
        "outputId": "d01e5b87-6ef8-4f1d-819b-4b66dc6a2555"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E-IRTMhAeuc"
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(units=16, input_shape=(14,), activation='relu'), #First hidden layer\n",
        "    Dense(units=32, activation='relu'),\n",
        "    Dense(units=2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SC2K9TkVKPJ5",
        "outputId": "f3c69aa1-52c1-49b2-bc2c-7969febc94af"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16)                240       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 850\n",
            "Trainable params: 850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVFxB7uNLmv8"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLWKShfkKQUW"
      },
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001),loss='sparse_categorical_crossentropy', metrics=[precision_m])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tNnO-CvK_Dn",
        "outputId": "02aa7a2c-62b7-47df-c049-d95aac82e785"
      },
      "source": [
        "model.fit(x=train, y=train_y, batch_size=10, epochs=30, shuffle=True, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "43/43 - 1s - loss: 153.0679 - precision_m: 0.6802\n",
            "Epoch 2/30\n",
            "43/43 - 0s - loss: 80.9386 - precision_m: 0.6767\n",
            "Epoch 3/30\n",
            "43/43 - 0s - loss: 47.0497 - precision_m: 0.6767\n",
            "Epoch 4/30\n",
            "43/43 - 0s - loss: 42.7706 - precision_m: 0.6733\n",
            "Epoch 5/30\n",
            "43/43 - 0s - loss: 38.9929 - precision_m: 0.6767\n",
            "Epoch 6/30\n",
            "43/43 - 0s - loss: 36.1195 - precision_m: 0.6802\n",
            "Epoch 7/30\n",
            "43/43 - 0s - loss: 32.4582 - precision_m: 0.6837\n",
            "Epoch 8/30\n",
            "43/43 - 0s - loss: 29.6655 - precision_m: 0.6767\n",
            "Epoch 9/30\n",
            "43/43 - 0s - loss: 25.7732 - precision_m: 0.6802\n",
            "Epoch 10/30\n",
            "43/43 - 0s - loss: 22.9687 - precision_m: 0.6802\n",
            "Epoch 11/30\n",
            "43/43 - 0s - loss: 20.6302 - precision_m: 0.6837\n",
            "Epoch 12/30\n",
            "43/43 - 0s - loss: 18.4907 - precision_m: 0.6802\n",
            "Epoch 13/30\n",
            "43/43 - 0s - loss: 17.2917 - precision_m: 0.6837\n",
            "Epoch 14/30\n",
            "43/43 - 0s - loss: 16.1239 - precision_m: 0.6767\n",
            "Epoch 15/30\n",
            "43/43 - 0s - loss: 14.9837 - precision_m: 0.6767\n",
            "Epoch 16/30\n",
            "43/43 - 0s - loss: 14.0886 - precision_m: 0.6767\n",
            "Epoch 17/30\n",
            "43/43 - 0s - loss: 13.4512 - precision_m: 0.6733\n",
            "Epoch 18/30\n",
            "43/43 - 0s - loss: 13.8119 - precision_m: 0.6802\n",
            "Epoch 19/30\n",
            "43/43 - 0s - loss: 12.0644 - precision_m: 0.6837\n",
            "Epoch 20/30\n",
            "43/43 - 0s - loss: 12.4447 - precision_m: 0.6802\n",
            "Epoch 21/30\n",
            "43/43 - 0s - loss: 11.2803 - precision_m: 0.6767\n",
            "Epoch 22/30\n",
            "43/43 - 0s - loss: 10.6213 - precision_m: 0.6767\n",
            "Epoch 23/30\n",
            "43/43 - 0s - loss: 10.1493 - precision_m: 0.6802\n",
            "Epoch 24/30\n",
            "43/43 - 0s - loss: 9.5831 - precision_m: 0.6733\n",
            "Epoch 25/30\n",
            "43/43 - 0s - loss: 9.2641 - precision_m: 0.6767\n",
            "Epoch 26/30\n",
            "43/43 - 0s - loss: 8.5334 - precision_m: 0.6733\n",
            "Epoch 27/30\n",
            "43/43 - 0s - loss: 8.3149 - precision_m: 0.6802\n",
            "Epoch 28/30\n",
            "43/43 - 0s - loss: 7.8518 - precision_m: 0.6767\n",
            "Epoch 29/30\n",
            "43/43 - 0s - loss: 7.5547 - precision_m: 0.6837\n",
            "Epoch 30/30\n",
            "43/43 - 0s - loss: 7.7500 - precision_m: 0.6802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7464918590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bg1OQqpHzRN"
      },
      "source": [
        "secondModel = Sequential([\n",
        "    Dense(units=64, input_shape=(14,), activation='relu'), #First hidden layer\n",
        "    Dense(units=32, activation='relu'),\n",
        "    Dense(units=16, activation='relu'),\n",
        "    Dense(units=2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzzOs3RjH7ct"
      },
      "source": [
        "secondModel.compile(optimizer=Adam(learning_rate=0.001),loss='sparse_categorical_crossentropy', metrics=[precision_m])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHK30sHqIAeY",
        "outputId": "08d1fe26-7434-4921-e407-c4472034ed43"
      },
      "source": [
        "secondModel.fit(x=train, y=train_y, batch_size=10, epochs=30, shuffle=True, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "43/43 - 0s - loss: 17.0553 - precision_m: 0.6767\n",
            "Epoch 2/30\n",
            "43/43 - 0s - loss: 0.6959 - precision_m: 0.6767\n",
            "Epoch 3/30\n",
            "43/43 - 0s - loss: 0.6916 - precision_m: 0.6802\n",
            "Epoch 4/30\n",
            "43/43 - 0s - loss: 0.6750 - precision_m: 0.6767\n",
            "Epoch 5/30\n",
            "43/43 - 0s - loss: 0.6666 - precision_m: 0.6802\n",
            "Epoch 6/30\n",
            "43/43 - 0s - loss: 0.6595 - precision_m: 0.6767\n",
            "Epoch 7/30\n",
            "43/43 - 0s - loss: 0.6533 - precision_m: 0.6837\n",
            "Epoch 8/30\n",
            "43/43 - 0s - loss: 0.6507 - precision_m: 0.6837\n",
            "Epoch 9/30\n",
            "43/43 - 0s - loss: 0.6560 - precision_m: 0.6802\n",
            "Epoch 10/30\n",
            "43/43 - 0s - loss: 0.6421 - precision_m: 0.6837\n",
            "Epoch 11/30\n",
            "43/43 - 0s - loss: 0.6385 - precision_m: 0.6733\n",
            "Epoch 12/30\n",
            "43/43 - 0s - loss: 0.6360 - precision_m: 0.6802\n",
            "Epoch 13/30\n",
            "43/43 - 0s - loss: 0.6339 - precision_m: 0.6837\n",
            "Epoch 14/30\n",
            "43/43 - 0s - loss: 0.6319 - precision_m: 0.6802\n",
            "Epoch 15/30\n",
            "43/43 - 0s - loss: 0.6305 - precision_m: 0.6837\n",
            "Epoch 16/30\n",
            "43/43 - 0s - loss: 0.6293 - precision_m: 0.6767\n",
            "Epoch 17/30\n",
            "43/43 - 0s - loss: 0.6286 - precision_m: 0.6767\n",
            "Epoch 18/30\n",
            "43/43 - 0s - loss: 0.6277 - precision_m: 0.6802\n",
            "Epoch 19/30\n",
            "43/43 - 0s - loss: 0.6272 - precision_m: 0.6767\n",
            "Epoch 20/30\n",
            "43/43 - 0s - loss: 0.6267 - precision_m: 0.6802\n",
            "Epoch 21/30\n",
            "43/43 - 0s - loss: 0.6263 - precision_m: 0.6767\n",
            "Epoch 22/30\n",
            "43/43 - 0s - loss: 0.6261 - precision_m: 0.6802\n",
            "Epoch 23/30\n",
            "43/43 - 0s - loss: 0.6259 - precision_m: 0.6767\n",
            "Epoch 24/30\n",
            "43/43 - 0s - loss: 0.6256 - precision_m: 0.6802\n",
            "Epoch 25/30\n",
            "43/43 - 0s - loss: 0.6255 - precision_m: 0.6767\n",
            "Epoch 26/30\n",
            "43/43 - 0s - loss: 0.6255 - precision_m: 0.6733\n",
            "Epoch 27/30\n",
            "43/43 - 0s - loss: 0.6252 - precision_m: 0.6802\n",
            "Epoch 28/30\n",
            "43/43 - 0s - loss: 0.6251 - precision_m: 0.6837\n",
            "Epoch 29/30\n",
            "43/43 - 0s - loss: 0.6251 - precision_m: 0.6733\n",
            "Epoch 30/30\n",
            "43/43 - 0s - loss: 0.6252 - precision_m: 0.6767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f745d5dba50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tmv5hOWfJadA"
      },
      "source": [
        "Despues de hacer dos modelos, de los cuales estuve cambiando valores en tanto numero de capas, unidades y learning rate, el mejor modelo fue el primero que hice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gvi63jWLL23m"
      },
      "source": [
        "# e) Entrena en Google colab por 500 épocas el mejor modelo obtenido en el inciso c) utilizando:\n",
        "* CPU:  33.4 s\n",
        "* GPU: 45.9s\n",
        "* TPU: 11.6S"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti84Xo4dL8E9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f65e33a-61c9-47f9-bb50-5ba1bc109837"
      },
      "source": [
        "%%time\n",
        "model.fit(x=train, y=train_y, batch_size=10, epochs=500, shuffle=True, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "43/43 - 0s - loss: 7.1017 - precision_m: 0.6802\n",
            "Epoch 2/500\n",
            "43/43 - 0s - loss: 6.8400 - precision_m: 0.6802\n",
            "Epoch 3/500\n",
            "43/43 - 0s - loss: 7.2684 - precision_m: 0.6837\n",
            "Epoch 4/500\n",
            "43/43 - 0s - loss: 6.6268 - precision_m: 0.6802\n",
            "Epoch 5/500\n",
            "43/43 - 0s - loss: 5.9699 - precision_m: 0.6767\n",
            "Epoch 6/500\n",
            "43/43 - 0s - loss: 5.5595 - precision_m: 0.6802\n",
            "Epoch 7/500\n",
            "43/43 - 0s - loss: 5.2671 - precision_m: 0.6733\n",
            "Epoch 8/500\n",
            "43/43 - 0s - loss: 5.0920 - precision_m: 0.6733\n",
            "Epoch 9/500\n",
            "43/43 - 0s - loss: 7.5916 - precision_m: 0.6837\n",
            "Epoch 10/500\n",
            "43/43 - 0s - loss: 5.5774 - precision_m: 0.6767\n",
            "Epoch 11/500\n",
            "43/43 - 0s - loss: 5.7318 - precision_m: 0.6733\n",
            "Epoch 12/500\n",
            "43/43 - 0s - loss: 4.3842 - precision_m: 0.6802\n",
            "Epoch 13/500\n",
            "43/43 - 0s - loss: 3.8185 - precision_m: 0.6837\n",
            "Epoch 14/500\n",
            "43/43 - 0s - loss: 3.5815 - precision_m: 0.6767\n",
            "Epoch 15/500\n",
            "43/43 - 0s - loss: 3.3156 - precision_m: 0.6802\n",
            "Epoch 16/500\n",
            "43/43 - 0s - loss: 3.5975 - precision_m: 0.6837\n",
            "Epoch 17/500\n",
            "43/43 - 0s - loss: 3.2084 - precision_m: 0.6802\n",
            "Epoch 18/500\n",
            "43/43 - 0s - loss: 3.1225 - precision_m: 0.6767\n",
            "Epoch 19/500\n",
            "43/43 - 0s - loss: 3.0758 - precision_m: 0.6802\n",
            "Epoch 20/500\n",
            "43/43 - 0s - loss: 2.9117 - precision_m: 0.6837\n",
            "Epoch 21/500\n",
            "43/43 - 0s - loss: 3.5348 - precision_m: 0.6837\n",
            "Epoch 22/500\n",
            "43/43 - 0s - loss: 3.0567 - precision_m: 0.6802\n",
            "Epoch 23/500\n",
            "43/43 - 0s - loss: 2.6218 - precision_m: 0.6802\n",
            "Epoch 24/500\n",
            "43/43 - 0s - loss: 2.8613 - precision_m: 0.6837\n",
            "Epoch 25/500\n",
            "43/43 - 0s - loss: 2.6959 - precision_m: 0.6802\n",
            "Epoch 26/500\n",
            "43/43 - 0s - loss: 2.5379 - precision_m: 0.6767\n",
            "Epoch 27/500\n",
            "43/43 - 0s - loss: 2.4047 - precision_m: 0.6767\n",
            "Epoch 28/500\n",
            "43/43 - 0s - loss: 2.3614 - precision_m: 0.6802\n",
            "Epoch 29/500\n",
            "43/43 - 0s - loss: 2.4127 - precision_m: 0.6802\n",
            "Epoch 30/500\n",
            "43/43 - 0s - loss: 2.3936 - precision_m: 0.6802\n",
            "Epoch 31/500\n",
            "43/43 - 0s - loss: 2.2105 - precision_m: 0.6802\n",
            "Epoch 32/500\n",
            "43/43 - 0s - loss: 2.3967 - precision_m: 0.6733\n",
            "Epoch 33/500\n",
            "43/43 - 0s - loss: 2.4130 - precision_m: 0.6802\n",
            "Epoch 34/500\n",
            "43/43 - 0s - loss: 2.1968 - precision_m: 0.6802\n",
            "Epoch 35/500\n",
            "43/43 - 0s - loss: 2.2910 - precision_m: 0.6767\n",
            "Epoch 36/500\n",
            "43/43 - 0s - loss: 2.3518 - precision_m: 0.6767\n",
            "Epoch 37/500\n",
            "43/43 - 0s - loss: 2.0890 - precision_m: 0.6767\n",
            "Epoch 38/500\n",
            "43/43 - 0s - loss: 2.4612 - precision_m: 0.6802\n",
            "Epoch 39/500\n",
            "43/43 - 0s - loss: 2.0340 - precision_m: 0.6767\n",
            "Epoch 40/500\n",
            "43/43 - 0s - loss: 2.8341 - precision_m: 0.6767\n",
            "Epoch 41/500\n",
            "43/43 - 0s - loss: 2.4220 - precision_m: 0.6802\n",
            "Epoch 42/500\n",
            "43/43 - 0s - loss: 2.3359 - precision_m: 0.6767\n",
            "Epoch 43/500\n",
            "43/43 - 0s - loss: 2.3241 - precision_m: 0.6837\n",
            "Epoch 44/500\n",
            "43/43 - 0s - loss: 2.5678 - precision_m: 0.6837\n",
            "Epoch 45/500\n",
            "43/43 - 0s - loss: 1.9134 - precision_m: 0.6767\n",
            "Epoch 46/500\n",
            "43/43 - 0s - loss: 1.8763 - precision_m: 0.6802\n",
            "Epoch 47/500\n",
            "43/43 - 0s - loss: 1.9553 - precision_m: 0.6802\n",
            "Epoch 48/500\n",
            "43/43 - 0s - loss: 1.8135 - precision_m: 0.6802\n",
            "Epoch 49/500\n",
            "43/43 - 0s - loss: 1.9508 - precision_m: 0.6802\n",
            "Epoch 50/500\n",
            "43/43 - 0s - loss: 1.8074 - precision_m: 0.6802\n",
            "Epoch 51/500\n",
            "43/43 - 0s - loss: 1.7583 - precision_m: 0.6837\n",
            "Epoch 52/500\n",
            "43/43 - 0s - loss: 1.6527 - precision_m: 0.6802\n",
            "Epoch 53/500\n",
            "43/43 - 0s - loss: 1.5836 - precision_m: 0.6837\n",
            "Epoch 54/500\n",
            "43/43 - 0s - loss: 1.6552 - precision_m: 0.6802\n",
            "Epoch 55/500\n",
            "43/43 - 0s - loss: 1.7154 - precision_m: 0.6767\n",
            "Epoch 56/500\n",
            "43/43 - 0s - loss: 1.6293 - precision_m: 0.6767\n",
            "Epoch 57/500\n",
            "43/43 - 0s - loss: 1.9261 - precision_m: 0.6837\n",
            "Epoch 58/500\n",
            "43/43 - 0s - loss: 1.6245 - precision_m: 0.6767\n",
            "Epoch 59/500\n",
            "43/43 - 0s - loss: 1.6476 - precision_m: 0.6767\n",
            "Epoch 60/500\n",
            "43/43 - 0s - loss: 1.6843 - precision_m: 0.6767\n",
            "Epoch 61/500\n",
            "43/43 - 0s - loss: 1.4928 - precision_m: 0.6802\n",
            "Epoch 62/500\n",
            "43/43 - 0s - loss: 1.8623 - precision_m: 0.6767\n",
            "Epoch 63/500\n",
            "43/43 - 0s - loss: 1.4185 - precision_m: 0.6802\n",
            "Epoch 64/500\n",
            "43/43 - 0s - loss: 1.7143 - precision_m: 0.6802\n",
            "Epoch 65/500\n",
            "43/43 - 0s - loss: 1.8739 - precision_m: 0.6802\n",
            "Epoch 66/500\n",
            "43/43 - 0s - loss: 1.6177 - precision_m: 0.6802\n",
            "Epoch 67/500\n",
            "43/43 - 0s - loss: 1.3969 - precision_m: 0.6837\n",
            "Epoch 68/500\n",
            "43/43 - 0s - loss: 1.2744 - precision_m: 0.6837\n",
            "Epoch 69/500\n",
            "43/43 - 0s - loss: 1.3486 - precision_m: 0.6837\n",
            "Epoch 70/500\n",
            "43/43 - 0s - loss: 1.6319 - precision_m: 0.6802\n",
            "Epoch 71/500\n",
            "43/43 - 0s - loss: 1.4524 - precision_m: 0.6802\n",
            "Epoch 72/500\n",
            "43/43 - 0s - loss: 1.1282 - precision_m: 0.6837\n",
            "Epoch 73/500\n",
            "43/43 - 0s - loss: 1.4317 - precision_m: 0.6837\n",
            "Epoch 74/500\n",
            "43/43 - 0s - loss: 1.4388 - precision_m: 0.6802\n",
            "Epoch 75/500\n",
            "43/43 - 0s - loss: 1.2240 - precision_m: 0.6802\n",
            "Epoch 76/500\n",
            "43/43 - 0s - loss: 1.0897 - precision_m: 0.6802\n",
            "Epoch 77/500\n",
            "43/43 - 0s - loss: 1.1198 - precision_m: 0.6802\n",
            "Epoch 78/500\n",
            "43/43 - 0s - loss: 1.0601 - precision_m: 0.6802\n",
            "Epoch 79/500\n",
            "43/43 - 0s - loss: 2.0410 - precision_m: 0.6837\n",
            "Epoch 80/500\n",
            "43/43 - 0s - loss: 1.7418 - precision_m: 0.6767\n",
            "Epoch 81/500\n",
            "43/43 - 0s - loss: 1.1776 - precision_m: 0.6837\n",
            "Epoch 82/500\n",
            "43/43 - 0s - loss: 1.6488 - precision_m: 0.6767\n",
            "Epoch 83/500\n",
            "43/43 - 0s - loss: 1.1903 - precision_m: 0.6837\n",
            "Epoch 84/500\n",
            "43/43 - 0s - loss: 0.9957 - precision_m: 0.6733\n",
            "Epoch 85/500\n",
            "43/43 - 0s - loss: 1.1907 - precision_m: 0.6837\n",
            "Epoch 86/500\n",
            "43/43 - 0s - loss: 1.5629 - precision_m: 0.6837\n",
            "Epoch 87/500\n",
            "43/43 - 0s - loss: 1.5695 - precision_m: 0.6767\n",
            "Epoch 88/500\n",
            "43/43 - 0s - loss: 1.3638 - precision_m: 0.6802\n",
            "Epoch 89/500\n",
            "43/43 - 0s - loss: 0.9665 - precision_m: 0.6802\n",
            "Epoch 90/500\n",
            "43/43 - 0s - loss: 0.8957 - precision_m: 0.6767\n",
            "Epoch 91/500\n",
            "43/43 - 0s - loss: 0.9914 - precision_m: 0.6802\n",
            "Epoch 92/500\n",
            "43/43 - 0s - loss: 1.1395 - precision_m: 0.6837\n",
            "Epoch 93/500\n",
            "43/43 - 0s - loss: 1.4223 - precision_m: 0.6767\n",
            "Epoch 94/500\n",
            "43/43 - 0s - loss: 1.3963 - precision_m: 0.6767\n",
            "Epoch 95/500\n",
            "43/43 - 0s - loss: 1.2934 - precision_m: 0.6802\n",
            "Epoch 96/500\n",
            "43/43 - 0s - loss: 0.8861 - precision_m: 0.6767\n",
            "Epoch 97/500\n",
            "43/43 - 0s - loss: 0.8419 - precision_m: 0.6802\n",
            "Epoch 98/500\n",
            "43/43 - 0s - loss: 1.1758 - precision_m: 0.6802\n",
            "Epoch 99/500\n",
            "43/43 - 0s - loss: 1.2780 - precision_m: 0.6767\n",
            "Epoch 100/500\n",
            "43/43 - 0s - loss: 1.0205 - precision_m: 0.6802\n",
            "Epoch 101/500\n",
            "43/43 - 0s - loss: 0.9405 - precision_m: 0.6767\n",
            "Epoch 102/500\n",
            "43/43 - 0s - loss: 1.0312 - precision_m: 0.6767\n",
            "Epoch 103/500\n",
            "43/43 - 0s - loss: 1.2470 - precision_m: 0.6767\n",
            "Epoch 104/500\n",
            "43/43 - 0s - loss: 4.7203 - precision_m: 0.6733\n",
            "Epoch 105/500\n",
            "43/43 - 0s - loss: 1.1956 - precision_m: 0.6802\n",
            "Epoch 106/500\n",
            "43/43 - 0s - loss: 1.4503 - precision_m: 0.6767\n",
            "Epoch 107/500\n",
            "43/43 - 0s - loss: 0.8990 - precision_m: 0.6802\n",
            "Epoch 108/500\n",
            "43/43 - 0s - loss: 1.2616 - precision_m: 0.6802\n",
            "Epoch 109/500\n",
            "43/43 - 0s - loss: 0.8523 - precision_m: 0.6837\n",
            "Epoch 110/500\n",
            "43/43 - 0s - loss: 0.8376 - precision_m: 0.6802\n",
            "Epoch 111/500\n",
            "43/43 - 0s - loss: 1.0830 - precision_m: 0.6767\n",
            "Epoch 112/500\n",
            "43/43 - 0s - loss: 1.1894 - precision_m: 0.6837\n",
            "Epoch 113/500\n",
            "43/43 - 0s - loss: 1.0961 - precision_m: 0.6698\n",
            "Epoch 114/500\n",
            "43/43 - 0s - loss: 0.9564 - precision_m: 0.6733\n",
            "Epoch 115/500\n",
            "43/43 - 0s - loss: 1.1042 - precision_m: 0.6802\n",
            "Epoch 116/500\n",
            "43/43 - 0s - loss: 1.1321 - precision_m: 0.6767\n",
            "Epoch 117/500\n",
            "43/43 - 0s - loss: 0.8240 - precision_m: 0.6802\n",
            "Epoch 118/500\n",
            "43/43 - 0s - loss: 0.7924 - precision_m: 0.6802\n",
            "Epoch 119/500\n",
            "43/43 - 0s - loss: 0.7236 - precision_m: 0.6802\n",
            "Epoch 120/500\n",
            "43/43 - 0s - loss: 0.7199 - precision_m: 0.6802\n",
            "Epoch 121/500\n",
            "43/43 - 0s - loss: 0.7354 - precision_m: 0.6802\n",
            "Epoch 122/500\n",
            "43/43 - 0s - loss: 1.2758 - precision_m: 0.6767\n",
            "Epoch 123/500\n",
            "43/43 - 0s - loss: 0.8473 - precision_m: 0.6767\n",
            "Epoch 124/500\n",
            "43/43 - 0s - loss: 0.7588 - precision_m: 0.6837\n",
            "Epoch 125/500\n",
            "43/43 - 0s - loss: 0.7320 - precision_m: 0.6802\n",
            "Epoch 126/500\n",
            "43/43 - 0s - loss: 0.8848 - precision_m: 0.6802\n",
            "Epoch 127/500\n",
            "43/43 - 0s - loss: 0.7192 - precision_m: 0.6837\n",
            "Epoch 128/500\n",
            "43/43 - 0s - loss: 0.8444 - precision_m: 0.6837\n",
            "Epoch 129/500\n",
            "43/43 - 0s - loss: 1.4108 - precision_m: 0.6767\n",
            "Epoch 130/500\n",
            "43/43 - 0s - loss: 0.9173 - precision_m: 0.6767\n",
            "Epoch 131/500\n",
            "43/43 - 0s - loss: 0.8613 - precision_m: 0.6802\n",
            "Epoch 132/500\n",
            "43/43 - 0s - loss: 0.7013 - precision_m: 0.6802\n",
            "Epoch 133/500\n",
            "43/43 - 0s - loss: 0.8125 - precision_m: 0.6733\n",
            "Epoch 134/500\n",
            "43/43 - 0s - loss: 1.2104 - precision_m: 0.6733\n",
            "Epoch 135/500\n",
            "43/43 - 0s - loss: 0.9462 - precision_m: 0.6802\n",
            "Epoch 136/500\n",
            "43/43 - 0s - loss: 0.6865 - precision_m: 0.6802\n",
            "Epoch 137/500\n",
            "43/43 - 0s - loss: 0.7537 - precision_m: 0.6837\n",
            "Epoch 138/500\n",
            "43/43 - 0s - loss: 1.1401 - precision_m: 0.6767\n",
            "Epoch 139/500\n",
            "43/43 - 0s - loss: 0.7379 - precision_m: 0.6802\n",
            "Epoch 140/500\n",
            "43/43 - 0s - loss: 0.7876 - precision_m: 0.6802\n",
            "Epoch 141/500\n",
            "43/43 - 0s - loss: 1.2479 - precision_m: 0.6767\n",
            "Epoch 142/500\n",
            "43/43 - 0s - loss: 0.7535 - precision_m: 0.6767\n",
            "Epoch 143/500\n",
            "43/43 - 0s - loss: 0.9969 - precision_m: 0.6802\n",
            "Epoch 144/500\n",
            "43/43 - 0s - loss: 0.6930 - precision_m: 0.6767\n",
            "Epoch 145/500\n",
            "43/43 - 0s - loss: 0.8582 - precision_m: 0.6733\n",
            "Epoch 146/500\n",
            "43/43 - 0s - loss: 0.7465 - precision_m: 0.6767\n",
            "Epoch 147/500\n",
            "43/43 - 0s - loss: 1.3346 - precision_m: 0.6767\n",
            "Epoch 148/500\n",
            "43/43 - 0s - loss: 0.8583 - precision_m: 0.6802\n",
            "Epoch 149/500\n",
            "43/43 - 0s - loss: 0.9896 - precision_m: 0.6802\n",
            "Epoch 150/500\n",
            "43/43 - 0s - loss: 0.7109 - precision_m: 0.6802\n",
            "Epoch 151/500\n",
            "43/43 - 0s - loss: 0.8365 - precision_m: 0.6802\n",
            "Epoch 152/500\n",
            "43/43 - 0s - loss: 0.7064 - precision_m: 0.6802\n",
            "Epoch 153/500\n",
            "43/43 - 0s - loss: 0.9275 - precision_m: 0.6767\n",
            "Epoch 154/500\n",
            "43/43 - 0s - loss: 0.6749 - precision_m: 0.6802\n",
            "Epoch 155/500\n",
            "43/43 - 0s - loss: 0.8391 - precision_m: 0.6767\n",
            "Epoch 156/500\n",
            "43/43 - 0s - loss: 0.6101 - precision_m: 0.6767\n",
            "Epoch 157/500\n",
            "43/43 - 0s - loss: 0.6902 - precision_m: 0.6767\n",
            "Epoch 158/500\n",
            "43/43 - 0s - loss: 0.7843 - precision_m: 0.6837\n",
            "Epoch 159/500\n",
            "43/43 - 0s - loss: 0.7846 - precision_m: 0.6802\n",
            "Epoch 160/500\n",
            "43/43 - 0s - loss: 0.5888 - precision_m: 0.6837\n",
            "Epoch 161/500\n",
            "43/43 - 0s - loss: 0.6369 - precision_m: 0.6767\n",
            "Epoch 162/500\n",
            "43/43 - 0s - loss: 1.5631 - precision_m: 0.6802\n",
            "Epoch 163/500\n",
            "43/43 - 0s - loss: 0.8541 - precision_m: 0.6837\n",
            "Epoch 164/500\n",
            "43/43 - 0s - loss: 1.0096 - precision_m: 0.6802\n",
            "Epoch 165/500\n",
            "43/43 - 0s - loss: 0.8403 - precision_m: 0.6733\n",
            "Epoch 166/500\n",
            "43/43 - 0s - loss: 0.8381 - precision_m: 0.6802\n",
            "Epoch 167/500\n",
            "43/43 - 0s - loss: 0.6402 - precision_m: 0.6733\n",
            "Epoch 168/500\n",
            "43/43 - 0s - loss: 0.6553 - precision_m: 0.6767\n",
            "Epoch 169/500\n",
            "43/43 - 0s - loss: 0.5711 - precision_m: 0.6837\n",
            "Epoch 170/500\n",
            "43/43 - 0s - loss: 0.7980 - precision_m: 0.6837\n",
            "Epoch 171/500\n",
            "43/43 - 0s - loss: 0.5544 - precision_m: 0.6802\n",
            "Epoch 172/500\n",
            "43/43 - 0s - loss: 0.6323 - precision_m: 0.6802\n",
            "Epoch 173/500\n",
            "43/43 - 0s - loss: 1.0672 - precision_m: 0.6802\n",
            "Epoch 174/500\n",
            "43/43 - 0s - loss: 0.9771 - precision_m: 0.6767\n",
            "Epoch 175/500\n",
            "43/43 - 0s - loss: 0.6195 - precision_m: 0.6802\n",
            "Epoch 176/500\n",
            "43/43 - 0s - loss: 0.5814 - precision_m: 0.6837\n",
            "Epoch 177/500\n",
            "43/43 - 0s - loss: 1.1015 - precision_m: 0.6837\n",
            "Epoch 178/500\n",
            "43/43 - 0s - loss: 0.7825 - precision_m: 0.6733\n",
            "Epoch 179/500\n",
            "43/43 - 0s - loss: 0.7020 - precision_m: 0.6837\n",
            "Epoch 180/500\n",
            "43/43 - 0s - loss: 1.1822 - precision_m: 0.6837\n",
            "Epoch 181/500\n",
            "43/43 - 0s - loss: 1.0979 - precision_m: 0.6802\n",
            "Epoch 182/500\n",
            "43/43 - 0s - loss: 0.7460 - precision_m: 0.6802\n",
            "Epoch 183/500\n",
            "43/43 - 0s - loss: 0.6492 - precision_m: 0.6767\n",
            "Epoch 184/500\n",
            "43/43 - 0s - loss: 0.6015 - precision_m: 0.6837\n",
            "Epoch 185/500\n",
            "43/43 - 0s - loss: 0.7455 - precision_m: 0.6802\n",
            "Epoch 186/500\n",
            "43/43 - 0s - loss: 0.9357 - precision_m: 0.6837\n",
            "Epoch 187/500\n",
            "43/43 - 0s - loss: 0.5937 - precision_m: 0.6837\n",
            "Epoch 188/500\n",
            "43/43 - 0s - loss: 1.4926 - precision_m: 0.6767\n",
            "Epoch 189/500\n",
            "43/43 - 0s - loss: 0.6789 - precision_m: 0.6767\n",
            "Epoch 190/500\n",
            "43/43 - 0s - loss: 0.7597 - precision_m: 0.6802\n",
            "Epoch 191/500\n",
            "43/43 - 0s - loss: 2.6683 - precision_m: 0.6837\n",
            "Epoch 192/500\n",
            "43/43 - 0s - loss: 2.5228 - precision_m: 0.6802\n",
            "Epoch 193/500\n",
            "43/43 - 0s - loss: 0.9627 - precision_m: 0.6733\n",
            "Epoch 194/500\n",
            "43/43 - 0s - loss: 0.8971 - precision_m: 0.6802\n",
            "Epoch 195/500\n",
            "43/43 - 0s - loss: 1.0412 - precision_m: 0.6767\n",
            "Epoch 196/500\n",
            "43/43 - 0s - loss: 0.5981 - precision_m: 0.6733\n",
            "Epoch 197/500\n",
            "43/43 - 0s - loss: 0.7019 - precision_m: 0.6802\n",
            "Epoch 198/500\n",
            "43/43 - 0s - loss: 1.3360 - precision_m: 0.6837\n",
            "Epoch 199/500\n",
            "43/43 - 0s - loss: 0.6987 - precision_m: 0.6767\n",
            "Epoch 200/500\n",
            "43/43 - 0s - loss: 0.6051 - precision_m: 0.6837\n",
            "Epoch 201/500\n",
            "43/43 - 0s - loss: 0.5481 - precision_m: 0.6802\n",
            "Epoch 202/500\n",
            "43/43 - 0s - loss: 0.5235 - precision_m: 0.6837\n",
            "Epoch 203/500\n",
            "43/43 - 0s - loss: 0.5590 - precision_m: 0.6767\n",
            "Epoch 204/500\n",
            "43/43 - 0s - loss: 0.8161 - precision_m: 0.6733\n",
            "Epoch 205/500\n",
            "43/43 - 0s - loss: 0.6236 - precision_m: 0.6802\n",
            "Epoch 206/500\n",
            "43/43 - 0s - loss: 0.5720 - precision_m: 0.6802\n",
            "Epoch 207/500\n",
            "43/43 - 0s - loss: 0.4989 - precision_m: 0.6837\n",
            "Epoch 208/500\n",
            "43/43 - 0s - loss: 0.7733 - precision_m: 0.6767\n",
            "Epoch 209/500\n",
            "43/43 - 0s - loss: 0.6239 - precision_m: 0.6802\n",
            "Epoch 210/500\n",
            "43/43 - 0s - loss: 0.6163 - precision_m: 0.6802\n",
            "Epoch 211/500\n",
            "43/43 - 0s - loss: 0.5745 - precision_m: 0.6802\n",
            "Epoch 212/500\n",
            "43/43 - 0s - loss: 0.8410 - precision_m: 0.6733\n",
            "Epoch 213/500\n",
            "43/43 - 0s - loss: 1.2591 - precision_m: 0.6733\n",
            "Epoch 214/500\n",
            "43/43 - 0s - loss: 0.7789 - precision_m: 0.6767\n",
            "Epoch 215/500\n",
            "43/43 - 0s - loss: 1.0704 - precision_m: 0.6767\n",
            "Epoch 216/500\n",
            "43/43 - 0s - loss: 0.8283 - precision_m: 0.6767\n",
            "Epoch 217/500\n",
            "43/43 - 0s - loss: 1.3936 - precision_m: 0.6802\n",
            "Epoch 218/500\n",
            "43/43 - 0s - loss: 0.8456 - precision_m: 0.6802\n",
            "Epoch 219/500\n",
            "43/43 - 0s - loss: 0.7313 - precision_m: 0.6837\n",
            "Epoch 220/500\n",
            "43/43 - 0s - loss: 0.7613 - precision_m: 0.6802\n",
            "Epoch 221/500\n",
            "43/43 - 0s - loss: 0.7281 - precision_m: 0.6802\n",
            "Epoch 222/500\n",
            "43/43 - 0s - loss: 0.6685 - precision_m: 0.6837\n",
            "Epoch 223/500\n",
            "43/43 - 0s - loss: 1.2859 - precision_m: 0.6837\n",
            "Epoch 224/500\n",
            "43/43 - 0s - loss: 0.8684 - precision_m: 0.6802\n",
            "Epoch 225/500\n",
            "43/43 - 0s - loss: 0.9438 - precision_m: 0.6802\n",
            "Epoch 226/500\n",
            "43/43 - 0s - loss: 0.7473 - precision_m: 0.6802\n",
            "Epoch 227/500\n",
            "43/43 - 0s - loss: 0.4928 - precision_m: 0.6733\n",
            "Epoch 228/500\n",
            "43/43 - 0s - loss: 0.8494 - precision_m: 0.6733\n",
            "Epoch 229/500\n",
            "43/43 - 0s - loss: 0.6403 - precision_m: 0.6767\n",
            "Epoch 230/500\n",
            "43/43 - 0s - loss: 0.5344 - precision_m: 0.6802\n",
            "Epoch 231/500\n",
            "43/43 - 0s - loss: 0.6602 - precision_m: 0.6802\n",
            "Epoch 232/500\n",
            "43/43 - 0s - loss: 0.9324 - precision_m: 0.6837\n",
            "Epoch 233/500\n",
            "43/43 - 0s - loss: 0.5614 - precision_m: 0.6767\n",
            "Epoch 234/500\n",
            "43/43 - 0s - loss: 0.7359 - precision_m: 0.6802\n",
            "Epoch 235/500\n",
            "43/43 - 0s - loss: 1.5252 - precision_m: 0.6837\n",
            "Epoch 236/500\n",
            "43/43 - 0s - loss: 0.6347 - precision_m: 0.6767\n",
            "Epoch 237/500\n",
            "43/43 - 0s - loss: 1.1977 - precision_m: 0.6767\n",
            "Epoch 238/500\n",
            "43/43 - 0s - loss: 0.6221 - precision_m: 0.6837\n",
            "Epoch 239/500\n",
            "43/43 - 0s - loss: 0.4853 - precision_m: 0.6837\n",
            "Epoch 240/500\n",
            "43/43 - 0s - loss: 0.4894 - precision_m: 0.6802\n",
            "Epoch 241/500\n",
            "43/43 - 0s - loss: 0.5160 - precision_m: 0.6802\n",
            "Epoch 242/500\n",
            "43/43 - 0s - loss: 0.5609 - precision_m: 0.6802\n",
            "Epoch 243/500\n",
            "43/43 - 0s - loss: 0.7349 - precision_m: 0.6837\n",
            "Epoch 244/500\n",
            "43/43 - 0s - loss: 1.9370 - precision_m: 0.6802\n",
            "Epoch 245/500\n",
            "43/43 - 0s - loss: 1.0561 - precision_m: 0.6802\n",
            "Epoch 246/500\n",
            "43/43 - 0s - loss: 1.0920 - precision_m: 0.6837\n",
            "Epoch 247/500\n",
            "43/43 - 0s - loss: 0.4875 - precision_m: 0.6837\n",
            "Epoch 248/500\n",
            "43/43 - 0s - loss: 0.5242 - precision_m: 0.6802\n",
            "Epoch 249/500\n",
            "43/43 - 0s - loss: 0.6570 - precision_m: 0.6767\n",
            "Epoch 250/500\n",
            "43/43 - 0s - loss: 1.1750 - precision_m: 0.6767\n",
            "Epoch 251/500\n",
            "43/43 - 0s - loss: 0.8083 - precision_m: 0.6733\n",
            "Epoch 252/500\n",
            "43/43 - 0s - loss: 0.6566 - precision_m: 0.6802\n",
            "Epoch 253/500\n",
            "43/43 - 0s - loss: 0.7260 - precision_m: 0.6802\n",
            "Epoch 254/500\n",
            "43/43 - 0s - loss: 0.5620 - precision_m: 0.6802\n",
            "Epoch 255/500\n",
            "43/43 - 0s - loss: 0.4898 - precision_m: 0.6802\n",
            "Epoch 256/500\n",
            "43/43 - 0s - loss: 0.4589 - precision_m: 0.6733\n",
            "Epoch 257/500\n",
            "43/43 - 0s - loss: 0.5185 - precision_m: 0.6767\n",
            "Epoch 258/500\n",
            "43/43 - 0s - loss: 0.4883 - precision_m: 0.6837\n",
            "Epoch 259/500\n",
            "43/43 - 0s - loss: 0.4946 - precision_m: 0.6802\n",
            "Epoch 260/500\n",
            "43/43 - 0s - loss: 0.4389 - precision_m: 0.6837\n",
            "Epoch 261/500\n",
            "43/43 - 0s - loss: 0.5593 - precision_m: 0.6802\n",
            "Epoch 262/500\n",
            "43/43 - 0s - loss: 0.5367 - precision_m: 0.6802\n",
            "Epoch 263/500\n",
            "43/43 - 0s - loss: 0.8813 - precision_m: 0.6802\n",
            "Epoch 264/500\n",
            "43/43 - 0s - loss: 0.6907 - precision_m: 0.6837\n",
            "Epoch 265/500\n",
            "43/43 - 0s - loss: 0.6050 - precision_m: 0.6802\n",
            "Epoch 266/500\n",
            "43/43 - 0s - loss: 1.3756 - precision_m: 0.6837\n",
            "Epoch 267/500\n",
            "43/43 - 0s - loss: 0.8466 - precision_m: 0.6802\n",
            "Epoch 268/500\n",
            "43/43 - 0s - loss: 0.6680 - precision_m: 0.6837\n",
            "Epoch 269/500\n",
            "43/43 - 0s - loss: 0.4545 - precision_m: 0.6767\n",
            "Epoch 270/500\n",
            "43/43 - 0s - loss: 0.5371 - precision_m: 0.6767\n",
            "Epoch 271/500\n",
            "43/43 - 0s - loss: 0.5807 - precision_m: 0.6802\n",
            "Epoch 272/500\n",
            "43/43 - 0s - loss: 0.5885 - precision_m: 0.6767\n",
            "Epoch 273/500\n",
            "43/43 - 0s - loss: 0.7061 - precision_m: 0.6767\n",
            "Epoch 274/500\n",
            "43/43 - 0s - loss: 0.4569 - precision_m: 0.6802\n",
            "Epoch 275/500\n",
            "43/43 - 0s - loss: 0.4363 - precision_m: 0.6802\n",
            "Epoch 276/500\n",
            "43/43 - 0s - loss: 0.5795 - precision_m: 0.6837\n",
            "Epoch 277/500\n",
            "43/43 - 0s - loss: 0.7781 - precision_m: 0.6767\n",
            "Epoch 278/500\n",
            "43/43 - 0s - loss: 0.6047 - precision_m: 0.6767\n",
            "Epoch 279/500\n",
            "43/43 - 0s - loss: 0.6259 - precision_m: 0.6802\n",
            "Epoch 280/500\n",
            "43/43 - 0s - loss: 0.9543 - precision_m: 0.6767\n",
            "Epoch 281/500\n",
            "43/43 - 0s - loss: 0.6582 - precision_m: 0.6733\n",
            "Epoch 282/500\n",
            "43/43 - 0s - loss: 0.5507 - precision_m: 0.6802\n",
            "Epoch 283/500\n",
            "43/43 - 0s - loss: 0.5667 - precision_m: 0.6767\n",
            "Epoch 284/500\n",
            "43/43 - 0s - loss: 0.6065 - precision_m: 0.6802\n",
            "Epoch 285/500\n",
            "43/43 - 0s - loss: 0.4748 - precision_m: 0.6802\n",
            "Epoch 286/500\n",
            "43/43 - 0s - loss: 0.8884 - precision_m: 0.6802\n",
            "Epoch 287/500\n",
            "43/43 - 0s - loss: 0.7076 - precision_m: 0.6802\n",
            "Epoch 288/500\n",
            "43/43 - 0s - loss: 0.9597 - precision_m: 0.6767\n",
            "Epoch 289/500\n",
            "43/43 - 0s - loss: 0.8728 - precision_m: 0.6837\n",
            "Epoch 290/500\n",
            "43/43 - 0s - loss: 0.4965 - precision_m: 0.6802\n",
            "Epoch 291/500\n",
            "43/43 - 0s - loss: 0.5071 - precision_m: 0.6837\n",
            "Epoch 292/500\n",
            "43/43 - 0s - loss: 1.4524 - precision_m: 0.6837\n",
            "Epoch 293/500\n",
            "43/43 - 0s - loss: 0.7042 - precision_m: 0.6802\n",
            "Epoch 294/500\n",
            "43/43 - 0s - loss: 0.7345 - precision_m: 0.6802\n",
            "Epoch 295/500\n",
            "43/43 - 0s - loss: 0.4616 - precision_m: 0.6802\n",
            "Epoch 296/500\n",
            "43/43 - 0s - loss: 0.6076 - precision_m: 0.6767\n",
            "Epoch 297/500\n",
            "43/43 - 0s - loss: 0.6847 - precision_m: 0.6802\n",
            "Epoch 298/500\n",
            "43/43 - 0s - loss: 0.4932 - precision_m: 0.6802\n",
            "Epoch 299/500\n",
            "43/43 - 0s - loss: 0.6811 - precision_m: 0.6767\n",
            "Epoch 300/500\n",
            "43/43 - 0s - loss: 0.7989 - precision_m: 0.6767\n",
            "Epoch 301/500\n",
            "43/43 - 0s - loss: 0.8209 - precision_m: 0.6802\n",
            "Epoch 302/500\n",
            "43/43 - 0s - loss: 0.5567 - precision_m: 0.6767\n",
            "Epoch 303/500\n",
            "43/43 - 0s - loss: 0.4986 - precision_m: 0.6802\n",
            "Epoch 304/500\n",
            "43/43 - 0s - loss: 0.6769 - precision_m: 0.6802\n",
            "Epoch 305/500\n",
            "43/43 - 0s - loss: 0.5815 - precision_m: 0.6802\n",
            "Epoch 306/500\n",
            "43/43 - 0s - loss: 0.4447 - precision_m: 0.6767\n",
            "Epoch 307/500\n",
            "43/43 - 0s - loss: 0.6570 - precision_m: 0.6802\n",
            "Epoch 308/500\n",
            "43/43 - 0s - loss: 0.5622 - precision_m: 0.6733\n",
            "Epoch 309/500\n",
            "43/43 - 0s - loss: 1.2520 - precision_m: 0.6767\n",
            "Epoch 310/500\n",
            "43/43 - 0s - loss: 0.7805 - precision_m: 0.6802\n",
            "Epoch 311/500\n",
            "43/43 - 0s - loss: 0.7435 - precision_m: 0.6802\n",
            "Epoch 312/500\n",
            "43/43 - 0s - loss: 0.5140 - precision_m: 0.6767\n",
            "Epoch 313/500\n",
            "43/43 - 0s - loss: 0.3808 - precision_m: 0.6802\n",
            "Epoch 314/500\n",
            "43/43 - 0s - loss: 0.5317 - precision_m: 0.6767\n",
            "Epoch 315/500\n",
            "43/43 - 0s - loss: 0.5909 - precision_m: 0.6767\n",
            "Epoch 316/500\n",
            "43/43 - 0s - loss: 0.9378 - precision_m: 0.6802\n",
            "Epoch 317/500\n",
            "43/43 - 0s - loss: 0.5638 - precision_m: 0.6837\n",
            "Epoch 318/500\n",
            "43/43 - 0s - loss: 0.8240 - precision_m: 0.6802\n",
            "Epoch 319/500\n",
            "43/43 - 0s - loss: 0.4443 - precision_m: 0.6767\n",
            "Epoch 320/500\n",
            "43/43 - 0s - loss: 0.6457 - precision_m: 0.6802\n",
            "Epoch 321/500\n",
            "43/43 - 0s - loss: 0.4875 - precision_m: 0.6767\n",
            "Epoch 322/500\n",
            "43/43 - 0s - loss: 0.5434 - precision_m: 0.6802\n",
            "Epoch 323/500\n",
            "43/43 - 0s - loss: 0.7174 - precision_m: 0.6767\n",
            "Epoch 324/500\n",
            "43/43 - 0s - loss: 0.6928 - precision_m: 0.6767\n",
            "Epoch 325/500\n",
            "43/43 - 0s - loss: 0.5403 - precision_m: 0.6802\n",
            "Epoch 326/500\n",
            "43/43 - 0s - loss: 0.6257 - precision_m: 0.6733\n",
            "Epoch 327/500\n",
            "43/43 - 0s - loss: 1.1331 - precision_m: 0.6802\n",
            "Epoch 328/500\n",
            "43/43 - 0s - loss: 0.5699 - precision_m: 0.6802\n",
            "Epoch 329/500\n",
            "43/43 - 0s - loss: 0.3898 - precision_m: 0.6837\n",
            "Epoch 330/500\n",
            "43/43 - 0s - loss: 0.4914 - precision_m: 0.6767\n",
            "Epoch 331/500\n",
            "43/43 - 0s - loss: 0.6207 - precision_m: 0.6837\n",
            "Epoch 332/500\n",
            "43/43 - 0s - loss: 0.4326 - precision_m: 0.6802\n",
            "Epoch 333/500\n",
            "43/43 - 0s - loss: 0.3852 - precision_m: 0.6837\n",
            "Epoch 334/500\n",
            "43/43 - 0s - loss: 0.3588 - precision_m: 0.6837\n",
            "Epoch 335/500\n",
            "43/43 - 0s - loss: 0.7798 - precision_m: 0.6802\n",
            "Epoch 336/500\n",
            "43/43 - 0s - loss: 0.4949 - precision_m: 0.6767\n",
            "Epoch 337/500\n",
            "43/43 - 0s - loss: 0.5073 - precision_m: 0.6837\n",
            "Epoch 338/500\n",
            "43/43 - 0s - loss: 0.6109 - precision_m: 0.6837\n",
            "Epoch 339/500\n",
            "43/43 - 0s - loss: 1.0859 - precision_m: 0.6733\n",
            "Epoch 340/500\n",
            "43/43 - 0s - loss: 0.5409 - precision_m: 0.6767\n",
            "Epoch 341/500\n",
            "43/43 - 0s - loss: 0.6521 - precision_m: 0.6802\n",
            "Epoch 342/500\n",
            "43/43 - 0s - loss: 0.5234 - precision_m: 0.6767\n",
            "Epoch 343/500\n",
            "43/43 - 0s - loss: 0.5568 - precision_m: 0.6767\n",
            "Epoch 344/500\n",
            "43/43 - 0s - loss: 0.5300 - precision_m: 0.6802\n",
            "Epoch 345/500\n",
            "43/43 - 0s - loss: 0.6214 - precision_m: 0.6802\n",
            "Epoch 346/500\n",
            "43/43 - 0s - loss: 0.5849 - precision_m: 0.6733\n",
            "Epoch 347/500\n",
            "43/43 - 0s - loss: 0.4605 - precision_m: 0.6767\n",
            "Epoch 348/500\n",
            "43/43 - 0s - loss: 0.5525 - precision_m: 0.6767\n",
            "Epoch 349/500\n",
            "43/43 - 0s - loss: 0.4419 - precision_m: 0.6802\n",
            "Epoch 350/500\n",
            "43/43 - 0s - loss: 0.4300 - precision_m: 0.6837\n",
            "Epoch 351/500\n",
            "43/43 - 0s - loss: 0.4625 - precision_m: 0.6837\n",
            "Epoch 352/500\n",
            "43/43 - 0s - loss: 0.7030 - precision_m: 0.6767\n",
            "Epoch 353/500\n",
            "43/43 - 0s - loss: 1.1062 - precision_m: 0.6802\n",
            "Epoch 354/500\n",
            "43/43 - 0s - loss: 0.4571 - precision_m: 0.6733\n",
            "Epoch 355/500\n",
            "43/43 - 0s - loss: 0.4646 - precision_m: 0.6837\n",
            "Epoch 356/500\n",
            "43/43 - 0s - loss: 0.8165 - precision_m: 0.6837\n",
            "Epoch 357/500\n",
            "43/43 - 0s - loss: 0.4729 - precision_m: 0.6767\n",
            "Epoch 358/500\n",
            "43/43 - 0s - loss: 0.6307 - precision_m: 0.6802\n",
            "Epoch 359/500\n",
            "43/43 - 0s - loss: 0.4036 - precision_m: 0.6767\n",
            "Epoch 360/500\n",
            "43/43 - 0s - loss: 0.4947 - precision_m: 0.6802\n",
            "Epoch 361/500\n",
            "43/43 - 0s - loss: 0.5887 - precision_m: 0.6767\n",
            "Epoch 362/500\n",
            "43/43 - 0s - loss: 0.4212 - precision_m: 0.6837\n",
            "Epoch 363/500\n",
            "43/43 - 0s - loss: 0.6184 - precision_m: 0.6802\n",
            "Epoch 364/500\n",
            "43/43 - 0s - loss: 0.4392 - precision_m: 0.6733\n",
            "Epoch 365/500\n",
            "43/43 - 0s - loss: 0.9358 - precision_m: 0.6837\n",
            "Epoch 366/500\n",
            "43/43 - 0s - loss: 0.4031 - precision_m: 0.6837\n",
            "Epoch 367/500\n",
            "43/43 - 0s - loss: 0.3272 - precision_m: 0.6802\n",
            "Epoch 368/500\n",
            "43/43 - 0s - loss: 0.3914 - precision_m: 0.6837\n",
            "Epoch 369/500\n",
            "43/43 - 0s - loss: 0.5329 - precision_m: 0.6837\n",
            "Epoch 370/500\n",
            "43/43 - 0s - loss: 0.6301 - precision_m: 0.6837\n",
            "Epoch 371/500\n",
            "43/43 - 0s - loss: 0.7376 - precision_m: 0.6733\n",
            "Epoch 372/500\n",
            "43/43 - 0s - loss: 0.9228 - precision_m: 0.6837\n",
            "Epoch 373/500\n",
            "43/43 - 0s - loss: 0.4878 - precision_m: 0.6767\n",
            "Epoch 374/500\n",
            "43/43 - 0s - loss: 0.3716 - precision_m: 0.6767\n",
            "Epoch 375/500\n",
            "43/43 - 0s - loss: 0.4061 - precision_m: 0.6837\n",
            "Epoch 376/500\n",
            "43/43 - 0s - loss: 0.3936 - precision_m: 0.6802\n",
            "Epoch 377/500\n",
            "43/43 - 0s - loss: 0.7311 - precision_m: 0.6698\n",
            "Epoch 378/500\n",
            "43/43 - 0s - loss: 0.4936 - precision_m: 0.6802\n",
            "Epoch 379/500\n",
            "43/43 - 0s - loss: 0.3606 - precision_m: 0.6837\n",
            "Epoch 380/500\n",
            "43/43 - 0s - loss: 0.6206 - precision_m: 0.6837\n",
            "Epoch 381/500\n",
            "43/43 - 0s - loss: 0.6183 - precision_m: 0.6837\n",
            "Epoch 382/500\n",
            "43/43 - 0s - loss: 0.5496 - precision_m: 0.6837\n",
            "Epoch 383/500\n",
            "43/43 - 0s - loss: 0.4079 - precision_m: 0.6767\n",
            "Epoch 384/500\n",
            "43/43 - 0s - loss: 0.3769 - precision_m: 0.6733\n",
            "Epoch 385/500\n",
            "43/43 - 0s - loss: 0.9217 - precision_m: 0.6837\n",
            "Epoch 386/500\n",
            "43/43 - 0s - loss: 0.5280 - precision_m: 0.6802\n",
            "Epoch 387/500\n",
            "43/43 - 0s - loss: 0.5967 - precision_m: 0.6733\n",
            "Epoch 388/500\n",
            "43/43 - 0s - loss: 0.5326 - precision_m: 0.6698\n",
            "Epoch 389/500\n",
            "43/43 - 0s - loss: 0.4789 - precision_m: 0.6837\n",
            "Epoch 390/500\n",
            "43/43 - 0s - loss: 0.8035 - precision_m: 0.6837\n",
            "Epoch 391/500\n",
            "43/43 - 0s - loss: 1.1004 - precision_m: 0.6837\n",
            "Epoch 392/500\n",
            "43/43 - 0s - loss: 0.4948 - precision_m: 0.6767\n",
            "Epoch 393/500\n",
            "43/43 - 0s - loss: 0.4300 - precision_m: 0.6802\n",
            "Epoch 394/500\n",
            "43/43 - 0s - loss: 0.3951 - precision_m: 0.6767\n",
            "Epoch 395/500\n",
            "43/43 - 0s - loss: 0.6502 - precision_m: 0.6733\n",
            "Epoch 396/500\n",
            "43/43 - 0s - loss: 0.8023 - precision_m: 0.6802\n",
            "Epoch 397/500\n",
            "43/43 - 0s - loss: 0.4575 - precision_m: 0.6802\n",
            "Epoch 398/500\n",
            "43/43 - 0s - loss: 0.3562 - precision_m: 0.6733\n",
            "Epoch 399/500\n",
            "43/43 - 0s - loss: 0.4044 - precision_m: 0.6733\n",
            "Epoch 400/500\n",
            "43/43 - 0s - loss: 0.8082 - precision_m: 0.6767\n",
            "Epoch 401/500\n",
            "43/43 - 0s - loss: 0.6114 - precision_m: 0.6802\n",
            "Epoch 402/500\n",
            "43/43 - 0s - loss: 0.7825 - precision_m: 0.6802\n",
            "Epoch 403/500\n",
            "43/43 - 0s - loss: 0.4892 - precision_m: 0.6767\n",
            "Epoch 404/500\n",
            "43/43 - 0s - loss: 0.4666 - precision_m: 0.6837\n",
            "Epoch 405/500\n",
            "43/43 - 0s - loss: 0.3724 - precision_m: 0.6767\n",
            "Epoch 406/500\n",
            "43/43 - 0s - loss: 0.4649 - precision_m: 0.6802\n",
            "Epoch 407/500\n",
            "43/43 - 0s - loss: 1.8577 - precision_m: 0.6802\n",
            "Epoch 408/500\n",
            "43/43 - 0s - loss: 0.7942 - precision_m: 0.6767\n",
            "Epoch 409/500\n",
            "43/43 - 0s - loss: 0.5479 - precision_m: 0.6802\n",
            "Epoch 410/500\n",
            "43/43 - 0s - loss: 0.3356 - precision_m: 0.6767\n",
            "Epoch 411/500\n",
            "43/43 - 0s - loss: 0.3987 - precision_m: 0.6733\n",
            "Epoch 412/500\n",
            "43/43 - 0s - loss: 0.7685 - precision_m: 0.6733\n",
            "Epoch 413/500\n",
            "43/43 - 0s - loss: 0.5520 - precision_m: 0.6802\n",
            "Epoch 414/500\n",
            "43/43 - 0s - loss: 0.3822 - precision_m: 0.6767\n",
            "Epoch 415/500\n",
            "43/43 - 0s - loss: 0.7306 - precision_m: 0.6837\n",
            "Epoch 416/500\n",
            "43/43 - 0s - loss: 0.7259 - precision_m: 0.6802\n",
            "Epoch 417/500\n",
            "43/43 - 0s - loss: 0.5551 - precision_m: 0.6733\n",
            "Epoch 418/500\n",
            "43/43 - 0s - loss: 0.7585 - precision_m: 0.6767\n",
            "Epoch 419/500\n",
            "43/43 - 0s - loss: 2.3292 - precision_m: 0.6837\n",
            "Epoch 420/500\n",
            "43/43 - 0s - loss: 0.9794 - precision_m: 0.6802\n",
            "Epoch 421/500\n",
            "43/43 - 0s - loss: 0.6840 - precision_m: 0.6733\n",
            "Epoch 422/500\n",
            "43/43 - 0s - loss: 1.6409 - precision_m: 0.6767\n",
            "Epoch 423/500\n",
            "43/43 - 0s - loss: 0.8470 - precision_m: 0.6767\n",
            "Epoch 424/500\n",
            "43/43 - 0s - loss: 0.7529 - precision_m: 0.6767\n",
            "Epoch 425/500\n",
            "43/43 - 0s - loss: 0.4670 - precision_m: 0.6802\n",
            "Epoch 426/500\n",
            "43/43 - 0s - loss: 1.0175 - precision_m: 0.6802\n",
            "Epoch 427/500\n",
            "43/43 - 0s - loss: 0.5049 - precision_m: 0.6802\n",
            "Epoch 428/500\n",
            "43/43 - 0s - loss: 0.8531 - precision_m: 0.6802\n",
            "Epoch 429/500\n",
            "43/43 - 0s - loss: 0.4597 - precision_m: 0.6767\n",
            "Epoch 430/500\n",
            "43/43 - 0s - loss: 0.6386 - precision_m: 0.6802\n",
            "Epoch 431/500\n",
            "43/43 - 0s - loss: 0.5106 - precision_m: 0.6733\n",
            "Epoch 432/500\n",
            "43/43 - 0s - loss: 0.6485 - precision_m: 0.6767\n",
            "Epoch 433/500\n",
            "43/43 - 0s - loss: 0.5621 - precision_m: 0.6802\n",
            "Epoch 434/500\n",
            "43/43 - 0s - loss: 0.3235 - precision_m: 0.6802\n",
            "Epoch 435/500\n",
            "43/43 - 0s - loss: 2.7743 - precision_m: 0.6767\n",
            "Epoch 436/500\n",
            "43/43 - 0s - loss: 0.3273 - precision_m: 0.6767\n",
            "Epoch 437/500\n",
            "43/43 - 0s - loss: 1.0037 - precision_m: 0.6802\n",
            "Epoch 438/500\n",
            "43/43 - 0s - loss: 0.5051 - precision_m: 0.6802\n",
            "Epoch 439/500\n",
            "43/43 - 0s - loss: 0.4170 - precision_m: 0.6733\n",
            "Epoch 440/500\n",
            "43/43 - 0s - loss: 0.4872 - precision_m: 0.6802\n",
            "Epoch 441/500\n",
            "43/43 - 0s - loss: 0.3811 - precision_m: 0.6802\n",
            "Epoch 442/500\n",
            "43/43 - 0s - loss: 0.7974 - precision_m: 0.6802\n",
            "Epoch 443/500\n",
            "43/43 - 0s - loss: 0.5241 - precision_m: 0.6837\n",
            "Epoch 444/500\n",
            "43/43 - 0s - loss: 0.4359 - precision_m: 0.6767\n",
            "Epoch 445/500\n",
            "43/43 - 0s - loss: 0.5878 - precision_m: 0.6733\n",
            "Epoch 446/500\n",
            "43/43 - 0s - loss: 0.4045 - precision_m: 0.6767\n",
            "Epoch 447/500\n",
            "43/43 - 0s - loss: 0.6542 - precision_m: 0.6802\n",
            "Epoch 448/500\n",
            "43/43 - 0s - loss: 0.6261 - precision_m: 0.6837\n",
            "Epoch 449/500\n",
            "43/43 - 0s - loss: 1.3058 - precision_m: 0.6802\n",
            "Epoch 450/500\n",
            "43/43 - 0s - loss: 1.8980 - precision_m: 0.6767\n",
            "Epoch 451/500\n",
            "43/43 - 0s - loss: 0.4486 - precision_m: 0.6767\n",
            "Epoch 452/500\n",
            "43/43 - 0s - loss: 0.5460 - precision_m: 0.6767\n",
            "Epoch 453/500\n",
            "43/43 - 0s - loss: 0.6028 - precision_m: 0.6767\n",
            "Epoch 454/500\n",
            "43/43 - 0s - loss: 0.5087 - precision_m: 0.6767\n",
            "Epoch 455/500\n",
            "43/43 - 0s - loss: 0.6559 - precision_m: 0.6802\n",
            "Epoch 456/500\n",
            "43/43 - 0s - loss: 0.3430 - precision_m: 0.6767\n",
            "Epoch 457/500\n",
            "43/43 - 0s - loss: 0.4392 - precision_m: 0.6802\n",
            "Epoch 458/500\n",
            "43/43 - 0s - loss: 0.3327 - precision_m: 0.6802\n",
            "Epoch 459/500\n",
            "43/43 - 0s - loss: 0.3895 - precision_m: 0.6802\n",
            "Epoch 460/500\n",
            "43/43 - 0s - loss: 0.4431 - precision_m: 0.6837\n",
            "Epoch 461/500\n",
            "43/43 - 0s - loss: 0.3306 - precision_m: 0.6802\n",
            "Epoch 462/500\n",
            "43/43 - 0s - loss: 0.4229 - precision_m: 0.6767\n",
            "Epoch 463/500\n",
            "43/43 - 0s - loss: 1.0862 - precision_m: 0.6837\n",
            "Epoch 464/500\n",
            "43/43 - 0s - loss: 0.8361 - precision_m: 0.6767\n",
            "Epoch 465/500\n",
            "43/43 - 0s - loss: 0.7518 - precision_m: 0.6802\n",
            "Epoch 466/500\n",
            "43/43 - 0s - loss: 0.4009 - precision_m: 0.6767\n",
            "Epoch 467/500\n",
            "43/43 - 0s - loss: 0.4570 - precision_m: 0.6802\n",
            "Epoch 468/500\n",
            "43/43 - 0s - loss: 0.3567 - precision_m: 0.6802\n",
            "Epoch 469/500\n",
            "43/43 - 0s - loss: 1.0378 - precision_m: 0.6802\n",
            "Epoch 470/500\n",
            "43/43 - 0s - loss: 0.4285 - precision_m: 0.6837\n",
            "Epoch 471/500\n",
            "43/43 - 0s - loss: 0.3091 - precision_m: 0.6733\n",
            "Epoch 472/500\n",
            "43/43 - 0s - loss: 0.3269 - precision_m: 0.6767\n",
            "Epoch 473/500\n",
            "43/43 - 0s - loss: 0.3963 - precision_m: 0.6802\n",
            "Epoch 474/500\n",
            "43/43 - 0s - loss: 0.4105 - precision_m: 0.6802\n",
            "Epoch 475/500\n",
            "43/43 - 0s - loss: 0.4850 - precision_m: 0.6802\n",
            "Epoch 476/500\n",
            "43/43 - 0s - loss: 0.5024 - precision_m: 0.6802\n",
            "Epoch 477/500\n",
            "43/43 - 0s - loss: 0.5055 - precision_m: 0.6733\n",
            "Epoch 478/500\n",
            "43/43 - 0s - loss: 0.7149 - precision_m: 0.6767\n",
            "Epoch 479/500\n",
            "43/43 - 0s - loss: 0.9234 - precision_m: 0.6733\n",
            "Epoch 480/500\n",
            "43/43 - 0s - loss: 0.9736 - precision_m: 0.6802\n",
            "Epoch 481/500\n",
            "43/43 - 0s - loss: 0.3640 - precision_m: 0.6837\n",
            "Epoch 482/500\n",
            "43/43 - 0s - loss: 0.3490 - precision_m: 0.6698\n",
            "Epoch 483/500\n",
            "43/43 - 0s - loss: 0.5428 - precision_m: 0.6837\n",
            "Epoch 484/500\n",
            "43/43 - 0s - loss: 0.5718 - precision_m: 0.6837\n",
            "Epoch 485/500\n",
            "43/43 - 0s - loss: 3.1495 - precision_m: 0.6767\n",
            "Epoch 486/500\n",
            "43/43 - 0s - loss: 0.2936 - precision_m: 0.6802\n",
            "Epoch 487/500\n",
            "43/43 - 0s - loss: 0.7468 - precision_m: 0.6837\n",
            "Epoch 488/500\n",
            "43/43 - 0s - loss: 1.3274 - precision_m: 0.6802\n",
            "Epoch 489/500\n",
            "43/43 - 0s - loss: 0.6167 - precision_m: 0.6767\n",
            "Epoch 490/500\n",
            "43/43 - 0s - loss: 0.5483 - precision_m: 0.6802\n",
            "Epoch 491/500\n",
            "43/43 - 0s - loss: 0.6915 - precision_m: 0.6802\n",
            "Epoch 492/500\n",
            "43/43 - 0s - loss: 0.5286 - precision_m: 0.6837\n",
            "Epoch 493/500\n",
            "43/43 - 0s - loss: 0.4027 - precision_m: 0.6767\n",
            "Epoch 494/500\n",
            "43/43 - 0s - loss: 0.2577 - precision_m: 0.6837\n",
            "Epoch 495/500\n",
            "43/43 - 0s - loss: 0.3123 - precision_m: 0.6837\n",
            "Epoch 496/500\n",
            "43/43 - 0s - loss: 0.4171 - precision_m: 0.6837\n",
            "Epoch 497/500\n",
            "43/43 - 0s - loss: 0.6823 - precision_m: 0.6837\n",
            "Epoch 498/500\n",
            "43/43 - 0s - loss: 0.3943 - precision_m: 0.6837\n",
            "Epoch 499/500\n",
            "43/43 - 0s - loss: 0.2689 - precision_m: 0.6837\n",
            "Epoch 500/500\n",
            "43/43 - 0s - loss: 0.3899 - precision_m: 0.6767\n",
            "CPU times: user 31 s, sys: 2.44 s, total: 33.4 s\n",
            "Wall time: 27.3 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f74649101d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_hes15wJuKq",
        "outputId": "17f67403-eb3b-45d2-fe5c-08b2e3be3a8f"
      },
      "source": [
        "%%time\n",
        "with tf.device('/device:GPU:0'):\n",
        "  model.fit(x=train, y=train_y, batch_size=10, epochs=500, shuffle=True, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "43/43 - 0s - loss: 0.6434 - precision_m: 0.6965\n",
            "Epoch 2/500\n",
            "43/43 - 0s - loss: 0.8631 - precision_m: 0.7000\n",
            "Epoch 3/500\n",
            "43/43 - 0s - loss: 0.8235 - precision_m: 0.6965\n",
            "Epoch 4/500\n",
            "43/43 - 0s - loss: 0.7606 - precision_m: 0.6965\n",
            "Epoch 5/500\n",
            "43/43 - 0s - loss: 0.8624 - precision_m: 0.6930\n",
            "Epoch 6/500\n",
            "43/43 - 0s - loss: 0.6858 - precision_m: 0.6930\n",
            "Epoch 7/500\n",
            "43/43 - 0s - loss: 0.5926 - precision_m: 0.6965\n",
            "Epoch 8/500\n",
            "43/43 - 0s - loss: 0.7021 - precision_m: 0.6895\n",
            "Epoch 9/500\n",
            "43/43 - 0s - loss: 0.7875 - precision_m: 0.7000\n",
            "Epoch 10/500\n",
            "43/43 - 0s - loss: 0.9369 - precision_m: 0.7000\n",
            "Epoch 11/500\n",
            "43/43 - 0s - loss: 0.7172 - precision_m: 0.7000\n",
            "Epoch 12/500\n",
            "43/43 - 0s - loss: 1.4083 - precision_m: 0.7000\n",
            "Epoch 13/500\n",
            "43/43 - 0s - loss: 0.7689 - precision_m: 0.7000\n",
            "Epoch 14/500\n",
            "43/43 - 0s - loss: 0.6839 - precision_m: 0.6930\n",
            "Epoch 15/500\n",
            "43/43 - 0s - loss: 0.7536 - precision_m: 0.6930\n",
            "Epoch 16/500\n",
            "43/43 - 0s - loss: 0.7033 - precision_m: 0.6965\n",
            "Epoch 17/500\n",
            "43/43 - 0s - loss: 0.6087 - precision_m: 0.6930\n",
            "Epoch 18/500\n",
            "43/43 - 0s - loss: 0.6606 - precision_m: 0.6965\n",
            "Epoch 19/500\n",
            "43/43 - 0s - loss: 0.6886 - precision_m: 0.6930\n",
            "Epoch 20/500\n",
            "43/43 - 0s - loss: 0.8231 - precision_m: 0.6965\n",
            "Epoch 21/500\n",
            "43/43 - 0s - loss: 0.8272 - precision_m: 0.6965\n",
            "Epoch 22/500\n",
            "43/43 - 0s - loss: 0.8649 - precision_m: 0.6930\n",
            "Epoch 23/500\n",
            "43/43 - 0s - loss: 1.4963 - precision_m: 0.6965\n",
            "Epoch 24/500\n",
            "43/43 - 0s - loss: 0.8081 - precision_m: 0.6965\n",
            "Epoch 25/500\n",
            "43/43 - 0s - loss: 0.8886 - precision_m: 0.6965\n",
            "Epoch 26/500\n",
            "43/43 - 0s - loss: 0.7655 - precision_m: 0.7000\n",
            "Epoch 27/500\n",
            "43/43 - 0s - loss: 0.8209 - precision_m: 0.7000\n",
            "Epoch 28/500\n",
            "43/43 - 0s - loss: 1.2362 - precision_m: 0.7000\n",
            "Epoch 29/500\n",
            "43/43 - 0s - loss: 0.8414 - precision_m: 0.6965\n",
            "Epoch 30/500\n",
            "43/43 - 0s - loss: 0.8129 - precision_m: 0.6930\n",
            "Epoch 31/500\n",
            "43/43 - 0s - loss: 0.5743 - precision_m: 0.6965\n",
            "Epoch 32/500\n",
            "43/43 - 0s - loss: 0.7386 - precision_m: 0.6930\n",
            "Epoch 33/500\n",
            "43/43 - 0s - loss: 0.6686 - precision_m: 0.6965\n",
            "Epoch 34/500\n",
            "43/43 - 0s - loss: 0.7300 - precision_m: 0.6965\n",
            "Epoch 35/500\n",
            "43/43 - 0s - loss: 0.6410 - precision_m: 0.6965\n",
            "Epoch 36/500\n",
            "43/43 - 0s - loss: 0.6456 - precision_m: 0.6965\n",
            "Epoch 37/500\n",
            "43/43 - 0s - loss: 0.5417 - precision_m: 0.6930\n",
            "Epoch 38/500\n",
            "43/43 - 0s - loss: 0.6401 - precision_m: 0.6965\n",
            "Epoch 39/500\n",
            "43/43 - 0s - loss: 0.5796 - precision_m: 0.6930\n",
            "Epoch 40/500\n",
            "43/43 - 0s - loss: 0.8408 - precision_m: 0.6965\n",
            "Epoch 41/500\n",
            "43/43 - 0s - loss: 1.0938 - precision_m: 0.7000\n",
            "Epoch 42/500\n",
            "43/43 - 0s - loss: 0.9846 - precision_m: 0.6930\n",
            "Epoch 43/500\n",
            "43/43 - 0s - loss: 0.8466 - precision_m: 0.6895\n",
            "Epoch 44/500\n",
            "43/43 - 0s - loss: 0.5934 - precision_m: 0.6965\n",
            "Epoch 45/500\n",
            "43/43 - 0s - loss: 0.9295 - precision_m: 0.6930\n",
            "Epoch 46/500\n",
            "43/43 - 0s - loss: 0.6717 - precision_m: 0.7000\n",
            "Epoch 47/500\n",
            "43/43 - 0s - loss: 0.6075 - precision_m: 0.6895\n",
            "Epoch 48/500\n",
            "43/43 - 0s - loss: 0.7108 - precision_m: 0.6965\n",
            "Epoch 49/500\n",
            "43/43 - 0s - loss: 1.0174 - precision_m: 0.6965\n",
            "Epoch 50/500\n",
            "43/43 - 0s - loss: 0.7564 - precision_m: 0.6965\n",
            "Epoch 51/500\n",
            "43/43 - 0s - loss: 0.7658 - precision_m: 0.6965\n",
            "Epoch 52/500\n",
            "43/43 - 0s - loss: 0.6876 - precision_m: 0.6965\n",
            "Epoch 53/500\n",
            "43/43 - 0s - loss: 0.6919 - precision_m: 0.6895\n",
            "Epoch 54/500\n",
            "43/43 - 0s - loss: 0.6779 - precision_m: 0.6965\n",
            "Epoch 55/500\n",
            "43/43 - 0s - loss: 0.6380 - precision_m: 0.6895\n",
            "Epoch 56/500\n",
            "43/43 - 0s - loss: 0.6480 - precision_m: 0.7000\n",
            "Epoch 57/500\n",
            "43/43 - 0s - loss: 0.5967 - precision_m: 0.6965\n",
            "Epoch 58/500\n",
            "43/43 - 0s - loss: 0.5712 - precision_m: 0.6965\n",
            "Epoch 59/500\n",
            "43/43 - 0s - loss: 0.7650 - precision_m: 0.6895\n",
            "Epoch 60/500\n",
            "43/43 - 0s - loss: 2.2230 - precision_m: 0.6965\n",
            "Epoch 61/500\n",
            "43/43 - 0s - loss: 0.7145 - precision_m: 0.6930\n",
            "Epoch 62/500\n",
            "43/43 - 0s - loss: 0.8308 - precision_m: 0.6930\n",
            "Epoch 63/500\n",
            "43/43 - 0s - loss: 1.2077 - precision_m: 0.6930\n",
            "Epoch 64/500\n",
            "43/43 - 0s - loss: 0.7344 - precision_m: 0.7000\n",
            "Epoch 65/500\n",
            "43/43 - 0s - loss: 0.8389 - precision_m: 0.7000\n",
            "Epoch 66/500\n",
            "43/43 - 0s - loss: 0.6368 - precision_m: 0.6930\n",
            "Epoch 67/500\n",
            "43/43 - 0s - loss: 0.5670 - precision_m: 0.6930\n",
            "Epoch 68/500\n",
            "43/43 - 0s - loss: 0.5822 - precision_m: 0.6965\n",
            "Epoch 69/500\n",
            "43/43 - 0s - loss: 0.7065 - precision_m: 0.7000\n",
            "Epoch 70/500\n",
            "43/43 - 0s - loss: 0.6456 - precision_m: 0.6895\n",
            "Epoch 71/500\n",
            "43/43 - 0s - loss: 0.8482 - precision_m: 0.6930\n",
            "Epoch 72/500\n",
            "43/43 - 0s - loss: 1.0723 - precision_m: 0.7000\n",
            "Epoch 73/500\n",
            "43/43 - 0s - loss: 0.5625 - precision_m: 0.6930\n",
            "Epoch 74/500\n",
            "43/43 - 0s - loss: 0.6221 - precision_m: 0.6965\n",
            "Epoch 75/500\n",
            "43/43 - 0s - loss: 0.6057 - precision_m: 0.6965\n",
            "Epoch 76/500\n",
            "43/43 - 0s - loss: 0.5323 - precision_m: 0.7000\n",
            "Epoch 77/500\n",
            "43/43 - 0s - loss: 0.6849 - precision_m: 0.6895\n",
            "Epoch 78/500\n",
            "43/43 - 0s - loss: 0.9192 - precision_m: 0.6930\n",
            "Epoch 79/500\n",
            "43/43 - 0s - loss: 0.7528 - precision_m: 0.6965\n",
            "Epoch 80/500\n",
            "43/43 - 0s - loss: 1.0686 - precision_m: 0.6930\n",
            "Epoch 81/500\n",
            "43/43 - 0s - loss: 0.9170 - precision_m: 0.6965\n",
            "Epoch 82/500\n",
            "43/43 - 0s - loss: 0.5609 - precision_m: 0.6965\n",
            "Epoch 83/500\n",
            "43/43 - 0s - loss: 0.6350 - precision_m: 0.7000\n",
            "Epoch 84/500\n",
            "43/43 - 0s - loss: 0.6945 - precision_m: 0.7000\n",
            "Epoch 85/500\n",
            "43/43 - 0s - loss: 0.8969 - precision_m: 0.7000\n",
            "Epoch 86/500\n",
            "43/43 - 0s - loss: 0.5533 - precision_m: 0.6965\n",
            "Epoch 87/500\n",
            "43/43 - 0s - loss: 0.7557 - precision_m: 0.6965\n",
            "Epoch 88/500\n",
            "43/43 - 0s - loss: 0.9095 - precision_m: 0.6930\n",
            "Epoch 89/500\n",
            "43/43 - 0s - loss: 1.0521 - precision_m: 0.6930\n",
            "Epoch 90/500\n",
            "43/43 - 0s - loss: 0.5500 - precision_m: 0.6965\n",
            "Epoch 91/500\n",
            "43/43 - 0s - loss: 0.7049 - precision_m: 0.6930\n",
            "Epoch 92/500\n",
            "43/43 - 0s - loss: 0.9666 - precision_m: 0.6965\n",
            "Epoch 93/500\n",
            "43/43 - 0s - loss: 0.6544 - precision_m: 0.6930\n",
            "Epoch 94/500\n",
            "43/43 - 0s - loss: 0.8763 - precision_m: 0.6895\n",
            "Epoch 95/500\n",
            "43/43 - 0s - loss: 0.6140 - precision_m: 0.6930\n",
            "Epoch 96/500\n",
            "43/43 - 0s - loss: 0.8293 - precision_m: 0.7000\n",
            "Epoch 97/500\n",
            "43/43 - 0s - loss: 0.5531 - precision_m: 0.7000\n",
            "Epoch 98/500\n",
            "43/43 - 0s - loss: 0.7870 - precision_m: 0.7000\n",
            "Epoch 99/500\n",
            "43/43 - 0s - loss: 0.6800 - precision_m: 0.6965\n",
            "Epoch 100/500\n",
            "43/43 - 0s - loss: 0.7375 - precision_m: 0.7000\n",
            "Epoch 101/500\n",
            "43/43 - 0s - loss: 1.2395 - precision_m: 0.6965\n",
            "Epoch 102/500\n",
            "43/43 - 0s - loss: 0.8784 - precision_m: 0.6965\n",
            "Epoch 103/500\n",
            "43/43 - 0s - loss: 0.9114 - precision_m: 0.6965\n",
            "Epoch 104/500\n",
            "43/43 - 0s - loss: 0.7622 - precision_m: 0.7000\n",
            "Epoch 105/500\n",
            "43/43 - 0s - loss: 1.0119 - precision_m: 0.6930\n",
            "Epoch 106/500\n",
            "43/43 - 0s - loss: 0.7834 - precision_m: 0.6895\n",
            "Epoch 107/500\n",
            "43/43 - 0s - loss: 0.7970 - precision_m: 0.6965\n",
            "Epoch 108/500\n",
            "43/43 - 0s - loss: 0.6148 - precision_m: 0.6930\n",
            "Epoch 109/500\n",
            "43/43 - 0s - loss: 1.0049 - precision_m: 0.6965\n",
            "Epoch 110/500\n",
            "43/43 - 0s - loss: 0.5674 - precision_m: 0.7000\n",
            "Epoch 111/500\n",
            "43/43 - 0s - loss: 0.6034 - precision_m: 0.6930\n",
            "Epoch 112/500\n",
            "43/43 - 0s - loss: 0.6121 - precision_m: 0.6965\n",
            "Epoch 113/500\n",
            "43/43 - 0s - loss: 0.4917 - precision_m: 0.6965\n",
            "Epoch 114/500\n",
            "43/43 - 0s - loss: 0.7835 - precision_m: 0.6965\n",
            "Epoch 115/500\n",
            "43/43 - 0s - loss: 0.6010 - precision_m: 0.6965\n",
            "Epoch 116/500\n",
            "43/43 - 0s - loss: 0.6171 - precision_m: 0.6930\n",
            "Epoch 117/500\n",
            "43/43 - 0s - loss: 0.8535 - precision_m: 0.6930\n",
            "Epoch 118/500\n",
            "43/43 - 0s - loss: 0.5356 - precision_m: 0.6965\n",
            "Epoch 119/500\n",
            "43/43 - 0s - loss: 0.7386 - precision_m: 0.6930\n",
            "Epoch 120/500\n",
            "43/43 - 0s - loss: 1.0090 - precision_m: 0.6930\n",
            "Epoch 121/500\n",
            "43/43 - 0s - loss: 0.6751 - precision_m: 0.6930\n",
            "Epoch 122/500\n",
            "43/43 - 0s - loss: 1.0235 - precision_m: 0.6965\n",
            "Epoch 123/500\n",
            "43/43 - 0s - loss: 1.0765 - precision_m: 0.6930\n",
            "Epoch 124/500\n",
            "43/43 - 0s - loss: 0.5850 - precision_m: 0.6930\n",
            "Epoch 125/500\n",
            "43/43 - 0s - loss: 0.6446 - precision_m: 0.6965\n",
            "Epoch 126/500\n",
            "43/43 - 0s - loss: 0.8408 - precision_m: 0.6965\n",
            "Epoch 127/500\n",
            "43/43 - 0s - loss: 0.6835 - precision_m: 0.7000\n",
            "Epoch 128/500\n",
            "43/43 - 0s - loss: 0.7928 - precision_m: 0.6930\n",
            "Epoch 129/500\n",
            "43/43 - 0s - loss: 0.6973 - precision_m: 0.6930\n",
            "Epoch 130/500\n",
            "43/43 - 0s - loss: 0.7289 - precision_m: 0.6965\n",
            "Epoch 131/500\n",
            "43/43 - 0s - loss: 0.7026 - precision_m: 0.6930\n",
            "Epoch 132/500\n",
            "43/43 - 0s - loss: 0.9516 - precision_m: 0.7000\n",
            "Epoch 133/500\n",
            "43/43 - 0s - loss: 0.7311 - precision_m: 0.6965\n",
            "Epoch 134/500\n",
            "43/43 - 0s - loss: 1.1135 - precision_m: 0.7000\n",
            "Epoch 135/500\n",
            "43/43 - 0s - loss: 1.0982 - precision_m: 0.6965\n",
            "Epoch 136/500\n",
            "43/43 - 0s - loss: 1.2162 - precision_m: 0.6965\n",
            "Epoch 137/500\n",
            "43/43 - 0s - loss: 0.6777 - precision_m: 0.6895\n",
            "Epoch 138/500\n",
            "43/43 - 0s - loss: 0.6532 - precision_m: 0.6965\n",
            "Epoch 139/500\n",
            "43/43 - 0s - loss: 0.6838 - precision_m: 0.6930\n",
            "Epoch 140/500\n",
            "43/43 - 0s - loss: 0.9282 - precision_m: 0.6965\n",
            "Epoch 141/500\n",
            "43/43 - 0s - loss: 0.7726 - precision_m: 0.6965\n",
            "Epoch 142/500\n",
            "43/43 - 0s - loss: 0.5435 - precision_m: 0.6965\n",
            "Epoch 143/500\n",
            "43/43 - 0s - loss: 0.6480 - precision_m: 0.6895\n",
            "Epoch 144/500\n",
            "43/43 - 0s - loss: 0.6730 - precision_m: 0.6965\n",
            "Epoch 145/500\n",
            "43/43 - 0s - loss: 0.6476 - precision_m: 0.6965\n",
            "Epoch 146/500\n",
            "43/43 - 0s - loss: 0.6500 - precision_m: 0.6965\n",
            "Epoch 147/500\n",
            "43/43 - 0s - loss: 0.8786 - precision_m: 0.6965\n",
            "Epoch 148/500\n",
            "43/43 - 0s - loss: 0.7259 - precision_m: 0.7000\n",
            "Epoch 149/500\n",
            "43/43 - 0s - loss: 0.9679 - precision_m: 0.6965\n",
            "Epoch 150/500\n",
            "43/43 - 0s - loss: 0.8308 - precision_m: 0.6965\n",
            "Epoch 151/500\n",
            "43/43 - 0s - loss: 0.6669 - precision_m: 0.6965\n",
            "Epoch 152/500\n",
            "43/43 - 0s - loss: 0.7816 - precision_m: 0.6965\n",
            "Epoch 153/500\n",
            "43/43 - 0s - loss: 0.9131 - precision_m: 0.6965\n",
            "Epoch 154/500\n",
            "43/43 - 0s - loss: 0.6620 - precision_m: 0.6895\n",
            "Epoch 155/500\n",
            "43/43 - 0s - loss: 0.7017 - precision_m: 0.6965\n",
            "Epoch 156/500\n",
            "43/43 - 0s - loss: 0.6226 - precision_m: 0.6930\n",
            "Epoch 157/500\n",
            "43/43 - 0s - loss: 0.5110 - precision_m: 0.6930\n",
            "Epoch 158/500\n",
            "43/43 - 0s - loss: 0.6744 - precision_m: 0.6895\n",
            "Epoch 159/500\n",
            "43/43 - 0s - loss: 0.8409 - precision_m: 0.6895\n",
            "Epoch 160/500\n",
            "43/43 - 0s - loss: 0.9146 - precision_m: 0.6965\n",
            "Epoch 161/500\n",
            "43/43 - 0s - loss: 0.5580 - precision_m: 0.6965\n",
            "Epoch 162/500\n",
            "43/43 - 0s - loss: 1.0087 - precision_m: 0.6965\n",
            "Epoch 163/500\n",
            "43/43 - 0s - loss: 0.8883 - precision_m: 0.6930\n",
            "Epoch 164/500\n",
            "43/43 - 0s - loss: 0.6198 - precision_m: 0.6965\n",
            "Epoch 165/500\n",
            "43/43 - 0s - loss: 0.8064 - precision_m: 0.7000\n",
            "Epoch 166/500\n",
            "43/43 - 0s - loss: 0.7020 - precision_m: 0.6930\n",
            "Epoch 167/500\n",
            "43/43 - 0s - loss: 0.6001 - precision_m: 0.6965\n",
            "Epoch 168/500\n",
            "43/43 - 0s - loss: 0.7138 - precision_m: 0.6965\n",
            "Epoch 169/500\n",
            "43/43 - 0s - loss: 0.8647 - precision_m: 0.6930\n",
            "Epoch 170/500\n",
            "43/43 - 0s - loss: 0.5204 - precision_m: 0.6965\n",
            "Epoch 171/500\n",
            "43/43 - 0s - loss: 1.3435 - precision_m: 0.7000\n",
            "Epoch 172/500\n",
            "43/43 - 0s - loss: 1.4407 - precision_m: 0.7000\n",
            "Epoch 173/500\n",
            "43/43 - 0s - loss: 2.0489 - precision_m: 0.6965\n",
            "Epoch 174/500\n",
            "43/43 - 0s - loss: 0.7184 - precision_m: 0.6965\n",
            "Epoch 175/500\n",
            "43/43 - 0s - loss: 0.5908 - precision_m: 0.6965\n",
            "Epoch 176/500\n",
            "43/43 - 0s - loss: 1.0726 - precision_m: 0.6930\n",
            "Epoch 177/500\n",
            "43/43 - 0s - loss: 0.6240 - precision_m: 0.6965\n",
            "Epoch 178/500\n",
            "43/43 - 0s - loss: 0.5613 - precision_m: 0.6930\n",
            "Epoch 179/500\n",
            "43/43 - 0s - loss: 0.5635 - precision_m: 0.6930\n",
            "Epoch 180/500\n",
            "43/43 - 0s - loss: 1.1347 - precision_m: 0.7000\n",
            "Epoch 181/500\n",
            "43/43 - 0s - loss: 0.6657 - precision_m: 0.6895\n",
            "Epoch 182/500\n",
            "43/43 - 0s - loss: 0.5544 - precision_m: 0.6930\n",
            "Epoch 183/500\n",
            "43/43 - 0s - loss: 0.6569 - precision_m: 0.6965\n",
            "Epoch 184/500\n",
            "43/43 - 0s - loss: 0.7535 - precision_m: 0.6930\n",
            "Epoch 185/500\n",
            "43/43 - 0s - loss: 0.6554 - precision_m: 0.6930\n",
            "Epoch 186/500\n",
            "43/43 - 0s - loss: 0.5825 - precision_m: 0.6965\n",
            "Epoch 187/500\n",
            "43/43 - 0s - loss: 0.5489 - precision_m: 0.6965\n",
            "Epoch 188/500\n",
            "43/43 - 0s - loss: 0.6716 - precision_m: 0.6895\n",
            "Epoch 189/500\n",
            "43/43 - 0s - loss: 0.6002 - precision_m: 0.7000\n",
            "Epoch 190/500\n",
            "43/43 - 0s - loss: 0.7716 - precision_m: 0.6930\n",
            "Epoch 191/500\n",
            "43/43 - 0s - loss: 1.2064 - precision_m: 0.6965\n",
            "Epoch 192/500\n",
            "43/43 - 0s - loss: 0.8859 - precision_m: 0.6965\n",
            "Epoch 193/500\n",
            "43/43 - 0s - loss: 0.7729 - precision_m: 0.6965\n",
            "Epoch 194/500\n",
            "43/43 - 0s - loss: 0.8418 - precision_m: 0.6965\n",
            "Epoch 195/500\n",
            "43/43 - 0s - loss: 0.5582 - precision_m: 0.7000\n",
            "Epoch 196/500\n",
            "43/43 - 0s - loss: 0.5558 - precision_m: 0.6895\n",
            "Epoch 197/500\n",
            "43/43 - 0s - loss: 1.0728 - precision_m: 0.6930\n",
            "Epoch 198/500\n",
            "43/43 - 0s - loss: 0.9823 - precision_m: 0.6930\n",
            "Epoch 199/500\n",
            "43/43 - 0s - loss: 0.6763 - precision_m: 0.6895\n",
            "Epoch 200/500\n",
            "43/43 - 0s - loss: 0.8547 - precision_m: 0.6895\n",
            "Epoch 201/500\n",
            "43/43 - 0s - loss: 0.9301 - precision_m: 0.6930\n",
            "Epoch 202/500\n",
            "43/43 - 0s - loss: 0.6910 - precision_m: 0.6965\n",
            "Epoch 203/500\n",
            "43/43 - 0s - loss: 0.9030 - precision_m: 0.6965\n",
            "Epoch 204/500\n",
            "43/43 - 0s - loss: 1.0760 - precision_m: 0.6965\n",
            "Epoch 205/500\n",
            "43/43 - 0s - loss: 0.8125 - precision_m: 0.6965\n",
            "Epoch 206/500\n",
            "43/43 - 0s - loss: 0.5590 - precision_m: 0.7000\n",
            "Epoch 207/500\n",
            "43/43 - 0s - loss: 0.6146 - precision_m: 0.6965\n",
            "Epoch 208/500\n",
            "43/43 - 0s - loss: 0.7697 - precision_m: 0.6965\n",
            "Epoch 209/500\n",
            "43/43 - 0s - loss: 0.7655 - precision_m: 0.7000\n",
            "Epoch 210/500\n",
            "43/43 - 0s - loss: 0.5114 - precision_m: 0.6895\n",
            "Epoch 211/500\n",
            "43/43 - 0s - loss: 0.5574 - precision_m: 0.6930\n",
            "Epoch 212/500\n",
            "43/43 - 0s - loss: 0.8252 - precision_m: 0.6930\n",
            "Epoch 213/500\n",
            "43/43 - 0s - loss: 0.9951 - precision_m: 0.6860\n",
            "Epoch 214/500\n",
            "43/43 - 0s - loss: 1.0631 - precision_m: 0.7000\n",
            "Epoch 215/500\n",
            "43/43 - 0s - loss: 0.7797 - precision_m: 0.6965\n",
            "Epoch 216/500\n",
            "43/43 - 0s - loss: 0.5744 - precision_m: 0.6930\n",
            "Epoch 217/500\n",
            "43/43 - 0s - loss: 0.6741 - precision_m: 0.6965\n",
            "Epoch 218/500\n",
            "43/43 - 0s - loss: 0.9769 - precision_m: 0.6930\n",
            "Epoch 219/500\n",
            "43/43 - 0s - loss: 0.5051 - precision_m: 0.7000\n",
            "Epoch 220/500\n",
            "43/43 - 0s - loss: 0.6546 - precision_m: 0.6930\n",
            "Epoch 221/500\n",
            "43/43 - 0s - loss: 0.4816 - precision_m: 0.6930\n",
            "Epoch 222/500\n",
            "43/43 - 0s - loss: 0.8494 - precision_m: 0.6965\n",
            "Epoch 223/500\n",
            "43/43 - 0s - loss: 0.5079 - precision_m: 0.6965\n",
            "Epoch 224/500\n",
            "43/43 - 0s - loss: 0.7958 - precision_m: 0.6965\n",
            "Epoch 225/500\n",
            "43/43 - 0s - loss: 0.5856 - precision_m: 0.6930\n",
            "Epoch 226/500\n",
            "43/43 - 0s - loss: 0.7880 - precision_m: 0.6965\n",
            "Epoch 227/500\n",
            "43/43 - 0s - loss: 1.1595 - precision_m: 0.6965\n",
            "Epoch 228/500\n",
            "43/43 - 0s - loss: 0.4998 - precision_m: 0.6930\n",
            "Epoch 229/500\n",
            "43/43 - 0s - loss: 0.8130 - precision_m: 0.6965\n",
            "Epoch 230/500\n",
            "43/43 - 0s - loss: 0.5966 - precision_m: 0.6965\n",
            "Epoch 231/500\n",
            "43/43 - 0s - loss: 0.6772 - precision_m: 0.6930\n",
            "Epoch 232/500\n",
            "43/43 - 0s - loss: 0.7422 - precision_m: 0.6930\n",
            "Epoch 233/500\n",
            "43/43 - 0s - loss: 0.8227 - precision_m: 0.7000\n",
            "Epoch 234/500\n",
            "43/43 - 0s - loss: 0.7344 - precision_m: 0.6930\n",
            "Epoch 235/500\n",
            "43/43 - 0s - loss: 0.5357 - precision_m: 0.7000\n",
            "Epoch 236/500\n",
            "43/43 - 0s - loss: 0.6182 - precision_m: 0.7000\n",
            "Epoch 237/500\n",
            "43/43 - 0s - loss: 1.0372 - precision_m: 0.6965\n",
            "Epoch 238/500\n",
            "43/43 - 0s - loss: 0.8734 - precision_m: 0.6895\n",
            "Epoch 239/500\n",
            "43/43 - 0s - loss: 1.3967 - precision_m: 0.6965\n",
            "Epoch 240/500\n",
            "43/43 - 0s - loss: 1.2884 - precision_m: 0.6965\n",
            "Epoch 241/500\n",
            "43/43 - 0s - loss: 0.8160 - precision_m: 0.7000\n",
            "Epoch 242/500\n",
            "43/43 - 0s - loss: 0.7456 - precision_m: 0.7000\n",
            "Epoch 243/500\n",
            "43/43 - 0s - loss: 0.5386 - precision_m: 0.6965\n",
            "Epoch 244/500\n",
            "43/43 - 0s - loss: 0.5001 - precision_m: 0.6965\n",
            "Epoch 245/500\n",
            "43/43 - 0s - loss: 0.6244 - precision_m: 0.6930\n",
            "Epoch 246/500\n",
            "43/43 - 0s - loss: 0.7450 - precision_m: 0.6965\n",
            "Epoch 247/500\n",
            "43/43 - 0s - loss: 0.6511 - precision_m: 0.6965\n",
            "Epoch 248/500\n",
            "43/43 - 0s - loss: 0.5905 - precision_m: 0.6965\n",
            "Epoch 249/500\n",
            "43/43 - 0s - loss: 0.8904 - precision_m: 0.6895\n",
            "Epoch 250/500\n",
            "43/43 - 0s - loss: 0.6531 - precision_m: 0.6965\n",
            "Epoch 251/500\n",
            "43/43 - 0s - loss: 0.7232 - precision_m: 0.6930\n",
            "Epoch 252/500\n",
            "43/43 - 0s - loss: 0.4961 - precision_m: 0.7000\n",
            "Epoch 253/500\n",
            "43/43 - 0s - loss: 0.6137 - precision_m: 0.7000\n",
            "Epoch 254/500\n",
            "43/43 - 0s - loss: 0.6104 - precision_m: 0.7000\n",
            "Epoch 255/500\n",
            "43/43 - 0s - loss: 0.8184 - precision_m: 0.6965\n",
            "Epoch 256/500\n",
            "43/43 - 0s - loss: 0.5700 - precision_m: 0.6930\n",
            "Epoch 257/500\n",
            "43/43 - 0s - loss: 0.7466 - precision_m: 0.6930\n",
            "Epoch 258/500\n",
            "43/43 - 0s - loss: 0.6796 - precision_m: 0.6965\n",
            "Epoch 259/500\n",
            "43/43 - 0s - loss: 0.6083 - precision_m: 0.6965\n",
            "Epoch 260/500\n",
            "43/43 - 0s - loss: 0.4548 - precision_m: 0.7000\n",
            "Epoch 261/500\n",
            "43/43 - 0s - loss: 0.5046 - precision_m: 0.6895\n",
            "Epoch 262/500\n",
            "43/43 - 0s - loss: 0.7019 - precision_m: 0.6965\n",
            "Epoch 263/500\n",
            "43/43 - 0s - loss: 0.5788 - precision_m: 0.7000\n",
            "Epoch 264/500\n",
            "43/43 - 0s - loss: 0.7327 - precision_m: 0.7000\n",
            "Epoch 265/500\n",
            "43/43 - 0s - loss: 0.6518 - precision_m: 0.6965\n",
            "Epoch 266/500\n",
            "43/43 - 0s - loss: 0.8968 - precision_m: 0.7000\n",
            "Epoch 267/500\n",
            "43/43 - 0s - loss: 0.6595 - precision_m: 0.6965\n",
            "Epoch 268/500\n",
            "43/43 - 0s - loss: 0.6719 - precision_m: 0.6965\n",
            "Epoch 269/500\n",
            "43/43 - 0s - loss: 0.5553 - precision_m: 0.6965\n",
            "Epoch 270/500\n",
            "43/43 - 0s - loss: 0.4663 - precision_m: 0.6965\n",
            "Epoch 271/500\n",
            "43/43 - 0s - loss: 0.5157 - precision_m: 0.6895\n",
            "Epoch 272/500\n",
            "43/43 - 0s - loss: 0.5548 - precision_m: 0.6930\n",
            "Epoch 273/500\n",
            "43/43 - 0s - loss: 0.9679 - precision_m: 0.6930\n",
            "Epoch 274/500\n",
            "43/43 - 0s - loss: 0.9692 - precision_m: 0.6965\n",
            "Epoch 275/500\n",
            "43/43 - 0s - loss: 0.6187 - precision_m: 0.6965\n",
            "Epoch 276/500\n",
            "43/43 - 0s - loss: 0.6363 - precision_m: 0.6930\n",
            "Epoch 277/500\n",
            "43/43 - 0s - loss: 0.7747 - precision_m: 0.6930\n",
            "Epoch 278/500\n",
            "43/43 - 0s - loss: 0.7334 - precision_m: 0.7000\n",
            "Epoch 279/500\n",
            "43/43 - 0s - loss: 0.5223 - precision_m: 0.7000\n",
            "Epoch 280/500\n",
            "43/43 - 0s - loss: 0.4672 - precision_m: 0.6930\n",
            "Epoch 281/500\n",
            "43/43 - 0s - loss: 0.5732 - precision_m: 0.6930\n",
            "Epoch 282/500\n",
            "43/43 - 0s - loss: 0.7488 - precision_m: 0.6930\n",
            "Epoch 283/500\n",
            "43/43 - 0s - loss: 0.7000 - precision_m: 0.6965\n",
            "Epoch 284/500\n",
            "43/43 - 0s - loss: 0.6275 - precision_m: 0.7000\n",
            "Epoch 285/500\n",
            "43/43 - 0s - loss: 0.4879 - precision_m: 0.7000\n",
            "Epoch 286/500\n",
            "43/43 - 0s - loss: 0.4875 - precision_m: 0.6930\n",
            "Epoch 287/500\n",
            "43/43 - 0s - loss: 0.5860 - precision_m: 0.6965\n",
            "Epoch 288/500\n",
            "43/43 - 0s - loss: 0.5247 - precision_m: 0.6965\n",
            "Epoch 289/500\n",
            "43/43 - 0s - loss: 0.8012 - precision_m: 0.6965\n",
            "Epoch 290/500\n",
            "43/43 - 0s - loss: 0.6044 - precision_m: 0.6965\n",
            "Epoch 291/500\n",
            "43/43 - 0s - loss: 0.9076 - precision_m: 0.6930\n",
            "Epoch 292/500\n",
            "43/43 - 0s - loss: 1.0178 - precision_m: 0.6965\n",
            "Epoch 293/500\n",
            "43/43 - 0s - loss: 1.1754 - precision_m: 0.6965\n",
            "Epoch 294/500\n",
            "43/43 - 0s - loss: 0.6097 - precision_m: 0.7000\n",
            "Epoch 295/500\n",
            "43/43 - 0s - loss: 0.4420 - precision_m: 0.6930\n",
            "Epoch 296/500\n",
            "43/43 - 0s - loss: 0.5354 - precision_m: 0.6965\n",
            "Epoch 297/500\n",
            "43/43 - 0s - loss: 0.6435 - precision_m: 0.6930\n",
            "Epoch 298/500\n",
            "43/43 - 0s - loss: 0.6191 - precision_m: 0.6930\n",
            "Epoch 299/500\n",
            "43/43 - 0s - loss: 0.7245 - precision_m: 0.6965\n",
            "Epoch 300/500\n",
            "43/43 - 0s - loss: 0.6561 - precision_m: 0.6965\n",
            "Epoch 301/500\n",
            "43/43 - 0s - loss: 0.6075 - precision_m: 0.6965\n",
            "Epoch 302/500\n",
            "43/43 - 0s - loss: 0.7320 - precision_m: 0.6965\n",
            "Epoch 303/500\n",
            "43/43 - 0s - loss: 0.9132 - precision_m: 0.6965\n",
            "Epoch 304/500\n",
            "43/43 - 0s - loss: 1.2109 - precision_m: 0.6965\n",
            "Epoch 305/500\n",
            "43/43 - 0s - loss: 0.5994 - precision_m: 0.7000\n",
            "Epoch 306/500\n",
            "43/43 - 0s - loss: 0.5960 - precision_m: 0.6930\n",
            "Epoch 307/500\n",
            "43/43 - 0s - loss: 0.4441 - precision_m: 0.6965\n",
            "Epoch 308/500\n",
            "43/43 - 0s - loss: 0.6095 - precision_m: 0.7000\n",
            "Epoch 309/500\n",
            "43/43 - 0s - loss: 0.4914 - precision_m: 0.6965\n",
            "Epoch 310/500\n",
            "43/43 - 0s - loss: 0.5440 - precision_m: 0.6930\n",
            "Epoch 311/500\n",
            "43/43 - 0s - loss: 0.7536 - precision_m: 0.6930\n",
            "Epoch 312/500\n",
            "43/43 - 0s - loss: 0.7268 - precision_m: 0.6930\n",
            "Epoch 313/500\n",
            "43/43 - 0s - loss: 0.8165 - precision_m: 0.6895\n",
            "Epoch 314/500\n",
            "43/43 - 0s - loss: 0.9229 - precision_m: 0.6930\n",
            "Epoch 315/500\n",
            "43/43 - 0s - loss: 1.1859 - precision_m: 0.6965\n",
            "Epoch 316/500\n",
            "43/43 - 0s - loss: 0.7643 - precision_m: 0.6930\n",
            "Epoch 317/500\n",
            "43/43 - 0s - loss: 0.9656 - precision_m: 0.6930\n",
            "Epoch 318/500\n",
            "43/43 - 0s - loss: 0.5803 - precision_m: 0.6965\n",
            "Epoch 319/500\n",
            "43/43 - 0s - loss: 0.6086 - precision_m: 0.6930\n",
            "Epoch 320/500\n",
            "43/43 - 0s - loss: 0.7721 - precision_m: 0.6965\n",
            "Epoch 321/500\n",
            "43/43 - 0s - loss: 0.4342 - precision_m: 0.7000\n",
            "Epoch 322/500\n",
            "43/43 - 0s - loss: 0.8074 - precision_m: 0.6930\n",
            "Epoch 323/500\n",
            "43/43 - 0s - loss: 0.6268 - precision_m: 0.6965\n",
            "Epoch 324/500\n",
            "43/43 - 0s - loss: 0.5712 - precision_m: 0.6930\n",
            "Epoch 325/500\n",
            "43/43 - 0s - loss: 0.6041 - precision_m: 0.6930\n",
            "Epoch 326/500\n",
            "43/43 - 0s - loss: 0.7130 - precision_m: 0.7000\n",
            "Epoch 327/500\n",
            "43/43 - 0s - loss: 0.5792 - precision_m: 0.7000\n",
            "Epoch 328/500\n",
            "43/43 - 0s - loss: 0.6621 - precision_m: 0.6965\n",
            "Epoch 329/500\n",
            "43/43 - 0s - loss: 0.5305 - precision_m: 0.7000\n",
            "Epoch 330/500\n",
            "43/43 - 0s - loss: 0.8173 - precision_m: 0.6930\n",
            "Epoch 331/500\n",
            "43/43 - 0s - loss: 0.5509 - precision_m: 0.6965\n",
            "Epoch 332/500\n",
            "43/43 - 0s - loss: 0.7550 - precision_m: 0.6965\n",
            "Epoch 333/500\n",
            "43/43 - 0s - loss: 0.7388 - precision_m: 0.7000\n",
            "Epoch 334/500\n",
            "43/43 - 0s - loss: 0.8756 - precision_m: 0.6895\n",
            "Epoch 335/500\n",
            "43/43 - 0s - loss: 0.6146 - precision_m: 0.7000\n",
            "Epoch 336/500\n",
            "43/43 - 0s - loss: 0.5743 - precision_m: 0.6965\n",
            "Epoch 337/500\n",
            "43/43 - 0s - loss: 0.4907 - precision_m: 0.7000\n",
            "Epoch 338/500\n",
            "43/43 - 0s - loss: 0.5633 - precision_m: 0.7000\n",
            "Epoch 339/500\n",
            "43/43 - 0s - loss: 0.4114 - precision_m: 0.6965\n",
            "Epoch 340/500\n",
            "43/43 - 0s - loss: 0.6280 - precision_m: 0.6895\n",
            "Epoch 341/500\n",
            "43/43 - 0s - loss: 0.4890 - precision_m: 0.6965\n",
            "Epoch 342/500\n",
            "43/43 - 0s - loss: 0.8693 - precision_m: 0.6930\n",
            "Epoch 343/500\n",
            "43/43 - 0s - loss: 0.7304 - precision_m: 0.7000\n",
            "Epoch 344/500\n",
            "43/43 - 0s - loss: 0.5484 - precision_m: 0.6930\n",
            "Epoch 345/500\n",
            "43/43 - 0s - loss: 0.6809 - precision_m: 0.6965\n",
            "Epoch 346/500\n",
            "43/43 - 0s - loss: 1.2603 - precision_m: 0.7000\n",
            "Epoch 347/500\n",
            "43/43 - 0s - loss: 0.4971 - precision_m: 0.6965\n",
            "Epoch 348/500\n",
            "43/43 - 0s - loss: 0.5039 - precision_m: 0.6965\n",
            "Epoch 349/500\n",
            "43/43 - 0s - loss: 0.6521 - precision_m: 0.6930\n",
            "Epoch 350/500\n",
            "43/43 - 0s - loss: 0.9171 - precision_m: 0.6965\n",
            "Epoch 351/500\n",
            "43/43 - 0s - loss: 0.6702 - precision_m: 0.7000\n",
            "Epoch 352/500\n",
            "43/43 - 0s - loss: 0.6400 - precision_m: 0.7000\n",
            "Epoch 353/500\n",
            "43/43 - 0s - loss: 0.7866 - precision_m: 0.6930\n",
            "Epoch 354/500\n",
            "43/43 - 0s - loss: 0.6171 - precision_m: 0.6965\n",
            "Epoch 355/500\n",
            "43/43 - 0s - loss: 0.4471 - precision_m: 0.7000\n",
            "Epoch 356/500\n",
            "43/43 - 0s - loss: 0.6058 - precision_m: 0.6965\n",
            "Epoch 357/500\n",
            "43/43 - 0s - loss: 0.7559 - precision_m: 0.6930\n",
            "Epoch 358/500\n",
            "43/43 - 0s - loss: 0.4564 - precision_m: 0.6965\n",
            "Epoch 359/500\n",
            "43/43 - 0s - loss: 0.5688 - precision_m: 0.6930\n",
            "Epoch 360/500\n",
            "43/43 - 0s - loss: 0.5855 - precision_m: 0.6930\n",
            "Epoch 361/500\n",
            "43/43 - 0s - loss: 0.4699 - precision_m: 0.7000\n",
            "Epoch 362/500\n",
            "43/43 - 0s - loss: 0.4476 - precision_m: 0.6930\n",
            "Epoch 363/500\n",
            "43/43 - 0s - loss: 0.7421 - precision_m: 0.6930\n",
            "Epoch 364/500\n",
            "43/43 - 0s - loss: 0.5888 - precision_m: 0.6965\n",
            "Epoch 365/500\n",
            "43/43 - 0s - loss: 0.8487 - precision_m: 0.6930\n",
            "Epoch 366/500\n",
            "43/43 - 0s - loss: 0.9313 - precision_m: 0.7000\n",
            "Epoch 367/500\n",
            "43/43 - 0s - loss: 0.6689 - precision_m: 0.6930\n",
            "Epoch 368/500\n",
            "43/43 - 0s - loss: 0.5946 - precision_m: 0.7000\n",
            "Epoch 369/500\n",
            "43/43 - 0s - loss: 0.6604 - precision_m: 0.6965\n",
            "Epoch 370/500\n",
            "43/43 - 0s - loss: 0.5454 - precision_m: 0.6930\n",
            "Epoch 371/500\n",
            "43/43 - 0s - loss: 0.6267 - precision_m: 0.7000\n",
            "Epoch 372/500\n",
            "43/43 - 0s - loss: 0.4447 - precision_m: 0.6965\n",
            "Epoch 373/500\n",
            "43/43 - 0s - loss: 0.5811 - precision_m: 0.6930\n",
            "Epoch 374/500\n",
            "43/43 - 0s - loss: 0.4906 - precision_m: 0.7000\n",
            "Epoch 375/500\n",
            "43/43 - 0s - loss: 0.9259 - precision_m: 0.7000\n",
            "Epoch 376/500\n",
            "43/43 - 0s - loss: 0.6859 - precision_m: 0.6965\n",
            "Epoch 377/500\n",
            "43/43 - 0s - loss: 0.8121 - precision_m: 0.6965\n",
            "Epoch 378/500\n",
            "43/43 - 0s - loss: 0.5393 - precision_m: 0.7000\n",
            "Epoch 379/500\n",
            "43/43 - 0s - loss: 0.6577 - precision_m: 0.6965\n",
            "Epoch 380/500\n",
            "43/43 - 0s - loss: 0.5854 - precision_m: 0.6965\n",
            "Epoch 381/500\n",
            "43/43 - 0s - loss: 0.5711 - precision_m: 0.6965\n",
            "Epoch 382/500\n",
            "43/43 - 0s - loss: 1.2681 - precision_m: 0.6930\n",
            "Epoch 383/500\n",
            "43/43 - 0s - loss: 0.6487 - precision_m: 0.6930\n",
            "Epoch 384/500\n",
            "43/43 - 0s - loss: 0.5459 - precision_m: 0.6965\n",
            "Epoch 385/500\n",
            "43/43 - 0s - loss: 0.8063 - precision_m: 0.6965\n",
            "Epoch 386/500\n",
            "43/43 - 0s - loss: 0.5887 - precision_m: 0.6965\n",
            "Epoch 387/500\n",
            "43/43 - 0s - loss: 1.9710 - precision_m: 0.6930\n",
            "Epoch 388/500\n",
            "43/43 - 0s - loss: 0.8381 - precision_m: 0.6965\n",
            "Epoch 389/500\n",
            "43/43 - 0s - loss: 0.6656 - precision_m: 0.7000\n",
            "Epoch 390/500\n",
            "43/43 - 0s - loss: 0.5911 - precision_m: 0.6965\n",
            "Epoch 391/500\n",
            "43/43 - 0s - loss: 0.6798 - precision_m: 0.6930\n",
            "Epoch 392/500\n",
            "43/43 - 0s - loss: 0.5646 - precision_m: 0.6965\n",
            "Epoch 393/500\n",
            "43/43 - 0s - loss: 0.6259 - precision_m: 0.6965\n",
            "Epoch 394/500\n",
            "43/43 - 0s - loss: 1.0909 - precision_m: 0.7000\n",
            "Epoch 395/500\n",
            "43/43 - 0s - loss: 0.6479 - precision_m: 0.6930\n",
            "Epoch 396/500\n",
            "43/43 - 0s - loss: 0.4408 - precision_m: 0.6930\n",
            "Epoch 397/500\n",
            "43/43 - 0s - loss: 0.5519 - precision_m: 0.6965\n",
            "Epoch 398/500\n",
            "43/43 - 0s - loss: 0.5474 - precision_m: 0.6965\n",
            "Epoch 399/500\n",
            "43/43 - 0s - loss: 0.5923 - precision_m: 0.6895\n",
            "Epoch 400/500\n",
            "43/43 - 0s - loss: 0.4887 - precision_m: 0.6965\n",
            "Epoch 401/500\n",
            "43/43 - 0s - loss: 0.8473 - precision_m: 0.6930\n",
            "Epoch 402/500\n",
            "43/43 - 0s - loss: 0.9962 - precision_m: 0.6965\n",
            "Epoch 403/500\n",
            "43/43 - 0s - loss: 0.6273 - precision_m: 0.6965\n",
            "Epoch 404/500\n",
            "43/43 - 0s - loss: 0.5163 - precision_m: 0.6965\n",
            "Epoch 405/500\n",
            "43/43 - 0s - loss: 0.6027 - precision_m: 0.6965\n",
            "Epoch 406/500\n",
            "43/43 - 0s - loss: 0.6330 - precision_m: 0.6965\n",
            "Epoch 407/500\n",
            "43/43 - 0s - loss: 0.7541 - precision_m: 0.6965\n",
            "Epoch 408/500\n",
            "43/43 - 0s - loss: 0.7105 - precision_m: 0.7000\n",
            "Epoch 409/500\n",
            "43/43 - 0s - loss: 0.5699 - precision_m: 0.7000\n",
            "Epoch 410/500\n",
            "43/43 - 0s - loss: 0.6838 - precision_m: 0.6965\n",
            "Epoch 411/500\n",
            "43/43 - 0s - loss: 0.5359 - precision_m: 0.6930\n",
            "Epoch 412/500\n",
            "43/43 - 0s - loss: 0.4594 - precision_m: 0.6930\n",
            "Epoch 413/500\n",
            "43/43 - 0s - loss: 0.5428 - precision_m: 0.6965\n",
            "Epoch 414/500\n",
            "43/43 - 0s - loss: 0.4952 - precision_m: 0.6930\n",
            "Epoch 415/500\n",
            "43/43 - 0s - loss: 0.7415 - precision_m: 0.6930\n",
            "Epoch 416/500\n",
            "43/43 - 0s - loss: 0.7294 - precision_m: 0.6965\n",
            "Epoch 417/500\n",
            "43/43 - 0s - loss: 0.4351 - precision_m: 0.6930\n",
            "Epoch 418/500\n",
            "43/43 - 0s - loss: 0.4813 - precision_m: 0.6930\n",
            "Epoch 419/500\n",
            "43/43 - 0s - loss: 0.5966 - precision_m: 0.6965\n",
            "Epoch 420/500\n",
            "43/43 - 0s - loss: 0.4771 - precision_m: 0.6965\n",
            "Epoch 421/500\n",
            "43/43 - 0s - loss: 0.6034 - precision_m: 0.6895\n",
            "Epoch 422/500\n",
            "43/43 - 0s - loss: 0.6936 - precision_m: 0.6965\n",
            "Epoch 423/500\n",
            "43/43 - 0s - loss: 0.7386 - precision_m: 0.6965\n",
            "Epoch 424/500\n",
            "43/43 - 0s - loss: 0.4932 - precision_m: 0.6930\n",
            "Epoch 425/500\n",
            "43/43 - 0s - loss: 0.5525 - precision_m: 0.6965\n",
            "Epoch 426/500\n",
            "43/43 - 0s - loss: 0.3996 - precision_m: 0.6930\n",
            "Epoch 427/500\n",
            "43/43 - 0s - loss: 0.6075 - precision_m: 0.6965\n",
            "Epoch 428/500\n",
            "43/43 - 0s - loss: 0.6221 - precision_m: 0.7000\n",
            "Epoch 429/500\n",
            "43/43 - 0s - loss: 0.5250 - precision_m: 0.6965\n",
            "Epoch 430/500\n",
            "43/43 - 0s - loss: 0.6058 - precision_m: 0.6895\n",
            "Epoch 431/500\n",
            "43/43 - 0s - loss: 0.5424 - precision_m: 0.6930\n",
            "Epoch 432/500\n",
            "43/43 - 0s - loss: 0.4325 - precision_m: 0.6930\n",
            "Epoch 433/500\n",
            "43/43 - 0s - loss: 0.4538 - precision_m: 0.6965\n",
            "Epoch 434/500\n",
            "43/43 - 0s - loss: 0.8053 - precision_m: 0.6930\n",
            "Epoch 435/500\n",
            "43/43 - 0s - loss: 0.4755 - precision_m: 0.6965\n",
            "Epoch 436/500\n",
            "43/43 - 0s - loss: 0.4086 - precision_m: 0.6965\n",
            "Epoch 437/500\n",
            "43/43 - 0s - loss: 0.6669 - precision_m: 0.6930\n",
            "Epoch 438/500\n",
            "43/43 - 0s - loss: 0.8480 - precision_m: 0.6965\n",
            "Epoch 439/500\n",
            "43/43 - 0s - loss: 1.4118 - precision_m: 0.7000\n",
            "Epoch 440/500\n",
            "43/43 - 0s - loss: 0.8053 - precision_m: 0.7000\n",
            "Epoch 441/500\n",
            "43/43 - 0s - loss: 0.5942 - precision_m: 0.6965\n",
            "Epoch 442/500\n",
            "43/43 - 0s - loss: 0.7059 - precision_m: 0.7000\n",
            "Epoch 443/500\n",
            "43/43 - 0s - loss: 0.6515 - precision_m: 0.6895\n",
            "Epoch 444/500\n",
            "43/43 - 0s - loss: 0.6328 - precision_m: 0.6895\n",
            "Epoch 445/500\n",
            "43/43 - 0s - loss: 0.4340 - precision_m: 0.6965\n",
            "Epoch 446/500\n",
            "43/43 - 0s - loss: 0.7003 - precision_m: 0.6965\n",
            "Epoch 447/500\n",
            "43/43 - 0s - loss: 0.4662 - precision_m: 0.6965\n",
            "Epoch 448/500\n",
            "43/43 - 0s - loss: 0.7528 - precision_m: 0.7000\n",
            "Epoch 449/500\n",
            "43/43 - 0s - loss: 0.4837 - precision_m: 0.6930\n",
            "Epoch 450/500\n",
            "43/43 - 0s - loss: 0.5650 - precision_m: 0.6930\n",
            "Epoch 451/500\n",
            "43/43 - 0s - loss: 0.4596 - precision_m: 0.6965\n",
            "Epoch 452/500\n",
            "43/43 - 0s - loss: 0.5652 - precision_m: 0.7000\n",
            "Epoch 453/500\n",
            "43/43 - 0s - loss: 0.6608 - precision_m: 0.7000\n",
            "Epoch 454/500\n",
            "43/43 - 0s - loss: 0.6766 - precision_m: 0.7000\n",
            "Epoch 455/500\n",
            "43/43 - 0s - loss: 0.8940 - precision_m: 0.6930\n",
            "Epoch 456/500\n",
            "43/43 - 0s - loss: 0.7677 - precision_m: 0.6930\n",
            "Epoch 457/500\n",
            "43/43 - 0s - loss: 0.7003 - precision_m: 0.6930\n",
            "Epoch 458/500\n",
            "43/43 - 0s - loss: 0.4558 - precision_m: 0.6965\n",
            "Epoch 459/500\n",
            "43/43 - 0s - loss: 0.4990 - precision_m: 0.6965\n",
            "Epoch 460/500\n",
            "43/43 - 0s - loss: 0.5207 - precision_m: 0.6965\n",
            "Epoch 461/500\n",
            "43/43 - 0s - loss: 0.6717 - precision_m: 0.7000\n",
            "Epoch 462/500\n",
            "43/43 - 0s - loss: 0.5709 - precision_m: 0.6930\n",
            "Epoch 463/500\n",
            "43/43 - 0s - loss: 0.5388 - precision_m: 0.7000\n",
            "Epoch 464/500\n",
            "43/43 - 0s - loss: 0.4249 - precision_m: 0.6965\n",
            "Epoch 465/500\n",
            "43/43 - 0s - loss: 0.6456 - precision_m: 0.6930\n",
            "Epoch 466/500\n",
            "43/43 - 0s - loss: 0.7682 - precision_m: 0.7000\n",
            "Epoch 467/500\n",
            "43/43 - 0s - loss: 0.5794 - precision_m: 0.7000\n",
            "Epoch 468/500\n",
            "43/43 - 0s - loss: 0.7925 - precision_m: 0.6930\n",
            "Epoch 469/500\n",
            "43/43 - 0s - loss: 0.6121 - precision_m: 0.6930\n",
            "Epoch 470/500\n",
            "43/43 - 0s - loss: 0.6221 - precision_m: 0.7000\n",
            "Epoch 471/500\n",
            "43/43 - 0s - loss: 0.6196 - precision_m: 0.6965\n",
            "Epoch 472/500\n",
            "43/43 - 0s - loss: 0.8670 - precision_m: 0.7000\n",
            "Epoch 473/500\n",
            "43/43 - 0s - loss: 0.4160 - precision_m: 0.6965\n",
            "Epoch 474/500\n",
            "43/43 - 0s - loss: 0.5217 - precision_m: 0.6965\n",
            "Epoch 475/500\n",
            "43/43 - 0s - loss: 0.3999 - precision_m: 0.6930\n",
            "Epoch 476/500\n",
            "43/43 - 0s - loss: 0.9974 - precision_m: 0.6930\n",
            "Epoch 477/500\n",
            "43/43 - 0s - loss: 0.5830 - precision_m: 0.6965\n",
            "Epoch 478/500\n",
            "43/43 - 0s - loss: 0.6189 - precision_m: 0.6965\n",
            "Epoch 479/500\n",
            "43/43 - 0s - loss: 1.1398 - precision_m: 0.6895\n",
            "Epoch 480/500\n",
            "43/43 - 0s - loss: 1.0490 - precision_m: 0.7000\n",
            "Epoch 481/500\n",
            "43/43 - 0s - loss: 0.7051 - precision_m: 0.6965\n",
            "Epoch 482/500\n",
            "43/43 - 0s - loss: 0.5091 - precision_m: 0.6895\n",
            "Epoch 483/500\n",
            "43/43 - 0s - loss: 0.5461 - precision_m: 0.6895\n",
            "Epoch 484/500\n",
            "43/43 - 0s - loss: 0.4664 - precision_m: 0.6895\n",
            "Epoch 485/500\n",
            "43/43 - 0s - loss: 0.6071 - precision_m: 0.6965\n",
            "Epoch 486/500\n",
            "43/43 - 0s - loss: 0.8542 - precision_m: 0.6965\n",
            "Epoch 487/500\n",
            "43/43 - 0s - loss: 0.6101 - precision_m: 0.6895\n",
            "Epoch 488/500\n",
            "43/43 - 0s - loss: 0.4519 - precision_m: 0.6965\n",
            "Epoch 489/500\n",
            "43/43 - 0s - loss: 0.7742 - precision_m: 0.6930\n",
            "Epoch 490/500\n",
            "43/43 - 0s - loss: 0.6318 - precision_m: 0.6895\n",
            "Epoch 491/500\n",
            "43/43 - 0s - loss: 0.6504 - precision_m: 0.6930\n",
            "Epoch 492/500\n",
            "43/43 - 0s - loss: 0.6112 - precision_m: 0.6895\n",
            "Epoch 493/500\n",
            "43/43 - 0s - loss: 0.5057 - precision_m: 0.6965\n",
            "Epoch 494/500\n",
            "43/43 - 0s - loss: 1.2406 - precision_m: 0.6895\n",
            "Epoch 495/500\n",
            "43/43 - 0s - loss: 0.6069 - precision_m: 0.7000\n",
            "Epoch 496/500\n",
            "43/43 - 0s - loss: 0.3860 - precision_m: 0.6965\n",
            "Epoch 497/500\n",
            "43/43 - 0s - loss: 0.5770 - precision_m: 0.6965\n",
            "Epoch 498/500\n",
            "43/43 - 0s - loss: 0.6651 - precision_m: 0.7000\n",
            "Epoch 499/500\n",
            "43/43 - 0s - loss: 0.5117 - precision_m: 0.6930\n",
            "Epoch 500/500\n",
            "43/43 - 0s - loss: 0.9156 - precision_m: 0.6965\n",
            "CPU times: user 42.2 s, sys: 3.72 s, total: 45.9 s\n",
            "Wall time: 37.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6Qht-SbNsHd",
        "outputId": "df9c9217-39a1-4387-e8bc-f86f90aada7c"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.5.0\n",
            "Running on TPU  ['10.33.212.162:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.33.212.162:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.33.212.162:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpeTPWVAODme"
      },
      "source": [
        "def create_model():\n",
        "  model = Sequential([\n",
        "    Dense(units=16, input_shape=(14,), activation='relu'), #First hidden layer\n",
        "    Dense(units=32, activation='relu'),\n",
        "    Dense(units=2, activation='softmax')\n",
        "])\n",
        "  model.compile(optimizer=Adam(learning_rate=0.0001),loss='sparse_categorical_crossentropy', metrics=[precision_m])\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jhTeFgCOc7w",
        "outputId": "b8920764-5c95-43f5-920c-ccc8cb6da092"
      },
      "source": [
        "with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "  model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16)                240       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 850\n",
            "Trainable params: 850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2OxVYLTMFbP",
        "outputId": "dcdda98e-307a-4892-9d72-ae392f8d3638"
      },
      "source": [
        "%%time\n",
        "\n",
        "model.fit(x=train, y=train_y, batch_size=10, epochs=500, shuffle=True, verbose=2)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "43/43 - 4s - loss: 836.6110 - precision_m: 0.4186\n",
            "Epoch 2/500\n",
            "43/43 - 0s - loss: 676.8171 - precision_m: 0.4215\n",
            "Epoch 3/500\n",
            "43/43 - 0s - loss: 513.4035 - precision_m: 0.4186\n",
            "Epoch 4/500\n",
            "43/43 - 0s - loss: 355.6233 - precision_m: 0.4186\n",
            "Epoch 5/500\n",
            "43/43 - 0s - loss: 213.1276 - precision_m: 0.4186\n",
            "Epoch 6/500\n",
            "43/43 - 0s - loss: 102.5852 - precision_m: 0.4215\n",
            "Epoch 7/500\n",
            "43/43 - 0s - loss: 45.0692 - precision_m: 0.4186\n",
            "Epoch 8/500\n",
            "43/43 - 0s - loss: 38.6449 - precision_m: 0.4186\n",
            "Epoch 9/500\n",
            "43/43 - 0s - loss: 34.8491 - precision_m: 0.4186\n",
            "Epoch 10/500\n",
            "43/43 - 0s - loss: 32.0275 - precision_m: 0.4201\n",
            "Epoch 11/500\n",
            "43/43 - 0s - loss: 29.7974 - precision_m: 0.4215\n",
            "Epoch 12/500\n",
            "43/43 - 0s - loss: 28.3842 - precision_m: 0.4186\n",
            "Epoch 13/500\n",
            "43/43 - 0s - loss: 27.5590 - precision_m: 0.4201\n",
            "Epoch 14/500\n",
            "43/43 - 0s - loss: 26.0509 - precision_m: 0.4186\n",
            "Epoch 15/500\n",
            "43/43 - 0s - loss: 24.5860 - precision_m: 0.4201\n",
            "Epoch 16/500\n",
            "43/43 - 0s - loss: 23.7713 - precision_m: 0.4186\n",
            "Epoch 17/500\n",
            "43/43 - 0s - loss: 22.2361 - precision_m: 0.4186\n",
            "Epoch 18/500\n",
            "43/43 - 0s - loss: 21.1864 - precision_m: 0.4201\n",
            "Epoch 19/500\n",
            "43/43 - 0s - loss: 20.3423 - precision_m: 0.4201\n",
            "Epoch 20/500\n",
            "43/43 - 0s - loss: 19.1475 - precision_m: 0.4186\n",
            "Epoch 21/500\n",
            "43/43 - 0s - loss: 18.0998 - precision_m: 0.4201\n",
            "Epoch 22/500\n",
            "43/43 - 0s - loss: 17.4912 - precision_m: 0.4186\n",
            "Epoch 23/500\n",
            "43/43 - 0s - loss: 17.3709 - precision_m: 0.4172\n",
            "Epoch 24/500\n",
            "43/43 - 0s - loss: 16.3673 - precision_m: 0.4201\n",
            "Epoch 25/500\n",
            "43/43 - 0s - loss: 15.4703 - precision_m: 0.4186\n",
            "Epoch 26/500\n",
            "43/43 - 0s - loss: 16.1428 - precision_m: 0.4186\n",
            "Epoch 27/500\n",
            "43/43 - 0s - loss: 15.0873 - precision_m: 0.4186\n",
            "Epoch 28/500\n",
            "43/43 - 0s - loss: 14.5042 - precision_m: 0.4201\n",
            "Epoch 29/500\n",
            "43/43 - 0s - loss: 14.0338 - precision_m: 0.4201\n",
            "Epoch 30/500\n",
            "43/43 - 0s - loss: 13.9849 - precision_m: 0.4186\n",
            "Epoch 31/500\n",
            "43/43 - 0s - loss: 13.0869 - precision_m: 0.4186\n",
            "Epoch 32/500\n",
            "43/43 - 0s - loss: 13.4949 - precision_m: 0.4201\n",
            "Epoch 33/500\n",
            "43/43 - 0s - loss: 12.6031 - precision_m: 0.4186\n",
            "Epoch 34/500\n",
            "43/43 - 0s - loss: 12.3537 - precision_m: 0.4201\n",
            "Epoch 35/500\n",
            "43/43 - 0s - loss: 12.1196 - precision_m: 0.4186\n",
            "Epoch 36/500\n",
            "43/43 - 0s - loss: 11.2236 - precision_m: 0.4201\n",
            "Epoch 37/500\n",
            "43/43 - 0s - loss: 11.0160 - precision_m: 0.4201\n",
            "Epoch 38/500\n",
            "43/43 - 0s - loss: 10.6044 - precision_m: 0.4201\n",
            "Epoch 39/500\n",
            "43/43 - 0s - loss: 10.7155 - precision_m: 0.4186\n",
            "Epoch 40/500\n",
            "43/43 - 0s - loss: 10.0005 - precision_m: 0.4215\n",
            "Epoch 41/500\n",
            "43/43 - 0s - loss: 9.1420 - precision_m: 0.4186\n",
            "Epoch 42/500\n",
            "43/43 - 0s - loss: 8.8480 - precision_m: 0.4215\n",
            "Epoch 43/500\n",
            "43/43 - 0s - loss: 8.6308 - precision_m: 0.4215\n",
            "Epoch 44/500\n",
            "43/43 - 0s - loss: 7.9736 - precision_m: 0.4186\n",
            "Epoch 45/500\n",
            "43/43 - 0s - loss: 7.7606 - precision_m: 0.4201\n",
            "Epoch 46/500\n",
            "43/43 - 0s - loss: 6.9053 - precision_m: 0.4201\n",
            "Epoch 47/500\n",
            "43/43 - 0s - loss: 7.1176 - precision_m: 0.4201\n",
            "Epoch 48/500\n",
            "43/43 - 0s - loss: 6.3938 - precision_m: 0.4186\n",
            "Epoch 49/500\n",
            "43/43 - 0s - loss: 6.6826 - precision_m: 0.4215\n",
            "Epoch 50/500\n",
            "43/43 - 0s - loss: 5.4105 - precision_m: 0.4201\n",
            "Epoch 51/500\n",
            "43/43 - 0s - loss: 5.2505 - precision_m: 0.4201\n",
            "Epoch 52/500\n",
            "43/43 - 0s - loss: 5.5692 - precision_m: 0.4215\n",
            "Epoch 53/500\n",
            "43/43 - 0s - loss: 5.8232 - precision_m: 0.4215\n",
            "Epoch 54/500\n",
            "43/43 - 0s - loss: 4.7305 - precision_m: 0.4215\n",
            "Epoch 55/500\n",
            "43/43 - 0s - loss: 5.0236 - precision_m: 0.4201\n",
            "Epoch 56/500\n",
            "43/43 - 0s - loss: 4.5639 - precision_m: 0.4186\n",
            "Epoch 57/500\n",
            "43/43 - 0s - loss: 3.7170 - precision_m: 0.4201\n",
            "Epoch 58/500\n",
            "43/43 - 0s - loss: 3.5138 - precision_m: 0.4215\n",
            "Epoch 59/500\n",
            "43/43 - 0s - loss: 3.2311 - precision_m: 0.4186\n",
            "Epoch 60/500\n",
            "43/43 - 0s - loss: 3.1604 - precision_m: 0.4201\n",
            "Epoch 61/500\n",
            "43/43 - 0s - loss: 2.9304 - precision_m: 0.4157\n",
            "Epoch 62/500\n",
            "43/43 - 0s - loss: 2.7933 - precision_m: 0.4201\n",
            "Epoch 63/500\n",
            "43/43 - 0s - loss: 2.4338 - precision_m: 0.4186\n",
            "Epoch 64/500\n",
            "43/43 - 0s - loss: 2.5576 - precision_m: 0.4201\n",
            "Epoch 65/500\n",
            "43/43 - 0s - loss: 2.5209 - precision_m: 0.4186\n",
            "Epoch 66/500\n",
            "43/43 - 0s - loss: 2.4448 - precision_m: 0.4201\n",
            "Epoch 67/500\n",
            "43/43 - 0s - loss: 2.3848 - precision_m: 0.4201\n",
            "Epoch 68/500\n",
            "43/43 - 0s - loss: 1.9596 - precision_m: 0.4172\n",
            "Epoch 69/500\n",
            "43/43 - 0s - loss: 2.2839 - precision_m: 0.4186\n",
            "Epoch 70/500\n",
            "43/43 - 0s - loss: 4.1647 - precision_m: 0.4172\n",
            "Epoch 71/500\n",
            "43/43 - 0s - loss: 3.4234 - precision_m: 0.4186\n",
            "Epoch 72/500\n",
            "43/43 - 0s - loss: 2.8945 - precision_m: 0.4201\n",
            "Epoch 73/500\n",
            "43/43 - 0s - loss: 2.3435 - precision_m: 0.4215\n",
            "Epoch 74/500\n",
            "43/43 - 0s - loss: 1.8868 - precision_m: 0.4186\n",
            "Epoch 75/500\n",
            "43/43 - 0s - loss: 3.3318 - precision_m: 0.4201\n",
            "Epoch 76/500\n",
            "43/43 - 0s - loss: 2.7834 - precision_m: 0.4201\n",
            "Epoch 77/500\n",
            "43/43 - 0s - loss: 2.1155 - precision_m: 0.4201\n",
            "Epoch 78/500\n",
            "43/43 - 0s - loss: 1.6682 - precision_m: 0.4186\n",
            "Epoch 79/500\n",
            "43/43 - 0s - loss: 2.1627 - precision_m: 0.4186\n",
            "Epoch 80/500\n",
            "43/43 - 0s - loss: 2.0899 - precision_m: 0.4201\n",
            "Epoch 81/500\n",
            "43/43 - 0s - loss: 2.5263 - precision_m: 0.4201\n",
            "Epoch 82/500\n",
            "43/43 - 0s - loss: 1.8610 - precision_m: 0.4201\n",
            "Epoch 83/500\n",
            "43/43 - 0s - loss: 1.7529 - precision_m: 0.4215\n",
            "Epoch 84/500\n",
            "43/43 - 0s - loss: 2.2755 - precision_m: 0.4215\n",
            "Epoch 85/500\n",
            "43/43 - 0s - loss: 1.6184 - precision_m: 0.4201\n",
            "Epoch 86/500\n",
            "43/43 - 0s - loss: 1.7561 - precision_m: 0.4201\n",
            "Epoch 87/500\n",
            "43/43 - 0s - loss: 1.9292 - precision_m: 0.4172\n",
            "Epoch 88/500\n",
            "43/43 - 0s - loss: 1.9386 - precision_m: 0.4215\n",
            "Epoch 89/500\n",
            "43/43 - 0s - loss: 2.2113 - precision_m: 0.4201\n",
            "Epoch 90/500\n",
            "43/43 - 0s - loss: 1.9987 - precision_m: 0.4186\n",
            "Epoch 91/500\n",
            "43/43 - 0s - loss: 2.2924 - precision_m: 0.4172\n",
            "Epoch 92/500\n",
            "43/43 - 0s - loss: 1.9618 - precision_m: 0.4215\n",
            "Epoch 93/500\n",
            "43/43 - 0s - loss: 2.2425 - precision_m: 0.4201\n",
            "Epoch 94/500\n",
            "43/43 - 0s - loss: 2.2820 - precision_m: 0.4186\n",
            "Epoch 95/500\n",
            "43/43 - 0s - loss: 2.2371 - precision_m: 0.4215\n",
            "Epoch 96/500\n",
            "43/43 - 0s - loss: 2.4499 - precision_m: 0.4201\n",
            "Epoch 97/500\n",
            "43/43 - 0s - loss: 2.4340 - precision_m: 0.4186\n",
            "Epoch 98/500\n",
            "43/43 - 0s - loss: 1.6716 - precision_m: 0.4201\n",
            "Epoch 99/500\n",
            "43/43 - 0s - loss: 2.4356 - precision_m: 0.4201\n",
            "Epoch 100/500\n",
            "43/43 - 0s - loss: 1.7104 - precision_m: 0.4201\n",
            "Epoch 101/500\n",
            "43/43 - 0s - loss: 1.9240 - precision_m: 0.4215\n",
            "Epoch 102/500\n",
            "43/43 - 0s - loss: 2.6979 - precision_m: 0.4172\n",
            "Epoch 103/500\n",
            "43/43 - 0s - loss: 1.5855 - precision_m: 0.4201\n",
            "Epoch 104/500\n",
            "43/43 - 0s - loss: 2.3051 - precision_m: 0.4201\n",
            "Epoch 105/500\n",
            "43/43 - 0s - loss: 1.8317 - precision_m: 0.4201\n",
            "Epoch 106/500\n",
            "43/43 - 0s - loss: 1.8418 - precision_m: 0.4201\n",
            "Epoch 107/500\n",
            "43/43 - 0s - loss: 2.0778 - precision_m: 0.4201\n",
            "Epoch 108/500\n",
            "43/43 - 0s - loss: 1.7674 - precision_m: 0.4201\n",
            "Epoch 109/500\n",
            "43/43 - 0s - loss: 3.6358 - precision_m: 0.4186\n",
            "Epoch 110/500\n",
            "43/43 - 0s - loss: 2.9898 - precision_m: 0.4186\n",
            "Epoch 111/500\n",
            "43/43 - 0s - loss: 2.1190 - precision_m: 0.4201\n",
            "Epoch 112/500\n",
            "43/43 - 0s - loss: 1.9454 - precision_m: 0.4172\n",
            "Epoch 113/500\n",
            "43/43 - 0s - loss: 1.7516 - precision_m: 0.4215\n",
            "Epoch 114/500\n",
            "43/43 - 0s - loss: 1.5381 - precision_m: 0.4201\n",
            "Epoch 115/500\n",
            "43/43 - 0s - loss: 1.5148 - precision_m: 0.4215\n",
            "Epoch 116/500\n",
            "43/43 - 0s - loss: 1.6085 - precision_m: 0.4215\n",
            "Epoch 117/500\n",
            "43/43 - 0s - loss: 1.4479 - precision_m: 0.4201\n",
            "Epoch 118/500\n",
            "43/43 - 0s - loss: 1.3895 - precision_m: 0.4201\n",
            "Epoch 119/500\n",
            "43/43 - 0s - loss: 2.0443 - precision_m: 0.4186\n",
            "Epoch 120/500\n",
            "43/43 - 0s - loss: 1.6271 - precision_m: 0.4157\n",
            "Epoch 121/500\n",
            "43/43 - 0s - loss: 1.3763 - precision_m: 0.4201\n",
            "Epoch 122/500\n",
            "43/43 - 0s - loss: 1.3509 - precision_m: 0.4201\n",
            "Epoch 123/500\n",
            "43/43 - 0s - loss: 1.3149 - precision_m: 0.4201\n",
            "Epoch 124/500\n",
            "43/43 - 0s - loss: 1.3166 - precision_m: 0.4186\n",
            "Epoch 125/500\n",
            "43/43 - 0s - loss: 1.3370 - precision_m: 0.4201\n",
            "Epoch 126/500\n",
            "43/43 - 0s - loss: 1.4705 - precision_m: 0.4186\n",
            "Epoch 127/500\n",
            "43/43 - 0s - loss: 1.5970 - precision_m: 0.4201\n",
            "Epoch 128/500\n",
            "43/43 - 0s - loss: 1.1814 - precision_m: 0.4215\n",
            "Epoch 129/500\n",
            "43/43 - 0s - loss: 1.2700 - precision_m: 0.4201\n",
            "Epoch 130/500\n",
            "43/43 - 0s - loss: 1.3378 - precision_m: 0.4201\n",
            "Epoch 131/500\n",
            "43/43 - 0s - loss: 1.6320 - precision_m: 0.4201\n",
            "Epoch 132/500\n",
            "43/43 - 0s - loss: 1.7762 - precision_m: 0.4201\n",
            "Epoch 133/500\n",
            "43/43 - 0s - loss: 1.6411 - precision_m: 0.4186\n",
            "Epoch 134/500\n",
            "43/43 - 0s - loss: 1.3491 - precision_m: 0.4186\n",
            "Epoch 135/500\n",
            "43/43 - 0s - loss: 2.2419 - precision_m: 0.4186\n",
            "Epoch 136/500\n",
            "43/43 - 0s - loss: 1.5462 - precision_m: 0.4201\n",
            "Epoch 137/500\n",
            "43/43 - 0s - loss: 1.2757 - precision_m: 0.4201\n",
            "Epoch 138/500\n",
            "43/43 - 0s - loss: 1.4224 - precision_m: 0.4201\n",
            "Epoch 139/500\n",
            "43/43 - 0s - loss: 1.7292 - precision_m: 0.4201\n",
            "Epoch 140/500\n",
            "43/43 - 0s - loss: 1.1000 - precision_m: 0.4201\n",
            "Epoch 141/500\n",
            "43/43 - 0s - loss: 1.7743 - precision_m: 0.4186\n",
            "Epoch 142/500\n",
            "43/43 - 0s - loss: 3.5137 - precision_m: 0.4201\n",
            "Epoch 143/500\n",
            "43/43 - 0s - loss: 1.8458 - precision_m: 0.4157\n",
            "Epoch 144/500\n",
            "43/43 - 0s - loss: 1.2307 - precision_m: 0.4201\n",
            "Epoch 145/500\n",
            "43/43 - 0s - loss: 1.8398 - precision_m: 0.4172\n",
            "Epoch 146/500\n",
            "43/43 - 0s - loss: 1.6112 - precision_m: 0.4172\n",
            "Epoch 147/500\n",
            "43/43 - 0s - loss: 0.9561 - precision_m: 0.4186\n",
            "Epoch 148/500\n",
            "43/43 - 0s - loss: 1.9921 - precision_m: 0.4201\n",
            "Epoch 149/500\n",
            "43/43 - 0s - loss: 1.5891 - precision_m: 0.4201\n",
            "Epoch 150/500\n",
            "43/43 - 0s - loss: 1.5094 - precision_m: 0.4186\n",
            "Epoch 151/500\n",
            "43/43 - 0s - loss: 0.9908 - precision_m: 0.4186\n",
            "Epoch 152/500\n",
            "43/43 - 0s - loss: 2.0296 - precision_m: 0.4201\n",
            "Epoch 153/500\n",
            "43/43 - 0s - loss: 0.9451 - precision_m: 0.4201\n",
            "Epoch 154/500\n",
            "43/43 - 0s - loss: 1.5561 - precision_m: 0.4186\n",
            "Epoch 155/500\n",
            "43/43 - 0s - loss: 1.3869 - precision_m: 0.4215\n",
            "Epoch 156/500\n",
            "43/43 - 0s - loss: 1.3892 - precision_m: 0.4172\n",
            "Epoch 157/500\n",
            "43/43 - 0s - loss: 1.1428 - precision_m: 0.4186\n",
            "Epoch 158/500\n",
            "43/43 - 0s - loss: 1.1150 - precision_m: 0.4201\n",
            "Epoch 159/500\n",
            "43/43 - 0s - loss: 2.0495 - precision_m: 0.4201\n",
            "Epoch 160/500\n",
            "43/43 - 0s - loss: 1.3408 - precision_m: 0.4186\n",
            "Epoch 161/500\n",
            "43/43 - 0s - loss: 1.1086 - precision_m: 0.4215\n",
            "Epoch 162/500\n",
            "43/43 - 0s - loss: 1.5643 - precision_m: 0.4186\n",
            "Epoch 163/500\n",
            "43/43 - 0s - loss: 1.1055 - precision_m: 0.4215\n",
            "Epoch 164/500\n",
            "43/43 - 0s - loss: 1.2576 - precision_m: 0.4201\n",
            "Epoch 165/500\n",
            "43/43 - 0s - loss: 1.3985 - precision_m: 0.4201\n",
            "Epoch 166/500\n",
            "43/43 - 0s - loss: 1.1301 - precision_m: 0.4186\n",
            "Epoch 167/500\n",
            "43/43 - 0s - loss: 1.2093 - precision_m: 0.4215\n",
            "Epoch 168/500\n",
            "43/43 - 0s - loss: 1.7051 - precision_m: 0.4201\n",
            "Epoch 169/500\n",
            "43/43 - 0s - loss: 1.7707 - precision_m: 0.4186\n",
            "Epoch 170/500\n",
            "43/43 - 0s - loss: 1.5052 - precision_m: 0.4172\n",
            "Epoch 171/500\n",
            "43/43 - 0s - loss: 1.5295 - precision_m: 0.4186\n",
            "Epoch 172/500\n",
            "43/43 - 0s - loss: 1.7425 - precision_m: 0.4215\n",
            "Epoch 173/500\n",
            "43/43 - 0s - loss: 1.5636 - precision_m: 0.4215\n",
            "Epoch 174/500\n",
            "43/43 - 0s - loss: 2.1367 - precision_m: 0.4201\n",
            "Epoch 175/500\n",
            "43/43 - 0s - loss: 1.7018 - precision_m: 0.4201\n",
            "Epoch 176/500\n",
            "43/43 - 0s - loss: 1.2155 - precision_m: 0.4201\n",
            "Epoch 177/500\n",
            "43/43 - 0s - loss: 1.2950 - precision_m: 0.4201\n",
            "Epoch 178/500\n",
            "43/43 - 0s - loss: 1.1943 - precision_m: 0.4201\n",
            "Epoch 179/500\n",
            "43/43 - 0s - loss: 1.4784 - precision_m: 0.4201\n",
            "Epoch 180/500\n",
            "43/43 - 0s - loss: 1.8160 - precision_m: 0.4186\n",
            "Epoch 181/500\n",
            "43/43 - 0s - loss: 1.7371 - precision_m: 0.4186\n",
            "Epoch 182/500\n",
            "43/43 - 0s - loss: 1.4450 - precision_m: 0.4215\n",
            "Epoch 183/500\n",
            "43/43 - 0s - loss: 1.4495 - precision_m: 0.4186\n",
            "Epoch 184/500\n",
            "43/43 - 0s - loss: 1.7268 - precision_m: 0.4201\n",
            "Epoch 185/500\n",
            "43/43 - 0s - loss: 1.2356 - precision_m: 0.4201\n",
            "Epoch 186/500\n",
            "43/43 - 0s - loss: 2.6465 - precision_m: 0.4201\n",
            "Epoch 187/500\n",
            "43/43 - 0s - loss: 1.7361 - precision_m: 0.4186\n",
            "Epoch 188/500\n",
            "43/43 - 0s - loss: 1.0753 - precision_m: 0.4201\n",
            "Epoch 189/500\n",
            "43/43 - 0s - loss: 1.4357 - precision_m: 0.4186\n",
            "Epoch 190/500\n",
            "43/43 - 0s - loss: 1.1799 - precision_m: 0.4215\n",
            "Epoch 191/500\n",
            "43/43 - 0s - loss: 1.5457 - precision_m: 0.4201\n",
            "Epoch 192/500\n",
            "43/43 - 0s - loss: 1.2350 - precision_m: 0.4186\n",
            "Epoch 193/500\n",
            "43/43 - 0s - loss: 1.6859 - precision_m: 0.4201\n",
            "Epoch 194/500\n",
            "43/43 - 0s - loss: 0.9680 - precision_m: 0.4201\n",
            "Epoch 195/500\n",
            "43/43 - 0s - loss: 1.6238 - precision_m: 0.4186\n",
            "Epoch 196/500\n",
            "43/43 - 0s - loss: 1.5830 - precision_m: 0.4201\n",
            "Epoch 197/500\n",
            "43/43 - 0s - loss: 1.5947 - precision_m: 0.4172\n",
            "Epoch 198/500\n",
            "43/43 - 0s - loss: 1.2332 - precision_m: 0.4172\n",
            "Epoch 199/500\n",
            "43/43 - 0s - loss: 1.5115 - precision_m: 0.4186\n",
            "Epoch 200/500\n",
            "43/43 - 0s - loss: 1.1637 - precision_m: 0.4186\n",
            "Epoch 201/500\n",
            "43/43 - 0s - loss: 1.7826 - precision_m: 0.4215\n",
            "Epoch 202/500\n",
            "43/43 - 0s - loss: 1.6949 - precision_m: 0.4215\n",
            "Epoch 203/500\n",
            "43/43 - 0s - loss: 2.0536 - precision_m: 0.4186\n",
            "Epoch 204/500\n",
            "43/43 - 0s - loss: 1.4636 - precision_m: 0.4201\n",
            "Epoch 205/500\n",
            "43/43 - 0s - loss: 1.5924 - precision_m: 0.4157\n",
            "Epoch 206/500\n",
            "43/43 - 0s - loss: 1.9328 - precision_m: 0.4186\n",
            "Epoch 207/500\n",
            "43/43 - 0s - loss: 1.1096 - precision_m: 0.4201\n",
            "Epoch 208/500\n",
            "43/43 - 0s - loss: 1.8152 - precision_m: 0.4201\n",
            "Epoch 209/500\n",
            "43/43 - 0s - loss: 1.5415 - precision_m: 0.4201\n",
            "Epoch 210/500\n",
            "43/43 - 0s - loss: 2.7932 - precision_m: 0.4215\n",
            "Epoch 211/500\n",
            "43/43 - 0s - loss: 1.5220 - precision_m: 0.4215\n",
            "Epoch 212/500\n",
            "43/43 - 0s - loss: 1.1290 - precision_m: 0.4186\n",
            "Epoch 213/500\n",
            "43/43 - 0s - loss: 1.5568 - precision_m: 0.4186\n",
            "Epoch 214/500\n",
            "43/43 - 0s - loss: 1.7054 - precision_m: 0.4186\n",
            "Epoch 215/500\n",
            "43/43 - 0s - loss: 1.3906 - precision_m: 0.4186\n",
            "Epoch 216/500\n",
            "43/43 - 0s - loss: 1.1894 - precision_m: 0.4201\n",
            "Epoch 217/500\n",
            "43/43 - 0s - loss: 1.4344 - precision_m: 0.4201\n",
            "Epoch 218/500\n",
            "43/43 - 0s - loss: 1.3640 - precision_m: 0.4186\n",
            "Epoch 219/500\n",
            "43/43 - 0s - loss: 1.5001 - precision_m: 0.4215\n",
            "Epoch 220/500\n",
            "43/43 - 0s - loss: 2.5428 - precision_m: 0.4215\n",
            "Epoch 221/500\n",
            "43/43 - 0s - loss: 1.6095 - precision_m: 0.4201\n",
            "Epoch 222/500\n",
            "43/43 - 0s - loss: 1.2955 - precision_m: 0.4186\n",
            "Epoch 223/500\n",
            "43/43 - 0s - loss: 1.1370 - precision_m: 0.4186\n",
            "Epoch 224/500\n",
            "43/43 - 0s - loss: 1.0555 - precision_m: 0.4215\n",
            "Epoch 225/500\n",
            "43/43 - 0s - loss: 1.8063 - precision_m: 0.4201\n",
            "Epoch 226/500\n",
            "43/43 - 0s - loss: 1.4673 - precision_m: 0.4201\n",
            "Epoch 227/500\n",
            "43/43 - 0s - loss: 1.7770 - precision_m: 0.4201\n",
            "Epoch 228/500\n",
            "43/43 - 0s - loss: 1.9364 - precision_m: 0.4186\n",
            "Epoch 229/500\n",
            "43/43 - 0s - loss: 2.4997 - precision_m: 0.4215\n",
            "Epoch 230/500\n",
            "43/43 - 0s - loss: 1.5781 - precision_m: 0.4186\n",
            "Epoch 231/500\n",
            "43/43 - 0s - loss: 0.8853 - precision_m: 0.4186\n",
            "Epoch 232/500\n",
            "43/43 - 0s - loss: 1.6956 - precision_m: 0.4172\n",
            "Epoch 233/500\n",
            "43/43 - 0s - loss: 0.9186 - precision_m: 0.4201\n",
            "Epoch 234/500\n",
            "43/43 - 0s - loss: 0.9332 - precision_m: 0.4172\n",
            "Epoch 235/500\n",
            "43/43 - 0s - loss: 1.3841 - precision_m: 0.4215\n",
            "Epoch 236/500\n",
            "43/43 - 0s - loss: 1.8575 - precision_m: 0.4186\n",
            "Epoch 237/500\n",
            "43/43 - 0s - loss: 2.1861 - precision_m: 0.4201\n",
            "Epoch 238/500\n",
            "43/43 - 0s - loss: 1.1947 - precision_m: 0.4186\n",
            "Epoch 239/500\n",
            "43/43 - 0s - loss: 0.9513 - precision_m: 0.4215\n",
            "Epoch 240/500\n",
            "43/43 - 0s - loss: 1.0555 - precision_m: 0.4201\n",
            "Epoch 241/500\n",
            "43/43 - 0s - loss: 0.8156 - precision_m: 0.4201\n",
            "Epoch 242/500\n",
            "43/43 - 0s - loss: 1.5965 - precision_m: 0.4186\n",
            "Epoch 243/500\n",
            "43/43 - 0s - loss: 1.2247 - precision_m: 0.4201\n",
            "Epoch 244/500\n",
            "43/43 - 0s - loss: 1.5995 - precision_m: 0.4201\n",
            "Epoch 245/500\n",
            "43/43 - 0s - loss: 1.3276 - precision_m: 0.4201\n",
            "Epoch 246/500\n",
            "43/43 - 0s - loss: 0.9855 - precision_m: 0.4215\n",
            "Epoch 247/500\n",
            "43/43 - 0s - loss: 1.1012 - precision_m: 0.4201\n",
            "Epoch 248/500\n",
            "43/43 - 0s - loss: 1.1735 - precision_m: 0.4186\n",
            "Epoch 249/500\n",
            "43/43 - 0s - loss: 1.7147 - precision_m: 0.4201\n",
            "Epoch 250/500\n",
            "43/43 - 0s - loss: 1.1702 - precision_m: 0.4201\n",
            "Epoch 251/500\n",
            "43/43 - 0s - loss: 1.3120 - precision_m: 0.4186\n",
            "Epoch 252/500\n",
            "43/43 - 0s - loss: 0.7409 - precision_m: 0.4172\n",
            "Epoch 253/500\n",
            "43/43 - 0s - loss: 1.1263 - precision_m: 0.4201\n",
            "Epoch 254/500\n",
            "43/43 - 0s - loss: 1.1639 - precision_m: 0.4186\n",
            "Epoch 255/500\n",
            "43/43 - 0s - loss: 0.8246 - precision_m: 0.4201\n",
            "Epoch 256/500\n",
            "43/43 - 0s - loss: 1.4349 - precision_m: 0.4186\n",
            "Epoch 257/500\n",
            "43/43 - 0s - loss: 1.0064 - precision_m: 0.4201\n",
            "Epoch 258/500\n",
            "43/43 - 0s - loss: 0.9663 - precision_m: 0.4201\n",
            "Epoch 259/500\n",
            "43/43 - 0s - loss: 1.0656 - precision_m: 0.4172\n",
            "Epoch 260/500\n",
            "43/43 - 0s - loss: 1.2650 - precision_m: 0.4186\n",
            "Epoch 261/500\n",
            "43/43 - 0s - loss: 0.9060 - precision_m: 0.4201\n",
            "Epoch 262/500\n",
            "43/43 - 0s - loss: 0.7266 - precision_m: 0.4215\n",
            "Epoch 263/500\n",
            "43/43 - 0s - loss: 1.1021 - precision_m: 0.4186\n",
            "Epoch 264/500\n",
            "43/43 - 0s - loss: 1.0228 - precision_m: 0.4215\n",
            "Epoch 265/500\n",
            "43/43 - 0s - loss: 0.9820 - precision_m: 0.4201\n",
            "Epoch 266/500\n",
            "43/43 - 0s - loss: 1.7716 - precision_m: 0.4186\n",
            "Epoch 267/500\n",
            "43/43 - 0s - loss: 1.7342 - precision_m: 0.4186\n",
            "Epoch 268/500\n",
            "43/43 - 0s - loss: 1.5187 - precision_m: 0.4215\n",
            "Epoch 269/500\n",
            "43/43 - 0s - loss: 0.9088 - precision_m: 0.4186\n",
            "Epoch 270/500\n",
            "43/43 - 0s - loss: 1.1422 - precision_m: 0.4215\n",
            "Epoch 271/500\n",
            "43/43 - 0s - loss: 1.0190 - precision_m: 0.4186\n",
            "Epoch 272/500\n",
            "43/43 - 0s - loss: 1.0345 - precision_m: 0.4186\n",
            "Epoch 273/500\n",
            "43/43 - 0s - loss: 1.1927 - precision_m: 0.4172\n",
            "Epoch 274/500\n",
            "43/43 - 0s - loss: 1.1002 - precision_m: 0.4186\n",
            "Epoch 275/500\n",
            "43/43 - 0s - loss: 1.2332 - precision_m: 0.4186\n",
            "Epoch 276/500\n",
            "43/43 - 0s - loss: 1.5167 - precision_m: 0.4201\n",
            "Epoch 277/500\n",
            "43/43 - 0s - loss: 1.4155 - precision_m: 0.4201\n",
            "Epoch 278/500\n",
            "43/43 - 0s - loss: 1.1529 - precision_m: 0.4186\n",
            "Epoch 279/500\n",
            "43/43 - 0s - loss: 1.4671 - precision_m: 0.4186\n",
            "Epoch 280/500\n",
            "43/43 - 0s - loss: 1.7335 - precision_m: 0.4186\n",
            "Epoch 281/500\n",
            "43/43 - 0s - loss: 1.7234 - precision_m: 0.4186\n",
            "Epoch 282/500\n",
            "43/43 - 0s - loss: 1.7650 - precision_m: 0.4186\n",
            "Epoch 283/500\n",
            "43/43 - 0s - loss: 1.4637 - precision_m: 0.4201\n",
            "Epoch 284/500\n",
            "43/43 - 0s - loss: 1.4923 - precision_m: 0.4186\n",
            "Epoch 285/500\n",
            "43/43 - 0s - loss: 1.0932 - precision_m: 0.4172\n",
            "Epoch 286/500\n",
            "43/43 - 0s - loss: 1.8796 - precision_m: 0.4201\n",
            "Epoch 287/500\n",
            "43/43 - 0s - loss: 1.1503 - precision_m: 0.4172\n",
            "Epoch 288/500\n",
            "43/43 - 0s - loss: 1.0374 - precision_m: 0.4201\n",
            "Epoch 289/500\n",
            "43/43 - 0s - loss: 2.3580 - precision_m: 0.4215\n",
            "Epoch 290/500\n",
            "43/43 - 0s - loss: 1.3199 - precision_m: 0.4186\n",
            "Epoch 291/500\n",
            "43/43 - 0s - loss: 1.2798 - precision_m: 0.4201\n",
            "Epoch 292/500\n",
            "43/43 - 0s - loss: 1.0923 - precision_m: 0.4201\n",
            "Epoch 293/500\n",
            "43/43 - 0s - loss: 1.9199 - precision_m: 0.4201\n",
            "Epoch 294/500\n",
            "43/43 - 0s - loss: 1.5400 - precision_m: 0.4201\n",
            "Epoch 295/500\n",
            "43/43 - 0s - loss: 1.5565 - precision_m: 0.4186\n",
            "Epoch 296/500\n",
            "43/43 - 0s - loss: 1.3534 - precision_m: 0.4201\n",
            "Epoch 297/500\n",
            "43/43 - 0s - loss: 1.5454 - precision_m: 0.4186\n",
            "Epoch 298/500\n",
            "43/43 - 0s - loss: 1.1278 - precision_m: 0.4201\n",
            "Epoch 299/500\n",
            "43/43 - 0s - loss: 0.9575 - precision_m: 0.4172\n",
            "Epoch 300/500\n",
            "43/43 - 0s - loss: 1.2287 - precision_m: 0.4201\n",
            "Epoch 301/500\n",
            "43/43 - 0s - loss: 2.2951 - precision_m: 0.4201\n",
            "Epoch 302/500\n",
            "43/43 - 0s - loss: 1.5060 - precision_m: 0.4172\n",
            "Epoch 303/500\n",
            "43/43 - 0s - loss: 1.5866 - precision_m: 0.4186\n",
            "Epoch 304/500\n",
            "43/43 - 0s - loss: 1.6732 - precision_m: 0.4186\n",
            "Epoch 305/500\n",
            "43/43 - 0s - loss: 1.4088 - precision_m: 0.4186\n",
            "Epoch 306/500\n",
            "43/43 - 0s - loss: 0.9200 - precision_m: 0.4215\n",
            "Epoch 307/500\n",
            "43/43 - 0s - loss: 1.6271 - precision_m: 0.4215\n",
            "Epoch 308/500\n",
            "43/43 - 0s - loss: 1.3355 - precision_m: 0.4186\n",
            "Epoch 309/500\n",
            "43/43 - 0s - loss: 2.1611 - precision_m: 0.4201\n",
            "Epoch 310/500\n",
            "43/43 - 0s - loss: 0.8388 - precision_m: 0.4172\n",
            "Epoch 311/500\n",
            "43/43 - 0s - loss: 1.7661 - precision_m: 0.4172\n",
            "Epoch 312/500\n",
            "43/43 - 0s - loss: 1.4024 - precision_m: 0.4201\n",
            "Epoch 313/500\n",
            "43/43 - 0s - loss: 1.4987 - precision_m: 0.4172\n",
            "Epoch 314/500\n",
            "43/43 - 0s - loss: 1.3890 - precision_m: 0.4215\n",
            "Epoch 315/500\n",
            "43/43 - 0s - loss: 1.5417 - precision_m: 0.4215\n",
            "Epoch 316/500\n",
            "43/43 - 0s - loss: 1.1645 - precision_m: 0.4186\n",
            "Epoch 317/500\n",
            "43/43 - 0s - loss: 0.9984 - precision_m: 0.4201\n",
            "Epoch 318/500\n",
            "43/43 - 0s - loss: 1.4154 - precision_m: 0.4215\n",
            "Epoch 319/500\n",
            "43/43 - 0s - loss: 1.1707 - precision_m: 0.4172\n",
            "Epoch 320/500\n",
            "43/43 - 0s - loss: 1.1114 - precision_m: 0.4201\n",
            "Epoch 321/500\n",
            "43/43 - 0s - loss: 0.7401 - precision_m: 0.4201\n",
            "Epoch 322/500\n",
            "43/43 - 0s - loss: 1.8122 - precision_m: 0.4201\n",
            "Epoch 323/500\n",
            "43/43 - 0s - loss: 1.0236 - precision_m: 0.4186\n",
            "Epoch 324/500\n",
            "43/43 - 0s - loss: 0.8924 - precision_m: 0.4215\n",
            "Epoch 325/500\n",
            "43/43 - 0s - loss: 1.0242 - precision_m: 0.4186\n",
            "Epoch 326/500\n",
            "43/43 - 0s - loss: 1.0193 - precision_m: 0.4215\n",
            "Epoch 327/500\n",
            "43/43 - 0s - loss: 0.9403 - precision_m: 0.4186\n",
            "Epoch 328/500\n",
            "43/43 - 0s - loss: 1.1339 - precision_m: 0.4186\n",
            "Epoch 329/500\n",
            "43/43 - 0s - loss: 0.7204 - precision_m: 0.4172\n",
            "Epoch 330/500\n",
            "43/43 - 0s - loss: 1.0263 - precision_m: 0.4201\n",
            "Epoch 331/500\n",
            "43/43 - 0s - loss: 1.1586 - precision_m: 0.4215\n",
            "Epoch 332/500\n",
            "43/43 - 0s - loss: 1.3374 - precision_m: 0.4186\n",
            "Epoch 333/500\n",
            "43/43 - 0s - loss: 0.8707 - precision_m: 0.4201\n",
            "Epoch 334/500\n",
            "43/43 - 0s - loss: 0.6610 - precision_m: 0.4215\n",
            "Epoch 335/500\n",
            "43/43 - 0s - loss: 1.4327 - precision_m: 0.4186\n",
            "Epoch 336/500\n",
            "43/43 - 0s - loss: 0.9087 - precision_m: 0.4201\n",
            "Epoch 337/500\n",
            "43/43 - 0s - loss: 0.8556 - precision_m: 0.4186\n",
            "Epoch 338/500\n",
            "43/43 - 0s - loss: 0.8007 - precision_m: 0.4201\n",
            "Epoch 339/500\n",
            "43/43 - 0s - loss: 0.9917 - precision_m: 0.4186\n",
            "Epoch 340/500\n",
            "43/43 - 0s - loss: 0.9199 - precision_m: 0.4186\n",
            "Epoch 341/500\n",
            "43/43 - 0s - loss: 1.7282 - precision_m: 0.4186\n",
            "Epoch 342/500\n",
            "43/43 - 0s - loss: 1.3776 - precision_m: 0.4201\n",
            "Epoch 343/500\n",
            "43/43 - 0s - loss: 0.7259 - precision_m: 0.4215\n",
            "Epoch 344/500\n",
            "43/43 - 0s - loss: 0.6792 - precision_m: 0.4172\n",
            "Epoch 345/500\n",
            "43/43 - 0s - loss: 1.0696 - precision_m: 0.4215\n",
            "Epoch 346/500\n",
            "43/43 - 0s - loss: 1.6138 - precision_m: 0.4201\n",
            "Epoch 347/500\n",
            "43/43 - 0s - loss: 0.8432 - precision_m: 0.4201\n",
            "Epoch 348/500\n",
            "43/43 - 0s - loss: 0.7842 - precision_m: 0.4172\n",
            "Epoch 349/500\n",
            "43/43 - 0s - loss: 0.5784 - precision_m: 0.4186\n",
            "Epoch 350/500\n",
            "43/43 - 0s - loss: 0.8383 - precision_m: 0.4201\n",
            "Epoch 351/500\n",
            "43/43 - 0s - loss: 0.6937 - precision_m: 0.4186\n",
            "Epoch 352/500\n",
            "43/43 - 0s - loss: 1.0046 - precision_m: 0.4201\n",
            "Epoch 353/500\n",
            "43/43 - 0s - loss: 0.8324 - precision_m: 0.4215\n",
            "Epoch 354/500\n",
            "43/43 - 0s - loss: 0.6873 - precision_m: 0.4172\n",
            "Epoch 355/500\n",
            "43/43 - 0s - loss: 1.0813 - precision_m: 0.4201\n",
            "Epoch 356/500\n",
            "43/43 - 0s - loss: 0.7242 - precision_m: 0.4201\n",
            "Epoch 357/500\n",
            "43/43 - 0s - loss: 0.5975 - precision_m: 0.4215\n",
            "Epoch 358/500\n",
            "43/43 - 0s - loss: 1.0664 - precision_m: 0.4201\n",
            "Epoch 359/500\n",
            "43/43 - 0s - loss: 1.5241 - precision_m: 0.4201\n",
            "Epoch 360/500\n",
            "43/43 - 0s - loss: 0.6866 - precision_m: 0.4186\n",
            "Epoch 361/500\n",
            "43/43 - 0s - loss: 0.6560 - precision_m: 0.4186\n",
            "Epoch 362/500\n",
            "43/43 - 0s - loss: 0.7663 - precision_m: 0.4201\n",
            "Epoch 363/500\n",
            "43/43 - 0s - loss: 1.7436 - precision_m: 0.4186\n",
            "Epoch 364/500\n",
            "43/43 - 0s - loss: 1.2959 - precision_m: 0.4186\n",
            "Epoch 365/500\n",
            "43/43 - 0s - loss: 0.9050 - precision_m: 0.4201\n",
            "Epoch 366/500\n",
            "43/43 - 0s - loss: 1.2336 - precision_m: 0.4186\n",
            "Epoch 367/500\n",
            "43/43 - 0s - loss: 1.0459 - precision_m: 0.4201\n",
            "Epoch 368/500\n",
            "43/43 - 0s - loss: 1.1980 - precision_m: 0.4172\n",
            "Epoch 369/500\n",
            "43/43 - 0s - loss: 0.6674 - precision_m: 0.4201\n",
            "Epoch 370/500\n",
            "43/43 - 0s - loss: 1.6380 - precision_m: 0.4201\n",
            "Epoch 371/500\n",
            "43/43 - 0s - loss: 1.3765 - precision_m: 0.4186\n",
            "Epoch 372/500\n",
            "43/43 - 0s - loss: 1.5758 - precision_m: 0.4201\n",
            "Epoch 373/500\n",
            "43/43 - 0s - loss: 1.4672 - precision_m: 0.4186\n",
            "Epoch 374/500\n",
            "43/43 - 0s - loss: 1.6211 - precision_m: 0.4186\n",
            "Epoch 375/500\n",
            "43/43 - 0s - loss: 1.0002 - precision_m: 0.4215\n",
            "Epoch 376/500\n",
            "43/43 - 0s - loss: 0.9489 - precision_m: 0.4215\n",
            "Epoch 377/500\n",
            "43/43 - 0s - loss: 1.2811 - precision_m: 0.4201\n",
            "Epoch 378/500\n",
            "43/43 - 0s - loss: 1.2601 - precision_m: 0.4215\n",
            "Epoch 379/500\n",
            "43/43 - 0s - loss: 0.7496 - precision_m: 0.4201\n",
            "Epoch 380/500\n",
            "43/43 - 0s - loss: 1.0951 - precision_m: 0.4215\n",
            "Epoch 381/500\n",
            "43/43 - 0s - loss: 0.8308 - precision_m: 0.4201\n",
            "Epoch 382/500\n",
            "43/43 - 0s - loss: 1.3582 - precision_m: 0.4186\n",
            "Epoch 383/500\n",
            "43/43 - 0s - loss: 1.0326 - precision_m: 0.4215\n",
            "Epoch 384/500\n",
            "43/43 - 0s - loss: 1.0820 - precision_m: 0.4172\n",
            "Epoch 385/500\n",
            "43/43 - 0s - loss: 1.1936 - precision_m: 0.4201\n",
            "Epoch 386/500\n",
            "43/43 - 0s - loss: 1.0687 - precision_m: 0.4215\n",
            "Epoch 387/500\n",
            "43/43 - 0s - loss: 0.9556 - precision_m: 0.4201\n",
            "Epoch 388/500\n",
            "43/43 - 0s - loss: 0.9426 - precision_m: 0.4172\n",
            "Epoch 389/500\n",
            "43/43 - 0s - loss: 1.1777 - precision_m: 0.4201\n",
            "Epoch 390/500\n",
            "43/43 - 0s - loss: 1.0640 - precision_m: 0.4186\n",
            "Epoch 391/500\n",
            "43/43 - 0s - loss: 1.2673 - precision_m: 0.4186\n",
            "Epoch 392/500\n",
            "43/43 - 0s - loss: 0.8044 - precision_m: 0.4186\n",
            "Epoch 393/500\n",
            "43/43 - 0s - loss: 1.3514 - precision_m: 0.4172\n",
            "Epoch 394/500\n",
            "43/43 - 0s - loss: 0.7520 - precision_m: 0.4201\n",
            "Epoch 395/500\n",
            "43/43 - 0s - loss: 2.1100 - precision_m: 0.4201\n",
            "Epoch 396/500\n",
            "43/43 - 0s - loss: 1.3411 - precision_m: 0.4201\n",
            "Epoch 397/500\n",
            "43/43 - 0s - loss: 0.8126 - precision_m: 0.4215\n",
            "Epoch 398/500\n",
            "43/43 - 0s - loss: 0.8180 - precision_m: 0.4201\n",
            "Epoch 399/500\n",
            "43/43 - 0s - loss: 1.4622 - precision_m: 0.4215\n",
            "Epoch 400/500\n",
            "43/43 - 0s - loss: 1.1977 - precision_m: 0.4186\n",
            "Epoch 401/500\n",
            "43/43 - 0s - loss: 0.7568 - precision_m: 0.4215\n",
            "Epoch 402/500\n",
            "43/43 - 0s - loss: 0.9105 - precision_m: 0.4201\n",
            "Epoch 403/500\n",
            "43/43 - 0s - loss: 1.0659 - precision_m: 0.4201\n",
            "Epoch 404/500\n",
            "43/43 - 0s - loss: 0.8185 - precision_m: 0.4172\n",
            "Epoch 405/500\n",
            "43/43 - 0s - loss: 0.9036 - precision_m: 0.4186\n",
            "Epoch 406/500\n",
            "43/43 - 0s - loss: 0.8994 - precision_m: 0.4172\n",
            "Epoch 407/500\n",
            "43/43 - 0s - loss: 0.7967 - precision_m: 0.4172\n",
            "Epoch 408/500\n",
            "43/43 - 0s - loss: 0.8905 - precision_m: 0.4201\n",
            "Epoch 409/500\n",
            "43/43 - 0s - loss: 0.6746 - precision_m: 0.4215\n",
            "Epoch 410/500\n",
            "43/43 - 0s - loss: 0.9443 - precision_m: 0.4215\n",
            "Epoch 411/500\n",
            "43/43 - 0s - loss: 1.2638 - precision_m: 0.4201\n",
            "Epoch 412/500\n",
            "43/43 - 0s - loss: 0.8506 - precision_m: 0.4201\n",
            "Epoch 413/500\n",
            "43/43 - 0s - loss: 0.9671 - precision_m: 0.4201\n",
            "Epoch 414/500\n",
            "43/43 - 0s - loss: 1.1203 - precision_m: 0.4201\n",
            "Epoch 415/500\n",
            "43/43 - 0s - loss: 1.0892 - precision_m: 0.4215\n",
            "Epoch 416/500\n",
            "43/43 - 0s - loss: 0.8616 - precision_m: 0.4215\n",
            "Epoch 417/500\n",
            "43/43 - 0s - loss: 1.3052 - precision_m: 0.4201\n",
            "Epoch 418/500\n",
            "43/43 - 0s - loss: 0.7009 - precision_m: 0.4215\n",
            "Epoch 419/500\n",
            "43/43 - 0s - loss: 1.5467 - precision_m: 0.4201\n",
            "Epoch 420/500\n",
            "43/43 - 0s - loss: 0.8901 - precision_m: 0.4215\n",
            "Epoch 421/500\n",
            "43/43 - 0s - loss: 0.9248 - precision_m: 0.4201\n",
            "Epoch 422/500\n",
            "43/43 - 0s - loss: 1.0666 - precision_m: 0.4186\n",
            "Epoch 423/500\n",
            "43/43 - 0s - loss: 0.7846 - precision_m: 0.4215\n",
            "Epoch 424/500\n",
            "43/43 - 0s - loss: 1.3946 - precision_m: 0.4201\n",
            "Epoch 425/500\n",
            "43/43 - 0s - loss: 1.6779 - precision_m: 0.4215\n",
            "Epoch 426/500\n",
            "43/43 - 0s - loss: 0.6725 - precision_m: 0.4201\n",
            "Epoch 427/500\n",
            "43/43 - 0s - loss: 0.9280 - precision_m: 0.4201\n",
            "Epoch 428/500\n",
            "43/43 - 0s - loss: 0.7599 - precision_m: 0.4215\n",
            "Epoch 429/500\n",
            "43/43 - 0s - loss: 1.3790 - precision_m: 0.4215\n",
            "Epoch 430/500\n",
            "43/43 - 0s - loss: 1.4236 - precision_m: 0.4215\n",
            "Epoch 431/500\n",
            "43/43 - 0s - loss: 1.4333 - precision_m: 0.4215\n",
            "Epoch 432/500\n",
            "43/43 - 0s - loss: 0.8370 - precision_m: 0.4186\n",
            "Epoch 433/500\n",
            "43/43 - 0s - loss: 0.7209 - precision_m: 0.4201\n",
            "Epoch 434/500\n",
            "43/43 - 0s - loss: 0.9261 - precision_m: 0.4172\n",
            "Epoch 435/500\n",
            "43/43 - 0s - loss: 1.5838 - precision_m: 0.4186\n",
            "Epoch 436/500\n",
            "43/43 - 0s - loss: 0.8396 - precision_m: 0.4186\n",
            "Epoch 437/500\n",
            "43/43 - 0s - loss: 0.9639 - precision_m: 0.4172\n",
            "Epoch 438/500\n",
            "43/43 - 0s - loss: 1.0998 - precision_m: 0.4201\n",
            "Epoch 439/500\n",
            "43/43 - 0s - loss: 0.8351 - precision_m: 0.4215\n",
            "Epoch 440/500\n",
            "43/43 - 0s - loss: 1.1468 - precision_m: 0.4186\n",
            "Epoch 441/500\n",
            "43/43 - 0s - loss: 0.7502 - precision_m: 0.4186\n",
            "Epoch 442/500\n",
            "43/43 - 0s - loss: 0.8596 - precision_m: 0.4172\n",
            "Epoch 443/500\n",
            "43/43 - 0s - loss: 1.0321 - precision_m: 0.4201\n",
            "Epoch 444/500\n",
            "43/43 - 0s - loss: 1.6393 - precision_m: 0.4201\n",
            "Epoch 445/500\n",
            "43/43 - 0s - loss: 0.8575 - precision_m: 0.4201\n",
            "Epoch 446/500\n",
            "43/43 - 0s - loss: 1.0496 - precision_m: 0.4201\n",
            "Epoch 447/500\n",
            "43/43 - 0s - loss: 0.9780 - precision_m: 0.4186\n",
            "Epoch 448/500\n",
            "43/43 - 0s - loss: 1.5103 - precision_m: 0.4215\n",
            "Epoch 449/500\n",
            "43/43 - 0s - loss: 0.7911 - precision_m: 0.4201\n",
            "Epoch 450/500\n",
            "43/43 - 0s - loss: 0.8327 - precision_m: 0.4186\n",
            "Epoch 451/500\n",
            "43/43 - 0s - loss: 1.0389 - precision_m: 0.4215\n",
            "Epoch 452/500\n",
            "43/43 - 0s - loss: 0.6504 - precision_m: 0.4186\n",
            "Epoch 453/500\n",
            "43/43 - 0s - loss: 1.0142 - precision_m: 0.4201\n",
            "Epoch 454/500\n",
            "43/43 - 0s - loss: 0.7277 - precision_m: 0.4215\n",
            "Epoch 455/500\n",
            "43/43 - 0s - loss: 0.9715 - precision_m: 0.4201\n",
            "Epoch 456/500\n",
            "43/43 - 0s - loss: 1.2682 - precision_m: 0.4201\n",
            "Epoch 457/500\n",
            "43/43 - 0s - loss: 1.1018 - precision_m: 0.4201\n",
            "Epoch 458/500\n",
            "43/43 - 0s - loss: 0.7855 - precision_m: 0.4201\n",
            "Epoch 459/500\n",
            "43/43 - 0s - loss: 0.7995 - precision_m: 0.4201\n",
            "Epoch 460/500\n",
            "43/43 - 0s - loss: 1.4989 - precision_m: 0.4215\n",
            "Epoch 461/500\n",
            "43/43 - 0s - loss: 1.4399 - precision_m: 0.4186\n",
            "Epoch 462/500\n",
            "43/43 - 0s - loss: 0.9459 - precision_m: 0.4201\n",
            "Epoch 463/500\n",
            "43/43 - 0s - loss: 1.1972 - precision_m: 0.4201\n",
            "Epoch 464/500\n",
            "43/43 - 0s - loss: 1.1519 - precision_m: 0.4215\n",
            "Epoch 465/500\n",
            "43/43 - 0s - loss: 0.8981 - precision_m: 0.4186\n",
            "Epoch 466/500\n",
            "43/43 - 0s - loss: 0.7458 - precision_m: 0.4172\n",
            "Epoch 467/500\n",
            "43/43 - 0s - loss: 1.9425 - precision_m: 0.4186\n",
            "Epoch 468/500\n",
            "43/43 - 0s - loss: 1.4767 - precision_m: 0.4201\n",
            "Epoch 469/500\n",
            "43/43 - 0s - loss: 0.7836 - precision_m: 0.4201\n",
            "Epoch 470/500\n",
            "43/43 - 0s - loss: 0.8313 - precision_m: 0.4215\n",
            "Epoch 471/500\n",
            "43/43 - 0s - loss: 1.1993 - precision_m: 0.4186\n",
            "Epoch 472/500\n",
            "43/43 - 0s - loss: 0.7340 - precision_m: 0.4186\n",
            "Epoch 473/500\n",
            "43/43 - 0s - loss: 0.7828 - precision_m: 0.4215\n",
            "Epoch 474/500\n",
            "43/43 - 0s - loss: 0.8486 - precision_m: 0.4172\n",
            "Epoch 475/500\n",
            "43/43 - 0s - loss: 0.8248 - precision_m: 0.4186\n",
            "Epoch 476/500\n",
            "43/43 - 0s - loss: 1.1638 - precision_m: 0.4201\n",
            "Epoch 477/500\n",
            "43/43 - 0s - loss: 0.7008 - precision_m: 0.4186\n",
            "Epoch 478/500\n",
            "43/43 - 0s - loss: 0.6840 - precision_m: 0.4215\n",
            "Epoch 479/500\n",
            "43/43 - 0s - loss: 1.2240 - precision_m: 0.4186\n",
            "Epoch 480/500\n",
            "43/43 - 0s - loss: 0.6525 - precision_m: 0.4201\n",
            "Epoch 481/500\n",
            "43/43 - 0s - loss: 0.6134 - precision_m: 0.4201\n",
            "Epoch 482/500\n",
            "43/43 - 0s - loss: 0.7841 - precision_m: 0.4201\n",
            "Epoch 483/500\n",
            "43/43 - 0s - loss: 0.8987 - precision_m: 0.4201\n",
            "Epoch 484/500\n",
            "43/43 - 0s - loss: 1.0084 - precision_m: 0.4215\n",
            "Epoch 485/500\n",
            "43/43 - 0s - loss: 0.5883 - precision_m: 0.4201\n",
            "Epoch 486/500\n",
            "43/43 - 0s - loss: 0.4836 - precision_m: 0.4201\n",
            "Epoch 487/500\n",
            "43/43 - 0s - loss: 0.8169 - precision_m: 0.4201\n",
            "Epoch 488/500\n",
            "43/43 - 0s - loss: 0.8402 - precision_m: 0.4201\n",
            "Epoch 489/500\n",
            "43/43 - 0s - loss: 0.8253 - precision_m: 0.4186\n",
            "Epoch 490/500\n",
            "43/43 - 0s - loss: 1.2382 - precision_m: 0.4201\n",
            "Epoch 491/500\n",
            "43/43 - 0s - loss: 0.5031 - precision_m: 0.4201\n",
            "Epoch 492/500\n",
            "43/43 - 0s - loss: 1.0171 - precision_m: 0.4215\n",
            "Epoch 493/500\n",
            "43/43 - 0s - loss: 0.7462 - precision_m: 0.4201\n",
            "Epoch 494/500\n",
            "43/43 - 0s - loss: 1.3625 - precision_m: 0.4172\n",
            "Epoch 495/500\n",
            "43/43 - 0s - loss: 1.5816 - precision_m: 0.4215\n",
            "Epoch 496/500\n",
            "43/43 - 0s - loss: 0.8073 - precision_m: 0.4215\n",
            "Epoch 497/500\n",
            "43/43 - 0s - loss: 1.5414 - precision_m: 0.4201\n",
            "Epoch 498/500\n",
            "43/43 - 0s - loss: 0.7051 - precision_m: 0.4186\n",
            "Epoch 499/500\n",
            "43/43 - 0s - loss: 1.0645 - precision_m: 0.4172\n",
            "Epoch 500/500\n",
            "43/43 - 0s - loss: 0.9362 - precision_m: 0.4215\n",
            "CPU times: user 1min 8s, sys: 11.6 s, total: 1min 20s\n",
            "Wall time: 1min 44s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb147d78b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpccN0LLNfxD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}